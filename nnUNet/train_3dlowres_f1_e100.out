Starting at Thu 27 Feb 2025 10:12:19 AM GMT

############################
INFO: You are using the old nnU-Net default plans. We have updated our recommendations. Please consider using those instead! Read more here: https://github.com/MIC-DKFZ/nnUNet/blob/master/documentation/resenc_presets.md
############################

Using device: cuda:0

#######################################################################
Please cite the following paper when using nnU-Net:
Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.
#######################################################################

2025-02-27 10:12:30.969582: do_dummy_2d_data_aug: False
2025-02-27 10:12:30.972178: Using splits from existing split file: /home3/hghr96/parm/work/AD_project/segmentation/nnUNet/data/nnUNet_preprocessed/Dataset501_AD/splits_final.json
2025-02-27 10:12:30.974723: The split file contains 5 splits.
2025-02-27 10:12:30.976307: Desired fold for training: 1
2025-02-27 10:12:30.977811: This split has 70 training and 18 validation cases.
using pin_memory on device 0
/home3/hghr96/miniconda3/envs/nnUnet/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
using pin_memory on device 0
2025-02-27 10:12:33.136021: Using torch.compile...

This is the configuration used by this training:
Configuration name: 3d_lowres
 {'data_identifier': 'nnUNetPlans_3d_lowres', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 2, 'patch_size': [112, 192, 112], 'median_image_size_in_voxels': [177, 288, 177], 'spacing': [2.275601343470847, 2.028794967802552, 2.275601343470847], 'normalization_schemes': ['CTNormalization'], 'use_mask_for_norm': [False], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.PlainConvUNet', 'arch_kwargs': {'n_stages': 6, 'features_per_stage': [32, 64, 128, 256, 320, 320], 'conv_op': 'torch.nn.modules.conv.Conv3d', 'kernel_sizes': [[3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]], 'strides': [[1, 1, 1], [2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2], [1, 2, 1]], 'n_conv_per_stage': [2, 2, 2, 2, 2, 2], 'n_conv_per_stage_decoder': [2, 2, 2, 2, 2], 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm3d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}}, '_kw_requires_import': ['conv_op', 'norm_op', 'dropout_op', 'nonlin']}, 'batch_dice': False, 'next_stage': '3d_cascade_fullres'} 

These are the global plan.json settings:
 {'dataset_name': 'Dataset501_AD', 'plans_name': 'nnUNetPlans', 'original_median_spacing_after_transp': [0.78515625, 0.7000000476837158, 0.78515625], 'original_median_shape_after_transp': [512, 800, 512], 'image_reader_writer': 'SimpleITKIO', 'transpose_forward': [1, 0, 2], 'transpose_backward': [1, 0, 2], 'experiment_planner_used': 'ExperimentPlanner', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 3071.0, 'mean': 161.64767456054688, 'median': 182.0, 'min': -1103.0, 'percentile_00_5': -840.0, 'percentile_99_5': 778.0, 'std': 241.90689086914062}}} 

2025-02-27 10:12:35.737242: unpacking dataset...
2025-02-27 10:13:46.024302: unpacking done...
2025-02-27 10:13:46.360661: Unable to plot network architecture: nnUNet_compile is enabled!
2025-02-27 10:13:46.620108: 
2025-02-27 10:13:46.622212: Epoch 0
2025-02-27 10:13:46.624382: Current learning rate: 0.01
2025-02-27 10:17:34.294682: train_loss 0.2022
2025-02-27 10:17:34.298105: val_loss 0.068
2025-02-27 10:17:34.300379: Pseudo dice [0.0, 0.0, 0.0, 0.0]
2025-02-27 10:17:34.302353: Epoch time: 227.68 s
2025-02-27 10:17:34.304353: Yayy! New best EMA pseudo Dice: 0.0
2025-02-27 10:17:37.771029: 
2025-02-27 10:17:37.773722: Epoch 1
2025-02-27 10:17:37.776108: Current learning rate: 0.00991
2025-02-27 10:19:45.989120: train_loss 0.0159
2025-02-27 10:19:45.993418: val_loss -0.0321
2025-02-27 10:19:45.995134: Pseudo dice [0.0, 0.1478, 0.0068, 0.3284]
2025-02-27 10:19:45.996828: Epoch time: 128.22 s
2025-02-27 10:19:45.998421: Yayy! New best EMA pseudo Dice: 0.0121
2025-02-27 10:19:50.275747: 
2025-02-27 10:19:50.534859: Epoch 2
2025-02-27 10:19:50.938288: Current learning rate: 0.00982
2025-02-27 10:22:26.558139: train_loss -0.0494
2025-02-27 10:22:26.561198: val_loss -0.0874
2025-02-27 10:22:26.563136: Pseudo dice [0.0, 0.0, 0.0, 0.3659]
2025-02-27 10:22:26.565471: Epoch time: 156.29 s
2025-02-27 10:22:26.567492: Yayy! New best EMA pseudo Dice: 0.02
2025-02-27 10:22:30.224278: 
2025-02-27 10:22:30.226416: Epoch 3
2025-02-27 10:22:30.228562: Current learning rate: 0.00973
2025-02-27 10:25:38.342174: train_loss -0.0959
2025-02-27 10:25:38.347114: val_loss -0.1147
2025-02-27 10:25:38.349628: Pseudo dice [0.0, 0.0, 0.0047, 0.2836]
2025-02-27 10:25:38.351919: Epoch time: 188.12 s
2025-02-27 10:25:38.354076: Yayy! New best EMA pseudo Dice: 0.0252
2025-02-27 10:25:42.082504: 
2025-02-27 10:25:42.085127: Epoch 4
2025-02-27 10:25:42.086967: Current learning rate: 0.00964
2025-02-27 10:29:08.731550: train_loss -0.1167
2025-02-27 10:29:08.734303: val_loss -0.1484
2025-02-27 10:29:08.736335: Pseudo dice [0.0, 0.0443, 0.5037, 0.4137]
2025-02-27 10:29:08.737923: Epoch time: 206.65 s
2025-02-27 10:29:08.739448: Yayy! New best EMA pseudo Dice: 0.0467
2025-02-27 10:29:12.460180: 
2025-02-27 10:29:12.462724: Epoch 5
2025-02-27 10:29:12.465055: Current learning rate: 0.00955
2025-02-27 10:32:41.950462: train_loss -0.1425
2025-02-27 10:32:41.954978: val_loss -0.1526
2025-02-27 10:32:41.957266: Pseudo dice [0.0, 0.0132, 0.5502, 0.4183]
2025-02-27 10:32:41.959461: Epoch time: 209.49 s
2025-02-27 10:32:41.961424: Yayy! New best EMA pseudo Dice: 0.0666
2025-02-27 10:32:45.589354: 
2025-02-27 10:32:45.592165: Epoch 6
2025-02-27 10:32:45.594796: Current learning rate: 0.00946
2025-02-27 10:36:18.483534: train_loss -0.178
2025-02-27 10:36:18.486631: val_loss -0.1628
2025-02-27 10:36:18.488802: Pseudo dice [0.3014, 0.0549, 0.5436, 0.4401]
2025-02-27 10:36:18.490516: Epoch time: 212.9 s
2025-02-27 10:36:18.492157: Yayy! New best EMA pseudo Dice: 0.0935
2025-02-27 10:36:22.165790: 
2025-02-27 10:36:22.167978: Epoch 7
2025-02-27 10:36:22.169705: Current learning rate: 0.00937
2025-02-27 10:39:52.001370: train_loss -0.2036
2025-02-27 10:39:52.006176: val_loss -0.2207
2025-02-27 10:39:52.009070: Pseudo dice [0.479, 0.0113, 0.632, 0.4899]
2025-02-27 10:39:52.011647: Epoch time: 209.84 s
2025-02-27 10:39:52.014067: Yayy! New best EMA pseudo Dice: 0.1244
2025-02-27 10:39:55.727617: 
2025-02-27 10:39:55.729884: Epoch 8
2025-02-27 10:39:55.731456: Current learning rate: 0.00928
2025-02-27 10:43:33.568926: train_loss -0.2399
2025-02-27 10:43:33.572496: val_loss -0.23
2025-02-27 10:43:33.574522: Pseudo dice [0.512, 0.4245, 0.6069, 0.5216]
2025-02-27 10:43:33.576949: Epoch time: 217.84 s
2025-02-27 10:43:33.579043: Yayy! New best EMA pseudo Dice: 0.1636
2025-02-27 10:43:37.318016: 
2025-02-27 10:43:37.320741: Epoch 9
2025-02-27 10:43:37.323023: Current learning rate: 0.00919
2025-02-27 10:46:00.080611: train_loss -0.2626
2025-02-27 10:46:00.086400: val_loss -0.2451
2025-02-27 10:46:00.088552: Pseudo dice [0.5361, 0.5311, 0.6636, 0.4972]
2025-02-27 10:46:00.090546: Epoch time: 142.76 s
2025-02-27 10:46:00.092542: Yayy! New best EMA pseudo Dice: 0.2029
2025-02-27 10:46:03.878306: 
2025-02-27 10:46:03.880369: Epoch 10
2025-02-27 10:46:03.882167: Current learning rate: 0.0091
2025-02-27 10:48:24.833305: train_loss -0.2747
2025-02-27 10:48:24.837220: val_loss -0.2479
2025-02-27 10:48:24.839289: Pseudo dice [0.5644, 0.5514, 0.7021, 0.4213]
2025-02-27 10:48:24.841084: Epoch time: 140.96 s
2025-02-27 10:48:24.842847: Yayy! New best EMA pseudo Dice: 0.2386
2025-02-27 10:48:29.187504: 
2025-02-27 10:48:29.189813: Epoch 11
2025-02-27 10:48:29.192193: Current learning rate: 0.009
2025-02-27 10:50:38.488250: train_loss -0.2736
2025-02-27 10:50:38.493392: val_loss -0.2478
2025-02-27 10:50:38.496063: Pseudo dice [0.5846, 0.5497, 0.6626, 0.4444]
2025-02-27 10:50:38.498532: Epoch time: 129.3 s
2025-02-27 10:50:38.501012: Yayy! New best EMA pseudo Dice: 0.2708
2025-02-27 10:50:42.963487: 
2025-02-27 10:50:42.966000: Epoch 12
2025-02-27 10:50:42.968125: Current learning rate: 0.00891
2025-02-27 10:53:01.046335: train_loss -0.2833
2025-02-27 10:53:01.051036: val_loss -0.2555
2025-02-27 10:53:01.053635: Pseudo dice [0.6191, 0.5936, 0.6477, 0.4616]
2025-02-27 10:53:01.056056: Epoch time: 138.08 s
2025-02-27 10:53:01.058254: Yayy! New best EMA pseudo Dice: 0.3018
2025-02-27 10:53:05.323583: 
2025-02-27 10:53:05.326171: Epoch 13
2025-02-27 10:53:05.328262: Current learning rate: 0.00882
2025-02-27 10:55:16.669138: train_loss -0.3091
2025-02-27 10:55:16.672555: val_loss -0.2732
2025-02-27 10:55:16.675006: Pseudo dice [0.5874, 0.6467, 0.722, 0.5382]
2025-02-27 10:55:16.677402: Epoch time: 131.35 s
2025-02-27 10:55:16.679450: Yayy! New best EMA pseudo Dice: 0.3339
2025-02-27 10:55:20.809542: 
2025-02-27 10:55:20.812382: Epoch 14
2025-02-27 10:55:20.814270: Current learning rate: 0.00873
2025-02-27 10:57:24.242909: train_loss -0.321
2025-02-27 10:57:24.247514: val_loss -0.2961
2025-02-27 10:57:24.250197: Pseudo dice [0.6432, 0.6932, 0.6977, 0.5185]
2025-02-27 10:57:24.252689: Epoch time: 123.43 s
2025-02-27 10:57:24.255083: Yayy! New best EMA pseudo Dice: 0.3644
2025-02-27 10:57:29.803459: 
2025-02-27 10:57:29.806506: Epoch 15
2025-02-27 10:57:29.808725: Current learning rate: 0.00864
2025-02-27 10:59:27.053164: train_loss -0.3255
2025-02-27 10:59:27.057976: val_loss -0.2834
2025-02-27 10:59:27.060808: Pseudo dice [0.6813, 0.6493, 0.7732, 0.4552]
2025-02-27 10:59:27.063432: Epoch time: 117.25 s
2025-02-27 10:59:27.066154: Yayy! New best EMA pseudo Dice: 0.3919
2025-02-27 10:59:31.024632: 
2025-02-27 10:59:31.328367: Epoch 16
2025-02-27 10:59:31.587717: Current learning rate: 0.00855
2025-02-27 11:01:47.233856: train_loss -0.3345
2025-02-27 11:01:47.236674: val_loss -0.3176
2025-02-27 11:01:47.238590: Pseudo dice [0.6862, 0.7358, 0.7772, 0.5558]
2025-02-27 11:01:47.240536: Epoch time: 136.21 s
2025-02-27 11:01:47.242368: Yayy! New best EMA pseudo Dice: 0.4216
2025-02-27 11:01:51.279200: 
2025-02-27 11:01:51.281240: Epoch 17
2025-02-27 11:01:51.282845: Current learning rate: 0.00846
2025-02-27 11:03:51.796920: train_loss -0.3503
2025-02-27 11:03:51.800234: val_loss -0.3165
2025-02-27 11:03:51.802611: Pseudo dice [0.7127, 0.717, 0.7243, 0.6303]
2025-02-27 11:03:51.804914: Epoch time: 120.52 s
2025-02-27 11:03:51.807235: Yayy! New best EMA pseudo Dice: 0.449
2025-02-27 11:03:55.652997: 
2025-02-27 11:03:55.655392: Epoch 18
2025-02-27 11:03:55.657529: Current learning rate: 0.00836
2025-02-27 11:05:59.002323: train_loss -0.3586
2025-02-27 11:05:59.006561: val_loss -0.3311
2025-02-27 11:05:59.009296: Pseudo dice [0.7115, 0.7126, 0.7999, 0.6001]
2025-02-27 11:05:59.011856: Epoch time: 123.35 s
2025-02-27 11:05:59.014342: Yayy! New best EMA pseudo Dice: 0.4747
2025-02-27 11:06:03.056215: 
2025-02-27 11:06:03.319015: Epoch 19
2025-02-27 11:06:03.595808: Current learning rate: 0.00827
2025-02-27 11:08:19.846027: train_loss -0.3642
2025-02-27 11:08:19.849605: val_loss -0.3269
2025-02-27 11:08:19.852350: Pseudo dice [0.7966, 0.7078, 0.8022, 0.5574]
2025-02-27 11:08:19.854979: Epoch time: 136.79 s
2025-02-27 11:08:19.857526: Yayy! New best EMA pseudo Dice: 0.4989
2025-02-27 11:08:23.633148: 
2025-02-27 11:08:23.635235: Epoch 20
2025-02-27 11:08:23.637440: Current learning rate: 0.00818
2025-02-27 11:10:28.172119: train_loss -0.3779
2025-02-27 11:10:28.175411: val_loss -0.3198
2025-02-27 11:10:28.177987: Pseudo dice [0.704, 0.7541, 0.7763, 0.6273]
2025-02-27 11:10:28.180562: Epoch time: 124.54 s
2025-02-27 11:10:28.182955: Yayy! New best EMA pseudo Dice: 0.5205
2025-02-27 11:10:32.694970: 
2025-02-27 11:10:32.697660: Epoch 21
2025-02-27 11:10:32.699730: Current learning rate: 0.00809
2025-02-27 11:12:43.327160: train_loss -0.381
2025-02-27 11:12:43.330752: val_loss -0.3089
2025-02-27 11:12:43.332739: Pseudo dice [0.7454, 0.7345, 0.7685, 0.6468]
2025-02-27 11:12:43.334769: Epoch time: 130.63 s
2025-02-27 11:12:43.336597: Yayy! New best EMA pseudo Dice: 0.5408
2025-02-27 11:12:47.149394: 
2025-02-27 11:12:47.152500: Epoch 22
2025-02-27 11:12:47.154544: Current learning rate: 0.008
2025-02-27 11:14:52.658807: train_loss -0.3822
2025-02-27 11:14:52.661780: val_loss -0.3587
2025-02-27 11:14:52.663716: Pseudo dice [0.7476, 0.7743, 0.7658, 0.6738]
2025-02-27 11:14:52.665947: Epoch time: 125.51 s
2025-02-27 11:14:52.667677: Yayy! New best EMA pseudo Dice: 0.5608
2025-02-27 11:14:57.024701: 
2025-02-27 11:14:57.026617: Epoch 23
2025-02-27 11:14:57.028450: Current learning rate: 0.0079
2025-02-27 11:17:12.612294: train_loss -0.3797
2025-02-27 11:17:12.615723: val_loss -0.3262
2025-02-27 11:17:12.618502: Pseudo dice [0.742, 0.7094, 0.7981, 0.6511]
2025-02-27 11:17:12.620773: Epoch time: 135.59 s
2025-02-27 11:17:12.623057: Yayy! New best EMA pseudo Dice: 0.5772
2025-02-27 11:17:17.081068: 
2025-02-27 11:17:17.083624: Epoch 24
2025-02-27 11:17:17.086209: Current learning rate: 0.00781
2025-02-27 11:19:37.689552: train_loss -0.3789
2025-02-27 11:19:37.693187: val_loss -0.3373
2025-02-27 11:19:37.695827: Pseudo dice [0.7153, 0.7416, 0.8207, 0.6311]
2025-02-27 11:19:37.698476: Epoch time: 140.61 s
2025-02-27 11:19:37.700969: Yayy! New best EMA pseudo Dice: 0.5922
2025-02-27 11:19:41.416931: 
2025-02-27 11:19:41.419426: Epoch 25
2025-02-27 11:19:41.421876: Current learning rate: 0.00772
2025-02-27 11:21:54.150724: train_loss -0.3786
2025-02-27 11:21:54.153637: val_loss -0.3252
2025-02-27 11:21:54.155242: Pseudo dice [0.707, 0.7573, 0.7497, 0.6118]
2025-02-27 11:21:54.157141: Epoch time: 132.73 s
2025-02-27 11:21:54.158635: Yayy! New best EMA pseudo Dice: 0.6037
2025-02-27 11:21:58.415988: 
2025-02-27 11:21:58.418686: Epoch 26
2025-02-27 11:21:58.420985: Current learning rate: 0.00763
2025-02-27 11:24:14.249736: train_loss -0.392
2025-02-27 11:24:14.252750: val_loss -0.347
2025-02-27 11:24:14.254867: Pseudo dice [0.7646, 0.7969, 0.8232, 0.7034]
2025-02-27 11:24:14.256508: Epoch time: 135.84 s
2025-02-27 11:24:14.257937: Yayy! New best EMA pseudo Dice: 0.6205
2025-02-27 11:24:18.094892: 
2025-02-27 11:24:18.097515: Epoch 27
2025-02-27 11:24:18.099201: Current learning rate: 0.00753
2025-02-27 11:26:29.387945: train_loss -0.3943
2025-02-27 11:26:29.391763: val_loss -0.3556
2025-02-27 11:26:29.393840: Pseudo dice [0.72, 0.799, 0.7903, 0.686]
2025-02-27 11:26:29.395901: Epoch time: 131.29 s
2025-02-27 11:26:29.398051: Yayy! New best EMA pseudo Dice: 0.6333
2025-02-27 11:26:33.464038: 
2025-02-27 11:26:33.466322: Epoch 28
2025-02-27 11:26:33.468560: Current learning rate: 0.00744
2025-02-27 11:28:36.929750: train_loss -0.383
2025-02-27 11:28:36.933050: val_loss -0.3598
2025-02-27 11:28:36.935451: Pseudo dice [0.793, 0.8007, 0.8049, 0.6758]
2025-02-27 11:28:36.937976: Epoch time: 123.47 s
2025-02-27 11:28:36.940045: Yayy! New best EMA pseudo Dice: 0.6468
2025-02-27 11:28:40.717864: 
2025-02-27 11:28:40.720060: Epoch 29
2025-02-27 11:28:40.721963: Current learning rate: 0.00735
2025-02-27 11:30:51.635590: train_loss -0.3804
2025-02-27 11:30:51.638190: val_loss -0.3433
2025-02-27 11:30:51.639613: Pseudo dice [0.7354, 0.7486, 0.7955, 0.6971]
2025-02-27 11:30:51.640966: Epoch time: 130.92 s
2025-02-27 11:30:51.642238: Yayy! New best EMA pseudo Dice: 0.6566
2025-02-27 11:30:55.452125: 
2025-02-27 11:30:55.454539: Epoch 30
2025-02-27 11:30:55.456807: Current learning rate: 0.00725
2025-02-27 11:33:04.062829: train_loss -0.4113
2025-02-27 11:33:04.066124: val_loss -0.329
2025-02-27 11:33:04.068562: Pseudo dice [0.7683, 0.7423, 0.8178, 0.6231]
2025-02-27 11:33:04.070706: Epoch time: 128.61 s
2025-02-27 11:33:04.072591: Yayy! New best EMA pseudo Dice: 0.6647
2025-02-27 11:33:07.815242: 
2025-02-27 11:33:07.819457: Epoch 31
2025-02-27 11:33:07.822453: Current learning rate: 0.00716
2025-02-27 11:35:21.459054: train_loss -0.4085
2025-02-27 11:35:21.462528: val_loss -0.3498
2025-02-27 11:35:21.464573: Pseudo dice [0.754, 0.8052, 0.7843, 0.6838]
2025-02-27 11:35:21.466442: Epoch time: 133.65 s
2025-02-27 11:35:21.468152: Yayy! New best EMA pseudo Dice: 0.6739
2025-02-27 11:35:25.879685: 
2025-02-27 11:35:25.881874: Epoch 32
2025-02-27 11:35:25.883549: Current learning rate: 0.00707
2025-02-27 11:37:25.806047: train_loss -0.4147
2025-02-27 11:37:25.810559: val_loss -0.34
2025-02-27 11:37:25.813174: Pseudo dice [0.7682, 0.758, 0.8114, 0.6582]
2025-02-27 11:37:25.815526: Epoch time: 119.93 s
2025-02-27 11:37:25.818241: Yayy! New best EMA pseudo Dice: 0.6814
2025-02-27 11:37:30.985023: 
2025-02-27 11:37:30.987118: Epoch 33
2025-02-27 11:37:30.989196: Current learning rate: 0.00697
2025-02-27 11:39:33.649247: train_loss -0.4221
2025-02-27 11:39:33.652167: val_loss -0.3612
2025-02-27 11:39:33.653435: Pseudo dice [0.7925, 0.8114, 0.8079, 0.6588]
2025-02-27 11:39:33.654645: Epoch time: 122.67 s
2025-02-27 11:39:33.655859: Yayy! New best EMA pseudo Dice: 0.6901
2025-02-27 11:39:37.480987: 
2025-02-27 11:39:37.483357: Epoch 34
2025-02-27 11:39:37.485622: Current learning rate: 0.00688
2025-02-27 11:41:49.462214: train_loss -0.4216
2025-02-27 11:41:49.466687: val_loss -0.3786
2025-02-27 11:41:49.469211: Pseudo dice [0.805, 0.8341, 0.8274, 0.7279]
2025-02-27 11:41:49.471358: Epoch time: 131.98 s
2025-02-27 11:41:49.473738: Yayy! New best EMA pseudo Dice: 0.7009
2025-02-27 11:41:53.422930: 
2025-02-27 11:41:53.424383: Epoch 35
2025-02-27 11:41:53.425788: Current learning rate: 0.00679
2025-02-27 11:44:12.454065: train_loss -0.43
2025-02-27 11:44:12.457802: val_loss -0.3294
2025-02-27 11:44:12.459396: Pseudo dice [0.7894, 0.7698, 0.8246, 0.6997]
2025-02-27 11:44:12.460844: Epoch time: 139.03 s
2025-02-27 11:44:12.462177: Yayy! New best EMA pseudo Dice: 0.7079
2025-02-27 11:44:16.573737: 
2025-02-27 11:44:16.576240: Epoch 36
2025-02-27 11:44:16.577941: Current learning rate: 0.00669
2025-02-27 11:46:28.013623: train_loss -0.4273
2025-02-27 11:46:28.018275: val_loss -0.3417
2025-02-27 11:46:28.020651: Pseudo dice [0.7619, 0.8048, 0.7819, 0.7233]
2025-02-27 11:46:28.023057: Epoch time: 131.44 s
2025-02-27 11:46:28.025377: Yayy! New best EMA pseudo Dice: 0.7139
2025-02-27 11:46:32.058253: 
2025-02-27 11:46:32.060728: Epoch 37
2025-02-27 11:46:32.062681: Current learning rate: 0.0066
2025-02-27 11:48:53.109944: train_loss -0.4209
2025-02-27 11:48:53.114534: val_loss -0.3842
2025-02-27 11:48:53.116952: Pseudo dice [0.8063, 0.8354, 0.8452, 0.712]
2025-02-27 11:48:53.119308: Epoch time: 141.05 s
2025-02-27 11:48:53.121718: Yayy! New best EMA pseudo Dice: 0.7225
2025-02-27 11:48:57.634075: 
2025-02-27 11:48:57.636403: Epoch 38
2025-02-27 11:48:57.638250: Current learning rate: 0.0065
2025-02-27 11:51:19.854470: train_loss -0.4275
2025-02-27 11:51:19.859324: val_loss -0.3467
2025-02-27 11:51:19.861943: Pseudo dice [0.8152, 0.7898, 0.7973, 0.692]
2025-02-27 11:51:19.864508: Epoch time: 142.22 s
2025-02-27 11:51:19.866658: Yayy! New best EMA pseudo Dice: 0.7276
2025-02-27 11:51:24.271320: 
2025-02-27 11:51:24.274625: Epoch 39
2025-02-27 11:51:24.276803: Current learning rate: 0.00641
2025-02-27 11:53:37.254840: train_loss -0.4322
2025-02-27 11:53:37.259459: val_loss -0.3535
2025-02-27 11:53:37.261946: Pseudo dice [0.8106, 0.7767, 0.823, 0.687]
2025-02-27 11:53:37.264010: Epoch time: 132.98 s
2025-02-27 11:53:37.266125: Yayy! New best EMA pseudo Dice: 0.7323
2025-02-27 11:53:42.088113: 
2025-02-27 11:53:42.090470: Epoch 40
2025-02-27 11:53:42.092619: Current learning rate: 0.00631
2025-02-27 11:55:47.269784: train_loss -0.4323
2025-02-27 11:55:47.274339: val_loss -0.3663
2025-02-27 11:55:47.276485: Pseudo dice [0.7803, 0.8112, 0.8262, 0.7325]
2025-02-27 11:55:47.278788: Epoch time: 125.18 s
2025-02-27 11:55:47.280756: Yayy! New best EMA pseudo Dice: 0.7378
2025-02-27 11:55:51.978037: 
2025-02-27 11:55:51.980416: Epoch 41
2025-02-27 11:55:51.982618: Current learning rate: 0.00622
2025-02-27 11:58:06.713514: train_loss -0.4335
2025-02-27 11:58:06.716515: val_loss -0.3626
2025-02-27 11:58:06.718100: Pseudo dice [0.8354, 0.8356, 0.8775, 0.7444]
2025-02-27 11:58:06.719469: Epoch time: 134.74 s
2025-02-27 11:58:06.720844: Yayy! New best EMA pseudo Dice: 0.7463
2025-02-27 11:58:11.096822: 
2025-02-27 11:58:11.099257: Epoch 42
2025-02-27 11:58:11.101638: Current learning rate: 0.00612
2025-02-27 12:00:22.595006: train_loss -0.4372
2025-02-27 12:00:22.599555: val_loss -0.3576
2025-02-27 12:00:22.601982: Pseudo dice [0.7845, 0.845, 0.7724, 0.7294]
2025-02-27 12:00:22.604011: Epoch time: 131.5 s
2025-02-27 12:00:22.605974: Yayy! New best EMA pseudo Dice: 0.75
2025-02-27 12:00:27.023913: 
2025-02-27 12:00:27.025698: Epoch 43
2025-02-27 12:00:27.027277: Current learning rate: 0.00603
2025-02-27 12:02:30.613306: train_loss -0.4473
2025-02-27 12:02:30.616808: val_loss -0.3948
2025-02-27 12:02:30.619378: Pseudo dice [0.8436, 0.8626, 0.8646, 0.7205]
2025-02-27 12:02:30.622020: Epoch time: 123.59 s
2025-02-27 12:02:30.624406: Yayy! New best EMA pseudo Dice: 0.7573
2025-02-27 12:02:35.457315: 
2025-02-27 12:02:35.460758: Epoch 44
2025-02-27 12:02:35.462932: Current learning rate: 0.00593
2025-02-27 12:04:41.970903: train_loss -0.4523
2025-02-27 12:04:41.973926: val_loss -0.3938
2025-02-27 12:04:41.976200: Pseudo dice [0.8252, 0.8434, 0.8737, 0.6585]
2025-02-27 12:04:41.978455: Epoch time: 126.52 s
2025-02-27 12:04:41.980699: Yayy! New best EMA pseudo Dice: 0.7616
2025-02-27 12:04:45.685807: 
2025-02-27 12:04:45.687893: Epoch 45
2025-02-27 12:04:45.689617: Current learning rate: 0.00584
2025-02-27 12:06:56.335145: train_loss -0.4478
2025-02-27 12:06:56.338104: val_loss -0.3644
2025-02-27 12:06:56.340194: Pseudo dice [0.8017, 0.8243, 0.8064, 0.7188]
2025-02-27 12:06:56.342359: Epoch time: 130.65 s
2025-02-27 12:06:56.344461: Yayy! New best EMA pseudo Dice: 0.7642
2025-02-27 12:07:00.601552: 
2025-02-27 12:07:00.603565: Epoch 46
2025-02-27 12:07:00.605463: Current learning rate: 0.00574
2025-02-27 12:09:01.623417: train_loss -0.4475
2025-02-27 12:09:01.626013: val_loss -0.363
2025-02-27 12:09:01.627705: Pseudo dice [0.8421, 0.8045, 0.8453, 0.7155]
2025-02-27 12:09:01.630037: Epoch time: 121.02 s
2025-02-27 12:09:01.631863: Yayy! New best EMA pseudo Dice: 0.768
2025-02-27 12:09:05.778970: 
2025-02-27 12:09:05.781320: Epoch 47
2025-02-27 12:09:05.783342: Current learning rate: 0.00565
2025-02-27 12:11:28.375682: train_loss -0.4565
2025-02-27 12:11:28.378403: val_loss -0.3826
2025-02-27 12:11:28.379867: Pseudo dice [0.8122, 0.8145, 0.8424, 0.7156]
2025-02-27 12:11:28.381720: Epoch time: 142.6 s
2025-02-27 12:11:28.383040: Yayy! New best EMA pseudo Dice: 0.7708
2025-02-27 12:11:32.640980: 
2025-02-27 12:11:32.642850: Epoch 48
2025-02-27 12:11:32.644365: Current learning rate: 0.00555
2025-02-27 12:13:35.843584: train_loss -0.4531
2025-02-27 12:13:35.847674: val_loss -0.3777
2025-02-27 12:13:35.849852: Pseudo dice [0.8479, 0.8466, 0.8534, 0.7424]
2025-02-27 12:13:35.851694: Epoch time: 123.2 s
2025-02-27 12:13:35.853360: Yayy! New best EMA pseudo Dice: 0.776
2025-02-27 12:13:40.292743: 
2025-02-27 12:13:40.409269: Epoch 49
2025-02-27 12:13:40.566294: Current learning rate: 0.00546
2025-02-27 12:15:46.657016: train_loss -0.4529
2025-02-27 12:15:46.661711: val_loss -0.3726
2025-02-27 12:15:46.664089: Pseudo dice [0.8445, 0.854, 0.8562, 0.7508]
2025-02-27 12:15:46.666581: Epoch time: 126.37 s
2025-02-27 12:15:49.023471: Yayy! New best EMA pseudo Dice: 0.781
2025-02-27 12:15:53.088754: 
2025-02-27 12:15:53.090354: Epoch 50
2025-02-27 12:15:53.091642: Current learning rate: 0.00536
2025-02-27 12:17:56.722256: train_loss -0.4614
2025-02-27 12:17:56.732478: val_loss -0.3609
2025-02-27 12:17:56.735260: Pseudo dice [0.8162, 0.8299, 0.7747, 0.738]
2025-02-27 12:17:56.737816: Epoch time: 123.63 s
2025-02-27 12:17:56.740133: Yayy! New best EMA pseudo Dice: 0.7819
2025-02-27 12:18:01.006440: 
2025-02-27 12:18:01.008978: Epoch 51
2025-02-27 12:18:01.011436: Current learning rate: 0.00526
2025-02-27 12:20:14.995900: train_loss -0.4526
2025-02-27 12:20:15.000890: val_loss -0.414
2025-02-27 12:20:15.003656: Pseudo dice [0.8439, 0.8755, 0.8756, 0.7545]
2025-02-27 12:20:15.006129: Epoch time: 133.99 s
2025-02-27 12:20:15.008412: Yayy! New best EMA pseudo Dice: 0.7874
2025-02-27 12:20:19.072918: 
2025-02-27 12:20:19.075224: Epoch 52
2025-02-27 12:20:19.077451: Current learning rate: 0.00517
2025-02-27 12:22:26.630569: train_loss -0.4663
2025-02-27 12:22:26.635134: val_loss -0.3706
2025-02-27 12:22:26.637557: Pseudo dice [0.8571, 0.8431, 0.8334, 0.7461]
2025-02-27 12:22:26.639672: Epoch time: 127.56 s
2025-02-27 12:22:26.642224: Yayy! New best EMA pseudo Dice: 0.7907
2025-02-27 12:22:30.380830: 
2025-02-27 12:22:30.383122: Epoch 53
2025-02-27 12:22:30.385349: Current learning rate: 0.00507
2025-02-27 12:24:35.750566: train_loss -0.4633
2025-02-27 12:24:35.755209: val_loss -0.3765
2025-02-27 12:24:35.757802: Pseudo dice [0.826, 0.8392, 0.7855, 0.7281]
2025-02-27 12:24:35.760136: Epoch time: 125.37 s
2025-02-27 12:24:35.762548: Yayy! New best EMA pseudo Dice: 0.7911
2025-02-27 12:24:39.536133: 
2025-02-27 12:24:39.540177: Epoch 54
2025-02-27 12:24:39.542549: Current learning rate: 0.00497
2025-02-27 12:26:47.923892: train_loss -0.4553
2025-02-27 12:26:47.928885: val_loss -0.3845
2025-02-27 12:26:47.931217: Pseudo dice [0.8563, 0.8615, 0.8589, 0.7555]
2025-02-27 12:26:47.933798: Epoch time: 128.39 s
2025-02-27 12:26:47.935981: Yayy! New best EMA pseudo Dice: 0.7953
2025-02-27 12:26:52.107474: 
2025-02-27 12:26:52.110052: Epoch 55
2025-02-27 12:26:52.111410: Current learning rate: 0.00487
2025-02-27 12:28:56.782117: train_loss -0.4692
2025-02-27 12:28:56.786400: val_loss -0.3994
2025-02-27 12:28:56.788505: Pseudo dice [0.8238, 0.8694, 0.8485, 0.765]
2025-02-27 12:28:56.790490: Epoch time: 124.68 s
2025-02-27 12:28:56.792722: Yayy! New best EMA pseudo Dice: 0.7984
2025-02-27 12:29:00.541100: 
2025-02-27 12:29:00.543104: Epoch 56
2025-02-27 12:29:00.544779: Current learning rate: 0.00478
2025-02-27 12:31:08.507834: train_loss -0.4499
2025-02-27 12:31:08.511134: val_loss -0.3717
2025-02-27 12:31:08.512765: Pseudo dice [0.8244, 0.8602, 0.786, 0.7465]
2025-02-27 12:31:08.514308: Epoch time: 127.97 s
2025-02-27 12:31:08.515754: Yayy! New best EMA pseudo Dice: 0.799
2025-02-27 12:31:12.321658: 
2025-02-27 12:31:12.324468: Epoch 57
2025-02-27 12:31:12.326685: Current learning rate: 0.00468
2025-02-27 12:33:15.186523: train_loss -0.4641
2025-02-27 12:33:15.191507: val_loss -0.3973
2025-02-27 12:33:15.194379: Pseudo dice [0.7836, 0.8654, 0.8158, 0.7579]
2025-02-27 12:33:15.196904: Epoch time: 122.87 s
2025-02-27 12:33:15.199109: Yayy! New best EMA pseudo Dice: 0.7997
2025-02-27 12:33:19.044117: 
2025-02-27 12:33:19.046320: Epoch 58
2025-02-27 12:33:19.048392: Current learning rate: 0.00458
2025-02-27 12:35:26.504302: train_loss -0.4681
2025-02-27 12:35:26.507330: val_loss -0.3931
2025-02-27 12:35:26.509825: Pseudo dice [0.837, 0.8642, 0.8669, 0.7932]
2025-02-27 12:35:26.512077: Epoch time: 127.46 s
2025-02-27 12:35:26.514293: Yayy! New best EMA pseudo Dice: 0.8037
2025-02-27 12:35:30.496081: 
2025-02-27 12:35:30.498126: Epoch 59
2025-02-27 12:35:30.500160: Current learning rate: 0.00448
2025-02-27 12:37:33.816691: train_loss -0.4582
2025-02-27 12:37:33.819754: val_loss -0.4007
2025-02-27 12:37:33.821914: Pseudo dice [0.8734, 0.8483, 0.8451, 0.7396]
2025-02-27 12:37:33.823905: Epoch time: 123.32 s
2025-02-27 12:37:33.825763: Yayy! New best EMA pseudo Dice: 0.806
2025-02-27 12:37:37.869849: 
2025-02-27 12:37:37.871942: Epoch 60
2025-02-27 12:37:37.873708: Current learning rate: 0.00438
2025-02-27 12:39:42.623427: train_loss -0.4617
2025-02-27 12:39:42.626866: val_loss -0.411
2025-02-27 12:39:42.629394: Pseudo dice [0.8581, 0.8778, 0.8362, 0.7865]
2025-02-27 12:39:42.631634: Epoch time: 124.75 s
2025-02-27 12:39:42.633788: Yayy! New best EMA pseudo Dice: 0.8094
2025-02-27 12:39:47.095004: 
2025-02-27 12:39:47.097370: Epoch 61
2025-02-27 12:39:47.099144: Current learning rate: 0.00429
2025-02-27 12:41:54.596522: train_loss -0.4742
2025-02-27 12:41:54.599533: val_loss -0.3743
2025-02-27 12:41:54.601365: Pseudo dice [0.8362, 0.86, 0.8735, 0.7571]
2025-02-27 12:41:54.603119: Epoch time: 127.5 s
2025-02-27 12:41:54.605340: Yayy! New best EMA pseudo Dice: 0.8116
2025-02-27 12:41:58.843983: 
2025-02-27 12:41:58.846535: Epoch 62
2025-02-27 12:41:58.848421: Current learning rate: 0.00419
2025-02-27 12:44:01.446402: train_loss -0.4763
2025-02-27 12:44:01.450464: val_loss -0.4104
2025-02-27 12:44:01.452657: Pseudo dice [0.8808, 0.8707, 0.8778, 0.8048]
2025-02-27 12:44:01.454715: Epoch time: 122.6 s
2025-02-27 12:44:01.456913: Yayy! New best EMA pseudo Dice: 0.8163
2025-02-27 12:44:06.304919: 
2025-02-27 12:44:06.318287: Epoch 63
2025-02-27 12:44:06.321015: Current learning rate: 0.00409
2025-02-27 12:46:10.872704: train_loss -0.4967
2025-02-27 12:46:10.876570: val_loss -0.4281
2025-02-27 12:46:10.878353: Pseudo dice [0.8504, 0.8917, 0.8517, 0.8158]
2025-02-27 12:46:10.880005: Epoch time: 124.57 s
2025-02-27 12:46:10.881711: Yayy! New best EMA pseudo Dice: 0.8199
2025-02-27 12:46:15.579682: 
2025-02-27 12:46:15.582206: Epoch 64
2025-02-27 12:46:15.584435: Current learning rate: 0.00399
2025-02-27 12:48:16.836804: train_loss -0.4803
2025-02-27 12:48:16.841726: val_loss -0.3891
2025-02-27 12:48:16.844149: Pseudo dice [0.8349, 0.877, 0.8337, 0.7888]
2025-02-27 12:48:16.846334: Epoch time: 121.26 s
2025-02-27 12:48:16.848600: Yayy! New best EMA pseudo Dice: 0.8213
2025-02-27 12:48:20.509915: 
2025-02-27 12:48:20.512183: Epoch 65
2025-02-27 12:48:20.514282: Current learning rate: 0.00389
2025-02-27 12:50:34.884536: train_loss -0.4853
2025-02-27 12:50:34.889042: val_loss -0.388
2025-02-27 12:50:34.890953: Pseudo dice [0.8371, 0.8246, 0.8716, 0.7618]
2025-02-27 12:50:34.893605: Epoch time: 134.38 s
2025-02-27 12:50:34.895618: Yayy! New best EMA pseudo Dice: 0.8215
2025-02-27 12:50:39.310472: 
2025-02-27 12:50:39.312639: Epoch 66
2025-02-27 12:50:39.314484: Current learning rate: 0.00379
2025-02-27 12:52:43.305166: train_loss -0.4726
2025-02-27 12:52:43.309681: val_loss -0.3962
2025-02-27 12:52:43.312053: Pseudo dice [0.8537, 0.8435, 0.8691, 0.7775]
2025-02-27 12:52:43.314454: Epoch time: 124.0 s
2025-02-27 12:52:43.316877: Yayy! New best EMA pseudo Dice: 0.823
2025-02-27 12:52:47.140370: 
2025-02-27 12:52:47.142917: Epoch 67
2025-02-27 12:52:47.145239: Current learning rate: 0.00369
2025-02-27 12:54:57.398849: train_loss -0.4877
2025-02-27 12:54:57.402995: val_loss -0.4141
2025-02-27 12:54:57.405181: Pseudo dice [0.8256, 0.8697, 0.8283, 0.7714]
2025-02-27 12:54:57.407279: Epoch time: 130.26 s
2025-02-27 12:54:57.409630: Yayy! New best EMA pseudo Dice: 0.8231
2025-02-27 12:55:01.264660: 
2025-02-27 12:55:01.267143: Epoch 68
2025-02-27 12:55:01.269289: Current learning rate: 0.00359
2025-02-27 12:57:17.084415: train_loss -0.4729
2025-02-27 12:57:17.088028: val_loss -0.4112
2025-02-27 12:57:17.089739: Pseudo dice [0.8582, 0.8664, 0.8579, 0.8177]
2025-02-27 12:57:17.091455: Epoch time: 135.82 s
2025-02-27 12:57:17.093163: Yayy! New best EMA pseudo Dice: 0.8258
2025-02-27 12:57:21.737232: 
2025-02-27 12:57:21.739066: Epoch 69
2025-02-27 12:57:21.740577: Current learning rate: 0.00349
2025-02-27 12:59:33.020555: train_loss -0.476
2025-02-27 12:59:33.024923: val_loss -0.4101
2025-02-27 12:59:33.026980: Pseudo dice [0.8855, 0.8947, 0.874, 0.7898]
2025-02-27 12:59:33.029086: Epoch time: 131.29 s
2025-02-27 12:59:33.030825: Yayy! New best EMA pseudo Dice: 0.8293
2025-02-27 12:59:37.100849: 
2025-02-27 12:59:37.102693: Epoch 70
2025-02-27 12:59:37.104309: Current learning rate: 0.00338
2025-02-27 13:01:55.398126: train_loss -0.4888
2025-02-27 13:01:55.402646: val_loss -0.4034
2025-02-27 13:01:55.404826: Pseudo dice [0.8565, 0.8724, 0.873, 0.7825]
2025-02-27 13:01:55.406667: Epoch time: 138.3 s
2025-02-27 13:01:55.408411: Yayy! New best EMA pseudo Dice: 0.831
2025-02-27 13:01:59.916316: 
2025-02-27 13:01:59.917979: Epoch 71
2025-02-27 13:01:59.919382: Current learning rate: 0.00328
2025-02-27 13:04:09.504147: train_loss -0.4956
2025-02-27 13:04:09.508607: val_loss -0.3982
2025-02-27 13:04:09.510749: Pseudo dice [0.8498, 0.8681, 0.872, 0.7739]
2025-02-27 13:04:09.512990: Epoch time: 129.59 s
2025-02-27 13:04:09.514835: Yayy! New best EMA pseudo Dice: 0.832
2025-02-27 13:04:14.091996: 
2025-02-27 13:04:14.094013: Epoch 72
2025-02-27 13:04:14.095996: Current learning rate: 0.00318
2025-02-27 13:06:13.631066: train_loss -0.4903
2025-02-27 13:06:13.635174: val_loss -0.412
2025-02-27 13:06:13.637245: Pseudo dice [0.8502, 0.8708, 0.8485, 0.8092]
2025-02-27 13:06:13.639079: Epoch time: 119.54 s
2025-02-27 13:06:13.640855: Yayy! New best EMA pseudo Dice: 0.8332
2025-02-27 13:06:17.477262: 
2025-02-27 13:06:17.479813: Epoch 73
2025-02-27 13:06:17.481830: Current learning rate: 0.00308
2025-02-27 13:08:10.633238: train_loss -0.4962
2025-02-27 13:08:10.637039: val_loss -0.4225
2025-02-27 13:08:10.639102: Pseudo dice [0.8302, 0.8875, 0.8502, 0.773]
2025-02-27 13:08:10.641531: Epoch time: 113.16 s
2025-02-27 13:08:10.643571: Yayy! New best EMA pseudo Dice: 0.8334
2025-02-27 13:08:14.834839: 
2025-02-27 13:08:14.836723: Epoch 74
2025-02-27 13:08:14.838257: Current learning rate: 0.00297
2025-02-27 13:10:23.249957: train_loss -0.4964
2025-02-27 13:10:23.253514: val_loss -0.3982
2025-02-27 13:10:23.256223: Pseudo dice [0.8541, 0.8856, 0.8701, 0.7671]
2025-02-27 13:10:23.258566: Epoch time: 128.42 s
2025-02-27 13:10:23.261290: Yayy! New best EMA pseudo Dice: 0.8345
2025-02-27 13:10:27.153322: 
2025-02-27 13:10:27.155709: Epoch 75
2025-02-27 13:10:27.157587: Current learning rate: 0.00287
2025-02-27 13:12:26.041183: train_loss -0.4847
2025-02-27 13:12:26.044500: val_loss -0.4097
2025-02-27 13:12:26.046975: Pseudo dice [0.8509, 0.8898, 0.8632, 0.7967]
2025-02-27 13:12:26.049355: Epoch time: 118.89 s
2025-02-27 13:12:26.051765: Yayy! New best EMA pseudo Dice: 0.8361
2025-02-27 13:12:29.899875: 
2025-02-27 13:12:29.901904: Epoch 76
2025-02-27 13:12:29.903850: Current learning rate: 0.00277
2025-02-27 13:14:33.088605: train_loss -0.5006
2025-02-27 13:14:33.091624: val_loss -0.4005
2025-02-27 13:14:33.093278: Pseudo dice [0.8078, 0.874, 0.8205, 0.7948]
2025-02-27 13:14:33.094731: Epoch time: 123.19 s
2025-02-27 13:14:34.632918: 
2025-02-27 13:14:34.635141: Epoch 77
2025-02-27 13:14:34.637110: Current learning rate: 0.00266
2025-02-27 13:16:41.194886: train_loss -0.4943
2025-02-27 13:16:41.199740: val_loss -0.4153
2025-02-27 13:16:41.201920: Pseudo dice [0.8648, 0.8671, 0.8706, 0.7628]
2025-02-27 13:16:41.204096: Epoch time: 126.56 s
2025-02-27 13:16:43.168499: 
2025-02-27 13:16:43.385172: Epoch 78
2025-02-27 13:16:43.559579: Current learning rate: 0.00256
2025-02-27 13:18:57.335222: train_loss -0.4925
2025-02-27 13:18:57.340055: val_loss -0.4041
2025-02-27 13:18:57.342401: Pseudo dice [0.8379, 0.8723, 0.8624, 0.8047]
2025-02-27 13:18:57.344780: Epoch time: 134.17 s
2025-02-27 13:18:57.346820: Yayy! New best EMA pseudo Dice: 0.8364
2025-02-27 13:19:01.766148: 
2025-02-27 13:19:01.846328: Epoch 79
2025-02-27 13:19:01.848321: Current learning rate: 0.00245
2025-02-27 13:21:07.022169: train_loss -0.5087
2025-02-27 13:21:07.026736: val_loss -0.416
2025-02-27 13:21:07.029296: Pseudo dice [0.8668, 0.8823, 0.8805, 0.8192]
2025-02-27 13:21:07.031559: Epoch time: 125.26 s
2025-02-27 13:21:07.032919: Yayy! New best EMA pseudo Dice: 0.839
2025-02-27 13:21:11.552672: 
2025-02-27 13:21:11.554883: Epoch 80
2025-02-27 13:21:11.557081: Current learning rate: 0.00235
2025-02-27 13:23:13.802898: train_loss -0.4937
2025-02-27 13:23:13.806993: val_loss -0.3938
2025-02-27 13:23:13.809230: Pseudo dice [0.8152, 0.8633, 0.8418, 0.7846]
2025-02-27 13:23:13.811210: Epoch time: 122.25 s
2025-02-27 13:23:16.056065: 
2025-02-27 13:23:16.058574: Epoch 81
2025-02-27 13:23:16.061151: Current learning rate: 0.00224
2025-02-27 13:25:16.762517: train_loss -0.4885
2025-02-27 13:25:16.767523: val_loss -0.4187
2025-02-27 13:25:16.770135: Pseudo dice [0.8615, 0.86, 0.8612, 0.7991]
2025-02-27 13:25:16.772280: Epoch time: 120.71 s
2025-02-27 13:25:18.280297: 
2025-02-27 13:25:18.282566: Epoch 82
2025-02-27 13:25:18.285020: Current learning rate: 0.00214
2025-02-27 13:27:19.050163: train_loss -0.4958
2025-02-27 13:27:19.054640: val_loss -0.436
2025-02-27 13:27:19.057129: Pseudo dice [0.8908, 0.8927, 0.8987, 0.816]
2025-02-27 13:27:19.059339: Epoch time: 120.77 s
2025-02-27 13:27:19.061359: Yayy! New best EMA pseudo Dice: 0.8421
2025-02-27 13:27:23.821582: 
2025-02-27 13:27:23.824202: Epoch 83
2025-02-27 13:27:23.825995: Current learning rate: 0.00203
2025-02-27 13:29:28.331638: train_loss -0.5069
2025-02-27 13:29:28.334647: val_loss -0.4099
2025-02-27 13:29:28.335943: Pseudo dice [0.8546, 0.8648, 0.8694, 0.7637]
2025-02-27 13:29:28.337267: Epoch time: 124.51 s
2025-02-27 13:29:29.936758: 
2025-02-27 13:29:29.953991: Epoch 84
2025-02-27 13:29:29.956126: Current learning rate: 0.00192
2025-02-27 13:31:46.291458: train_loss -0.5038
2025-02-27 13:31:46.294389: val_loss -0.4234
2025-02-27 13:31:46.296435: Pseudo dice [0.8446, 0.8843, 0.827, 0.812]
2025-02-27 13:31:46.298332: Epoch time: 136.36 s
2025-02-27 13:31:48.331968: 
2025-02-27 13:31:48.334539: Epoch 85
2025-02-27 13:31:48.336231: Current learning rate: 0.00181
2025-02-27 13:33:54.069783: train_loss -0.5087
2025-02-27 13:33:54.073437: val_loss -0.4119
2025-02-27 13:33:54.075938: Pseudo dice [0.8751, 0.8868, 0.8842, 0.8078]
2025-02-27 13:33:54.078510: Epoch time: 125.74 s
2025-02-27 13:33:54.080936: Yayy! New best EMA pseudo Dice: 0.8439
2025-02-27 13:33:58.220932: 
2025-02-27 13:33:58.223306: Epoch 86
2025-02-27 13:33:58.225055: Current learning rate: 0.0017
2025-02-27 13:35:59.867012: train_loss -0.4901
2025-02-27 13:35:59.870202: val_loss -0.3942
2025-02-27 13:35:59.872280: Pseudo dice [0.841, 0.8798, 0.834, 0.7931]
2025-02-27 13:35:59.874233: Epoch time: 121.65 s
2025-02-27 13:36:01.229269: 
2025-02-27 13:36:01.232212: Epoch 87
2025-02-27 13:36:01.234979: Current learning rate: 0.00159
2025-02-27 13:38:11.051082: train_loss -0.5026
2025-02-27 13:38:11.054150: val_loss -0.4131
2025-02-27 13:38:11.056347: Pseudo dice [0.8795, 0.8794, 0.8804, 0.7983]
2025-02-27 13:38:11.058455: Epoch time: 129.82 s
2025-02-27 13:38:11.060477: Yayy! New best EMA pseudo Dice: 0.8448
2025-02-27 13:38:15.515337: 
2025-02-27 13:38:15.517729: Epoch 88
2025-02-27 13:38:15.519447: Current learning rate: 0.00148
2025-02-27 13:40:17.486260: train_loss -0.5197
2025-02-27 13:40:17.489253: val_loss -0.4078
2025-02-27 13:40:17.491289: Pseudo dice [0.8659, 0.8755, 0.8781, 0.8057]
2025-02-27 13:40:17.492882: Epoch time: 121.97 s
2025-02-27 13:40:17.494175: Yayy! New best EMA pseudo Dice: 0.846
2025-02-27 13:40:21.971511: 
2025-02-27 13:40:21.974767: Epoch 89
2025-02-27 13:40:21.977406: Current learning rate: 0.00137
2025-02-27 13:42:31.634666: train_loss -0.5037
2025-02-27 13:42:31.638335: val_loss -0.4085
2025-02-27 13:42:31.641208: Pseudo dice [0.8663, 0.8898, 0.8851, 0.8063]
2025-02-27 13:42:31.643367: Epoch time: 129.67 s
2025-02-27 13:42:31.645805: Yayy! New best EMA pseudo Dice: 0.8476
2025-02-27 13:42:35.347693: 
2025-02-27 13:42:35.350138: Epoch 90
2025-02-27 13:42:35.352283: Current learning rate: 0.00126
2025-02-27 13:44:40.021771: train_loss -0.4884
2025-02-27 13:44:40.025388: val_loss -0.4171
2025-02-27 13:44:40.027102: Pseudo dice [0.8764, 0.894, 0.8932, 0.8088]
2025-02-27 13:44:40.029029: Epoch time: 124.68 s
2025-02-27 13:44:40.031046: Yayy! New best EMA pseudo Dice: 0.8496
2025-02-27 13:44:43.698407: 
2025-02-27 13:44:43.701165: Epoch 91
2025-02-27 13:44:43.703194: Current learning rate: 0.00115
2025-02-27 13:47:02.298506: train_loss -0.497
2025-02-27 13:47:02.303148: val_loss -0.4174
2025-02-27 13:47:02.305722: Pseudo dice [0.859, 0.8886, 0.8661, 0.7957]
2025-02-27 13:47:02.308215: Epoch time: 138.6 s
2025-02-27 13:47:02.310337: Yayy! New best EMA pseudo Dice: 0.8499
2025-02-27 13:47:06.501690: 
2025-02-27 13:47:06.504194: Epoch 92
2025-02-27 13:47:06.505969: Current learning rate: 0.00103
2025-02-27 13:49:12.991418: train_loss -0.5109
2025-02-27 13:49:12.996168: val_loss -0.4255
2025-02-27 13:49:12.998359: Pseudo dice [0.8807, 0.8982, 0.8723, 0.8104]
2025-02-27 13:49:13.000554: Epoch time: 126.49 s
2025-02-27 13:49:13.002336: Yayy! New best EMA pseudo Dice: 0.8514
2025-02-27 13:49:17.547708: 
2025-02-27 13:49:17.660827: Epoch 93
2025-02-27 13:49:17.662845: Current learning rate: 0.00091
2025-02-27 13:51:23.896648: train_loss -0.4935
2025-02-27 13:51:23.901424: val_loss -0.4245
2025-02-27 13:51:23.903834: Pseudo dice [0.8824, 0.9092, 0.8902, 0.8115]
2025-02-27 13:51:23.906053: Epoch time: 126.35 s
2025-02-27 13:51:23.908283: Yayy! New best EMA pseudo Dice: 0.8536
2025-02-27 13:51:28.413582: 
2025-02-27 13:51:28.763535: Epoch 94
2025-02-27 13:51:29.067389: Current learning rate: 0.00079
2025-02-27 13:53:56.331103: train_loss -0.5104
2025-02-27 13:53:56.339835: val_loss -0.4252
2025-02-27 13:53:56.342840: Pseudo dice [0.8914, 0.8968, 0.8886, 0.8157]
2025-02-27 13:53:56.345840: Epoch time: 147.92 s
2025-02-27 13:53:56.348364: Yayy! New best EMA pseudo Dice: 0.8556
2025-02-27 13:54:00.570673: 
2025-02-27 13:54:00.573340: Epoch 95
2025-02-27 13:54:00.575496: Current learning rate: 0.00067
2025-02-27 13:56:08.846517: train_loss -0.514
2025-02-27 13:56:09.155246: val_loss -0.4372
2025-02-27 13:56:09.351903: Pseudo dice [0.8829, 0.8974, 0.8863, 0.8104]
2025-02-27 13:56:09.468214: Epoch time: 128.28 s
2025-02-27 13:56:09.518834: Yayy! New best EMA pseudo Dice: 0.8569
2025-02-27 13:56:13.891183: 
2025-02-27 13:56:13.893095: Epoch 96
2025-02-27 13:56:13.894792: Current learning rate: 0.00055
2025-02-27 13:58:31.579846: train_loss -0.5148
2025-02-27 13:58:31.584234: val_loss -0.4386
2025-02-27 13:58:31.586365: Pseudo dice [0.8805, 0.9001, 0.8815, 0.834]
2025-02-27 13:58:31.588755: Epoch time: 137.69 s
2025-02-27 13:58:31.590556: Yayy! New best EMA pseudo Dice: 0.8587
2025-02-27 13:58:36.119826: 
2025-02-27 13:58:36.122558: Epoch 97
2025-02-27 13:58:36.124686: Current learning rate: 0.00043
2025-02-27 14:00:46.792280: train_loss -0.5216
2025-02-27 14:00:46.795954: val_loss -0.4233
2025-02-27 14:00:46.798325: Pseudo dice [0.8683, 0.8995, 0.8814, 0.8247]
2025-02-27 14:00:46.800864: Epoch time: 130.67 s
2025-02-27 14:00:46.802980: Yayy! New best EMA pseudo Dice: 0.8596
2025-02-27 14:00:51.933650: 
2025-02-27 14:00:51.935815: Epoch 98
2025-02-27 14:00:51.937655: Current learning rate: 0.0003
2025-02-27 14:03:06.900520: train_loss -0.5238
2025-02-27 14:03:06.904624: val_loss -0.4125
2025-02-27 14:03:06.906603: Pseudo dice [0.8877, 0.8841, 0.873, 0.8059]
2025-02-27 14:03:06.908705: Epoch time: 134.97 s
2025-02-27 14:03:06.910509: Yayy! New best EMA pseudo Dice: 0.8599
2025-02-27 14:03:10.711191: 
2025-02-27 14:03:10.713711: Epoch 99
2025-02-27 14:03:10.715151: Current learning rate: 0.00016
2025-02-27 14:05:17.599294: train_loss -0.5021
2025-02-27 14:05:17.602939: val_loss -0.4125
2025-02-27 14:05:17.605803: Pseudo dice [0.8882, 0.8663, 0.8804, 0.8006]
2025-02-27 14:05:17.608714: Epoch time: 126.89 s
2025-02-27 14:05:22.543154: Training done.
2025-02-27 14:05:22.575213: Using splits from existing split file: /home3/hghr96/parm/work/AD_project/segmentation/nnUNet/data/nnUNet_preprocessed/Dataset501_AD/splits_final.json
2025-02-27 14:05:22.577420: The split file contains 5 splits.
2025-02-27 14:05:22.579046: Desired fold for training: 1
2025-02-27 14:05:22.580794: This split has 70 training and 18 validation cases.
2025-02-27 14:05:22.582924: predicting ad_001
2025-02-27 14:05:22.588239: ad_001, shape torch.Size([1, 155, 177, 155]), rank 0
2025-02-27 14:05:35.959799: predicting ad_019
2025-02-27 14:05:35.967887: ad_019, shape torch.Size([1, 167, 371, 167]), rank 0
2025-02-27 14:08:49.829728: predicting ad_022
2025-02-27 14:08:49.840324: ad_022, shape torch.Size([1, 142, 301, 142]), rank 0
2025-02-27 14:15:41.939081: predicting ad_023
2025-02-27 14:15:41.949717: ad_023, shape torch.Size([1, 169, 364, 169]), rank 0
2025-02-27 14:21:04.290261: predicting ad_026
2025-02-27 14:21:04.303057: ad_026, shape torch.Size([1, 106, 252, 106]), rank 0
2025-02-27 14:27:57.631437: predicting ad_027
2025-02-27 14:27:57.883590: ad_027, shape torch.Size([1, 192, 288, 192]), rank 0
2025-02-27 14:32:04.485451: predicting ad_029
2025-02-27 14:32:04.496148: ad_029, shape torch.Size([1, 177, 276, 177]), rank 0
2025-02-27 14:37:27.781966: predicting ad_034
2025-02-27 14:37:27.793177: ad_034, shape torch.Size([1, 177, 389, 177]), rank 0
2025-02-27 14:42:27.312309: predicting ad_036
2025-02-27 14:42:27.323640: ad_036, shape torch.Size([1, 185, 319, 185]), rank 0
2025-02-27 14:50:58.689328: predicting ad_041
2025-02-27 14:50:58.701797: ad_041, shape torch.Size([1, 212, 324, 212]), rank 0
2025-02-27 14:56:37.237864: predicting ad_048
2025-02-27 14:56:37.249038: ad_048, shape torch.Size([1, 192, 352, 192]), rank 0
2025-02-27 15:04:21.441694: predicting ad_057
2025-02-27 15:04:21.453965: ad_057, shape torch.Size([1, 181, 325, 181]), rank 0
2025-02-27 15:11:05.837440: predicting ad_064
2025-02-27 15:11:05.850415: ad_064, shape torch.Size([1, 177, 276, 177]), rank 0
2025-02-27 15:16:52.844471: predicting ad_078
2025-02-27 15:16:52.857682: ad_078, shape torch.Size([1, 127, 222, 127]), rank 0
2025-02-27 15:22:59.175097: predicting ad_081
2025-02-27 15:22:59.186806: ad_081, shape torch.Size([1, 207, 303, 207]), rank 0
2025-02-27 15:26:58.034649: predicting ad_085
2025-02-27 15:26:58.050320: ad_085, shape torch.Size([1, 220, 771, 220]), rank 0
2025-02-27 15:32:05.308775: predicting ad_087
2025-02-27 15:32:05.328754: ad_087, shape torch.Size([1, 169, 281, 169]), rank 0
2025-02-27 15:58:37.619399: predicting ad_093
2025-02-27 15:58:37.634712: ad_093, shape torch.Size([1, 200, 274, 200]), rank 0
2025-02-27 16:11:02.128150: Validation complete
2025-02-27 16:11:02.131306: Mean Validation Dice:  0.5871951145182437
Finished at Thu 27 Feb 2025 04:11:04 PM GMT
Total Execution Time: 21525 seconds
