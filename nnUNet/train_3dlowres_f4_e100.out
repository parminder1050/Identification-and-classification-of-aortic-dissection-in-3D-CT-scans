Starting at Thu 27 Feb 2025 10:12:19 AM GMT

############################
INFO: You are using the old nnU-Net default plans. We have updated our recommendations. Please consider using those instead! Read more here: https://github.com/MIC-DKFZ/nnUNet/blob/master/documentation/resenc_presets.md
############################

Using device: cuda:0

#######################################################################
Please cite the following paper when using nnU-Net:
Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.
#######################################################################

2025-02-27 10:12:31.001201: do_dummy_2d_data_aug: False
2025-02-27 10:12:31.003527: Using splits from existing split file: /home3/hghr96/parm/work/AD_project/segmentation/nnUNet/data/nnUNet_preprocessed/Dataset501_AD/splits_final.json
2025-02-27 10:12:31.006374: The split file contains 5 splits.
2025-02-27 10:12:31.007894: Desired fold for training: 4
2025-02-27 10:12:31.009320: This split has 71 training and 17 validation cases.
using pin_memory on device 0
/home3/hghr96/miniconda3/envs/nnUnet/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
using pin_memory on device 0
2025-02-27 10:12:33.126050: Using torch.compile...

This is the configuration used by this training:
Configuration name: 3d_lowres
 {'data_identifier': 'nnUNetPlans_3d_lowres', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 2, 'patch_size': [112, 192, 112], 'median_image_size_in_voxels': [177, 288, 177], 'spacing': [2.275601343470847, 2.028794967802552, 2.275601343470847], 'normalization_schemes': ['CTNormalization'], 'use_mask_for_norm': [False], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.PlainConvUNet', 'arch_kwargs': {'n_stages': 6, 'features_per_stage': [32, 64, 128, 256, 320, 320], 'conv_op': 'torch.nn.modules.conv.Conv3d', 'kernel_sizes': [[3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]], 'strides': [[1, 1, 1], [2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2], [1, 2, 1]], 'n_conv_per_stage': [2, 2, 2, 2, 2, 2], 'n_conv_per_stage_decoder': [2, 2, 2, 2, 2], 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm3d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}}, '_kw_requires_import': ['conv_op', 'norm_op', 'dropout_op', 'nonlin']}, 'batch_dice': False, 'next_stage': '3d_cascade_fullres'} 

These are the global plan.json settings:
 {'dataset_name': 'Dataset501_AD', 'plans_name': 'nnUNetPlans', 'original_median_spacing_after_transp': [0.78515625, 0.7000000476837158, 0.78515625], 'original_median_shape_after_transp': [512, 800, 512], 'image_reader_writer': 'SimpleITKIO', 'transpose_forward': [1, 0, 2], 'transpose_backward': [1, 0, 2], 'experiment_planner_used': 'ExperimentPlanner', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 3071.0, 'mean': 161.64767456054688, 'median': 182.0, 'min': -1103.0, 'percentile_00_5': -840.0, 'percentile_99_5': 778.0, 'std': 241.90689086914062}}} 

2025-02-27 10:12:35.737021: unpacking dataset...
2025-02-27 10:13:46.030102: unpacking done...
2025-02-27 10:13:46.376406: Unable to plot network architecture: nnUNet_compile is enabled!
2025-02-27 10:13:46.619402: 
2025-02-27 10:13:46.621808: Epoch 0
2025-02-27 10:13:46.623713: Current learning rate: 0.01
2025-02-27 10:17:28.283686: train_loss 0.1307
2025-02-27 10:17:28.287741: val_loss 0.0242
2025-02-27 10:17:28.289689: Pseudo dice [0.0, 0.0, 0.0, 0.0]
2025-02-27 10:17:28.291250: Epoch time: 221.67 s
2025-02-27 10:17:28.292840: Yayy! New best EMA pseudo Dice: 0.0
2025-02-27 10:17:31.884781: 
2025-02-27 10:17:31.886796: Epoch 1
2025-02-27 10:17:31.888305: Current learning rate: 0.00991
2025-02-27 10:19:49.486966: train_loss -0.0087
2025-02-27 10:19:49.490283: val_loss -0.0531
2025-02-27 10:19:49.495949: Pseudo dice [0.0, 0.0, 0.0, 0.3348]
2025-02-27 10:19:49.498292: Epoch time: 137.6 s
2025-02-27 10:19:49.500529: Yayy! New best EMA pseudo Dice: 0.0084
2025-02-27 10:19:54.105449: 
2025-02-27 10:19:54.108387: Epoch 2
2025-02-27 10:19:54.110266: Current learning rate: 0.00982
2025-02-27 10:22:06.258752: train_loss -0.0736
2025-02-27 10:22:06.263556: val_loss -0.1038
2025-02-27 10:22:06.266189: Pseudo dice [0.0, 0.0044, 0.0, 0.4083]
2025-02-27 10:22:06.268708: Epoch time: 132.15 s
2025-02-27 10:22:06.270940: Yayy! New best EMA pseudo Dice: 0.0178
2025-02-27 10:22:10.676696: 
2025-02-27 10:22:10.678927: Epoch 3
2025-02-27 10:22:10.681382: Current learning rate: 0.00973
2025-02-27 10:24:24.180072: train_loss -0.1076
2025-02-27 10:24:24.184951: val_loss -0.1341
2025-02-27 10:24:24.187372: Pseudo dice [0.0, 0.1409, 0.0, 0.5395]
2025-02-27 10:24:24.189918: Epoch time: 133.5 s
2025-02-27 10:24:24.192303: Yayy! New best EMA pseudo Dice: 0.0331
2025-02-27 10:24:28.165824: 
2025-02-27 10:24:28.168473: Epoch 4
2025-02-27 10:24:28.170383: Current learning rate: 0.00964
2025-02-27 10:26:49.299517: train_loss -0.1482
2025-02-27 10:26:49.303989: val_loss -0.1684
2025-02-27 10:26:49.306337: Pseudo dice [0.0, 0.007, 0.5491, 0.4446]
2025-02-27 10:26:49.308762: Epoch time: 141.13 s
2025-02-27 10:26:49.310813: Yayy! New best EMA pseudo Dice: 0.0548
2025-02-27 10:26:53.771956: 
2025-02-27 10:26:53.774555: Epoch 5
2025-02-27 10:26:53.777143: Current learning rate: 0.00955
2025-02-27 10:29:06.179691: train_loss -0.2032
2025-02-27 10:29:06.184810: val_loss -0.2254
2025-02-27 10:29:06.187458: Pseudo dice [0.2828, 0.3898, 0.676, 0.4777]
2025-02-27 10:29:06.190218: Epoch time: 132.41 s
2025-02-27 10:29:06.192535: Yayy! New best EMA pseudo Dice: 0.095
2025-02-27 10:29:10.778369: 
2025-02-27 10:29:10.944054: Epoch 6
2025-02-27 10:29:10.966928: Current learning rate: 0.00946
2025-02-27 10:31:13.792344: train_loss -0.2105
2025-02-27 10:31:13.796197: val_loss -0.2224
2025-02-27 10:31:13.798193: Pseudo dice [0.4233, 0.5288, 0.5644, 0.4353]
2025-02-27 10:31:13.800350: Epoch time: 123.02 s
2025-02-27 10:31:13.802118: Yayy! New best EMA pseudo Dice: 0.1343
2025-02-27 10:31:17.480615: 
2025-02-27 10:31:17.483033: Epoch 7
2025-02-27 10:31:17.485319: Current learning rate: 0.00937
2025-02-27 10:33:29.781875: train_loss -0.2352
2025-02-27 10:33:29.785510: val_loss -0.2417
2025-02-27 10:33:29.787849: Pseudo dice [0.4418, 0.5346, 0.6342, 0.4994]
2025-02-27 10:33:29.790353: Epoch time: 132.3 s
2025-02-27 10:33:29.792925: Yayy! New best EMA pseudo Dice: 0.1736
2025-02-27 10:33:34.328162: 
2025-02-27 10:33:34.330593: Epoch 8
2025-02-27 10:33:34.332885: Current learning rate: 0.00928
2025-02-27 10:35:43.212389: train_loss -0.2519
2025-02-27 10:35:43.216535: val_loss -0.2767
2025-02-27 10:35:43.218583: Pseudo dice [0.5352, 0.5722, 0.7169, 0.5401]
2025-02-27 10:35:43.220845: Epoch time: 128.89 s
2025-02-27 10:35:43.222564: Yayy! New best EMA pseudo Dice: 0.2153
2025-02-27 10:35:48.534209: 
2025-02-27 10:35:48.537035: Epoch 9
2025-02-27 10:35:48.539516: Current learning rate: 0.00919
2025-02-27 10:38:03.040951: train_loss -0.2711
2025-02-27 10:38:03.045832: val_loss -0.2711
2025-02-27 10:38:03.048563: Pseudo dice [0.4745, 0.5992, 0.6997, 0.3233]
2025-02-27 10:38:03.051111: Epoch time: 134.51 s
2025-02-27 10:38:03.053567: Yayy! New best EMA pseudo Dice: 0.2462
2025-02-27 10:38:06.784786: 
2025-02-27 10:38:06.787300: Epoch 10
2025-02-27 10:38:06.789163: Current learning rate: 0.0091
2025-02-27 10:40:16.696968: train_loss -0.2699
2025-02-27 10:40:16.700464: val_loss -0.2892
2025-02-27 10:40:16.702480: Pseudo dice [0.5116, 0.6173, 0.7419, 0.4414]
2025-02-27 10:40:16.704507: Epoch time: 129.91 s
2025-02-27 10:40:16.706512: Yayy! New best EMA pseudo Dice: 0.2794
2025-02-27 10:40:20.360371: 
2025-02-27 10:40:20.362799: Epoch 11
2025-02-27 10:40:20.364858: Current learning rate: 0.009
2025-02-27 10:42:36.222306: train_loss -0.2787
2025-02-27 10:42:36.226358: val_loss -0.3051
2025-02-27 10:42:36.228315: Pseudo dice [0.603, 0.6492, 0.701, 0.5244]
2025-02-27 10:42:36.230159: Epoch time: 135.86 s
2025-02-27 10:42:36.231964: Yayy! New best EMA pseudo Dice: 0.3134
2025-02-27 10:42:40.622667: 
2025-02-27 10:42:40.625010: Epoch 12
2025-02-27 10:42:40.626851: Current learning rate: 0.00891
2025-02-27 10:44:36.724730: train_loss -0.2872
2025-02-27 10:44:36.729111: val_loss -0.2952
2025-02-27 10:44:36.731726: Pseudo dice [0.5863, 0.6283, 0.7593, 0.4992]
2025-02-27 10:44:36.733869: Epoch time: 116.1 s
2025-02-27 10:44:36.736165: Yayy! New best EMA pseudo Dice: 0.3439
2025-02-27 10:44:40.734915: 
2025-02-27 10:44:40.737531: Epoch 13
2025-02-27 10:44:40.739354: Current learning rate: 0.00882
2025-02-27 10:46:45.621919: train_loss -0.3128
2025-02-27 10:46:45.624932: val_loss -0.2972
2025-02-27 10:46:45.626875: Pseudo dice [0.7338, 0.5138, 0.7475, 0.5464]
2025-02-27 10:46:45.628742: Epoch time: 124.89 s
2025-02-27 10:46:45.630750: Yayy! New best EMA pseudo Dice: 0.373
2025-02-27 10:46:49.878223: 
2025-02-27 10:46:49.880658: Epoch 14
2025-02-27 10:46:49.882532: Current learning rate: 0.00873
2025-02-27 10:48:52.061478: train_loss -0.3302
2025-02-27 10:48:52.064555: val_loss -0.3127
2025-02-27 10:48:52.066629: Pseudo dice [0.7089, 0.6005, 0.7557, 0.5649]
2025-02-27 10:48:52.068716: Epoch time: 122.18 s
2025-02-27 10:48:52.070605: Yayy! New best EMA pseudo Dice: 0.4015
2025-02-27 10:48:56.435854: 
2025-02-27 10:48:56.437844: Epoch 15
2025-02-27 10:48:56.439634: Current learning rate: 0.00864
2025-02-27 10:51:01.528022: train_loss -0.3241
2025-02-27 10:51:01.531613: val_loss -0.3021
2025-02-27 10:51:01.534144: Pseudo dice [0.6172, 0.6094, 0.6529, 0.5179]
2025-02-27 10:51:01.536765: Epoch time: 125.09 s
2025-02-27 10:51:01.538942: Yayy! New best EMA pseudo Dice: 0.4213
2025-02-27 10:51:05.526590: 
2025-02-27 10:51:05.529378: Epoch 16
2025-02-27 10:51:05.531517: Current learning rate: 0.00855
2025-02-27 10:53:07.282441: train_loss -0.3364
2025-02-27 10:53:07.286077: val_loss -0.3321
2025-02-27 10:53:07.288368: Pseudo dice [0.7414, 0.652, 0.8064, 0.5853]
2025-02-27 10:53:07.290707: Epoch time: 121.76 s
2025-02-27 10:53:07.292817: Yayy! New best EMA pseudo Dice: 0.4488
2025-02-27 10:53:11.152504: 
2025-02-27 10:53:11.154709: Epoch 17
2025-02-27 10:53:11.156187: Current learning rate: 0.00846
2025-02-27 10:55:11.564293: train_loss -0.3431
2025-02-27 10:55:11.568087: val_loss -0.3498
2025-02-27 10:55:11.570149: Pseudo dice [0.7368, 0.718, 0.7784, 0.606]
2025-02-27 10:55:11.572128: Epoch time: 120.41 s
2025-02-27 10:55:11.574046: Yayy! New best EMA pseudo Dice: 0.4749
2025-02-27 10:55:15.970123: 
2025-02-27 10:55:15.972942: Epoch 18
2025-02-27 10:55:15.975005: Current learning rate: 0.00836
2025-02-27 10:57:25.165216: train_loss -0.3485
2025-02-27 10:57:25.510797: val_loss -0.3404
2025-02-27 10:57:25.796859: Pseudo dice [0.7169, 0.6787, 0.8018, 0.5772]
2025-02-27 10:57:26.091881: Epoch time: 129.2 s
2025-02-27 10:57:26.341969: Yayy! New best EMA pseudo Dice: 0.4968
2025-02-27 10:57:30.789230: 
2025-02-27 10:57:30.791813: Epoch 19
2025-02-27 10:57:30.794062: Current learning rate: 0.00827
2025-02-27 10:59:30.453880: train_loss -0.348
2025-02-27 10:59:30.457555: val_loss -0.3312
2025-02-27 10:59:30.460277: Pseudo dice [0.6572, 0.6198, 0.8037, 0.6729]
2025-02-27 10:59:30.462665: Epoch time: 119.67 s
2025-02-27 10:59:30.464978: Yayy! New best EMA pseudo Dice: 0.5159
2025-02-27 10:59:34.230040: 
2025-02-27 10:59:34.232357: Epoch 20
2025-02-27 10:59:34.233996: Current learning rate: 0.00818
2025-02-27 11:01:31.793260: train_loss -0.3547
2025-02-27 11:01:31.797928: val_loss -0.3688
2025-02-27 11:01:31.800641: Pseudo dice [0.7781, 0.7307, 0.815, 0.6109]
2025-02-27 11:01:31.803158: Epoch time: 117.56 s
2025-02-27 11:01:31.805711: Yayy! New best EMA pseudo Dice: 0.5377
2025-02-27 11:01:35.885493: 
2025-02-27 11:01:35.887419: Epoch 21
2025-02-27 11:01:35.888971: Current learning rate: 0.00809
2025-02-27 11:03:44.124603: train_loss -0.3759
2025-02-27 11:03:44.129453: val_loss -0.3709
2025-02-27 11:03:44.131999: Pseudo dice [0.816, 0.7461, 0.8045, 0.5763]
2025-02-27 11:03:44.134264: Epoch time: 128.24 s
2025-02-27 11:03:44.136412: Yayy! New best EMA pseudo Dice: 0.5575
2025-02-27 11:03:48.479199: 
2025-02-27 11:03:48.482131: Epoch 22
2025-02-27 11:03:48.484044: Current learning rate: 0.008
2025-02-27 11:06:02.717636: train_loss -0.3681
2025-02-27 11:06:02.720976: val_loss -0.3736
2025-02-27 11:06:02.723299: Pseudo dice [0.8024, 0.7311, 0.8028, 0.6537]
2025-02-27 11:06:02.725734: Epoch time: 134.24 s
2025-02-27 11:06:02.727725: Yayy! New best EMA pseudo Dice: 0.5765
2025-02-27 11:06:06.366692: 
2025-02-27 11:06:06.369401: Epoch 23
2025-02-27 11:06:06.371497: Current learning rate: 0.0079
2025-02-27 11:08:09.135189: train_loss -0.3727
2025-02-27 11:08:09.140114: val_loss -0.3634
2025-02-27 11:08:09.142709: Pseudo dice [0.7849, 0.7616, 0.7789, 0.5101]
2025-02-27 11:08:09.145302: Epoch time: 122.77 s
2025-02-27 11:08:09.147654: Yayy! New best EMA pseudo Dice: 0.5897
2025-02-27 11:08:13.630133: 
2025-02-27 11:08:13.632534: Epoch 24
2025-02-27 11:08:13.634068: Current learning rate: 0.00781
2025-02-27 11:10:18.972592: train_loss -0.3725
2025-02-27 11:10:18.977343: val_loss -0.363
2025-02-27 11:10:18.979464: Pseudo dice [0.7381, 0.6862, 0.7689, 0.6234]
2025-02-27 11:10:18.981653: Epoch time: 125.34 s
2025-02-27 11:10:18.983704: Yayy! New best EMA pseudo Dice: 0.6012
2025-02-27 11:10:22.992906: 
2025-02-27 11:10:22.996085: Epoch 25
2025-02-27 11:10:22.998843: Current learning rate: 0.00772
2025-02-27 11:12:27.817986: train_loss -0.3804
2025-02-27 11:12:27.821138: val_loss -0.36
2025-02-27 11:12:27.822733: Pseudo dice [0.8393, 0.6734, 0.836, 0.6575]
2025-02-27 11:12:27.824276: Epoch time: 124.83 s
2025-02-27 11:12:27.825801: Yayy! New best EMA pseudo Dice: 0.6162
2025-02-27 11:12:32.766259: 
2025-02-27 11:12:32.768940: Epoch 26
2025-02-27 11:12:32.771468: Current learning rate: 0.00763
2025-02-27 11:14:39.458372: train_loss -0.3874
2025-02-27 11:14:39.462844: val_loss -0.3627
2025-02-27 11:14:39.465417: Pseudo dice [0.8371, 0.7174, 0.8221, 0.5201]
2025-02-27 11:14:39.467706: Epoch time: 126.69 s
2025-02-27 11:14:39.470188: Yayy! New best EMA pseudo Dice: 0.627
2025-02-27 11:14:43.448009: 
2025-02-27 11:14:43.450602: Epoch 27
2025-02-27 11:14:43.452939: Current learning rate: 0.00753
2025-02-27 11:16:53.939275: train_loss -0.3788
2025-02-27 11:16:53.944700: val_loss -0.3946
2025-02-27 11:16:53.946815: Pseudo dice [0.8382, 0.7515, 0.8544, 0.6403]
2025-02-27 11:16:53.949030: Epoch time: 130.49 s
2025-02-27 11:16:53.951043: Yayy! New best EMA pseudo Dice: 0.6414
2025-02-27 11:16:58.106977: 
2025-02-27 11:16:58.108664: Epoch 28
2025-02-27 11:16:58.110120: Current learning rate: 0.00744
2025-02-27 11:19:02.969789: train_loss -0.3926
2025-02-27 11:19:02.974667: val_loss -0.3823
2025-02-27 11:19:02.977290: Pseudo dice [0.8078, 0.7568, 0.8509, 0.6685]
2025-02-27 11:19:02.979440: Epoch time: 124.86 s
2025-02-27 11:19:02.981963: Yayy! New best EMA pseudo Dice: 0.6544
2025-02-27 11:19:06.917297: 
2025-02-27 11:19:06.919865: Epoch 29
2025-02-27 11:19:06.922198: Current learning rate: 0.00735
2025-02-27 11:21:18.480854: train_loss -0.3955
2025-02-27 11:21:18.485422: val_loss -0.3839
2025-02-27 11:21:18.487895: Pseudo dice [0.7944, 0.783, 0.8183, 0.6499]
2025-02-27 11:21:18.490302: Epoch time: 131.56 s
2025-02-27 11:21:18.493070: Yayy! New best EMA pseudo Dice: 0.6651
2025-02-27 11:21:22.248820: 
2025-02-27 11:21:22.250836: Epoch 30
2025-02-27 11:21:22.252656: Current learning rate: 0.00725
2025-02-27 11:23:33.190803: train_loss -0.3913
2025-02-27 11:23:33.195513: val_loss -0.4013
2025-02-27 11:23:33.198248: Pseudo dice [0.8524, 0.7653, 0.8365, 0.606]
2025-02-27 11:23:33.200641: Epoch time: 130.94 s
2025-02-27 11:23:33.202917: Yayy! New best EMA pseudo Dice: 0.6751
2025-02-27 11:23:37.611689: 
2025-02-27 11:23:37.614547: Epoch 31
2025-02-27 11:23:37.617094: Current learning rate: 0.00716
2025-02-27 11:25:51.108226: train_loss -0.405
2025-02-27 11:25:51.113468: val_loss -0.3977
2025-02-27 11:25:51.115578: Pseudo dice [0.822, 0.7652, 0.8305, 0.6732]
2025-02-27 11:25:51.118179: Epoch time: 133.5 s
2025-02-27 11:25:51.120735: Yayy! New best EMA pseudo Dice: 0.6848
2025-02-27 11:25:55.561363: 
2025-02-27 11:25:55.564010: Epoch 32
2025-02-27 11:25:55.566402: Current learning rate: 0.00707
2025-02-27 11:28:12.422636: train_loss -0.3986
2025-02-27 11:28:12.426966: val_loss -0.3649
2025-02-27 11:28:12.428923: Pseudo dice [0.8385, 0.688, 0.815, 0.6591]
2025-02-27 11:28:12.430911: Epoch time: 136.86 s
2025-02-27 11:28:12.432772: Yayy! New best EMA pseudo Dice: 0.6914
2025-02-27 11:28:16.891159: 
2025-02-27 11:28:16.893180: Epoch 33
2025-02-27 11:28:16.894718: Current learning rate: 0.00697
2025-02-27 11:30:37.775881: train_loss -0.3955
2025-02-27 11:30:37.779247: val_loss -0.36
2025-02-27 11:30:37.780737: Pseudo dice [0.8239, 0.7612, 0.8159, 0.6895]
2025-02-27 11:30:37.782079: Epoch time: 140.89 s
2025-02-27 11:30:37.783376: Yayy! New best EMA pseudo Dice: 0.6995
2025-02-27 11:30:42.123769: 
2025-02-27 11:30:42.125743: Epoch 34
2025-02-27 11:30:42.127436: Current learning rate: 0.00688
2025-02-27 11:32:59.306036: train_loss -0.3993
2025-02-27 11:32:59.310210: val_loss -0.3833
2025-02-27 11:32:59.312601: Pseudo dice [0.7899, 0.7742, 0.7911, 0.6588]
2025-02-27 11:32:59.314959: Epoch time: 137.18 s
2025-02-27 11:32:59.317303: Yayy! New best EMA pseudo Dice: 0.7049
2025-02-27 11:33:03.616328: 
2025-02-27 11:33:03.618832: Epoch 35
2025-02-27 11:33:03.621146: Current learning rate: 0.00679
2025-02-27 11:35:05.461291: train_loss -0.4032
2025-02-27 11:35:05.464235: val_loss -0.3992
2025-02-27 11:35:05.465502: Pseudo dice [0.8318, 0.7398, 0.8477, 0.6899]
2025-02-27 11:35:05.466727: Epoch time: 121.85 s
2025-02-27 11:35:05.467974: Yayy! New best EMA pseudo Dice: 0.7121
2025-02-27 11:35:09.982463: 
2025-02-27 11:35:09.984405: Epoch 36
2025-02-27 11:35:09.986210: Current learning rate: 0.00669
2025-02-27 11:37:28.889367: train_loss -0.4229
2025-02-27 11:37:28.892644: val_loss -0.432
2025-02-27 11:37:28.894833: Pseudo dice [0.8458, 0.8288, 0.8487, 0.7185]
2025-02-27 11:37:28.896621: Epoch time: 138.91 s
2025-02-27 11:37:28.898263: Yayy! New best EMA pseudo Dice: 0.722
2025-02-27 11:37:33.365054: 
2025-02-27 11:37:33.367161: Epoch 37
2025-02-27 11:37:33.369041: Current learning rate: 0.0066
2025-02-27 11:40:02.615676: train_loss -0.4172
2025-02-27 11:40:02.619116: val_loss -0.3551
2025-02-27 11:40:02.621293: Pseudo dice [0.8415, 0.7107, 0.8072, 0.4955]
2025-02-27 11:40:02.623755: Epoch time: 149.25 s
2025-02-27 11:40:05.308628: 
2025-02-27 11:40:05.311341: Epoch 38
2025-02-27 11:40:05.314001: Current learning rate: 0.0065
2025-02-27 11:42:30.693198: train_loss -0.4155
2025-02-27 11:42:30.696065: val_loss -0.4377
2025-02-27 11:42:30.698064: Pseudo dice [0.8603, 0.816, 0.8429, 0.6836]
2025-02-27 11:42:30.700024: Epoch time: 145.39 s
2025-02-27 11:42:30.701784: Yayy! New best EMA pseudo Dice: 0.7291
2025-02-27 11:42:34.467854: 
2025-02-27 11:42:34.469984: Epoch 39
2025-02-27 11:42:34.471581: Current learning rate: 0.00641
2025-02-27 11:44:57.753960: train_loss -0.4145
2025-02-27 11:44:57.757231: val_loss -0.4142
2025-02-27 11:44:57.759587: Pseudo dice [0.8167, 0.811, 0.8268, 0.7261]
2025-02-27 11:44:57.761672: Epoch time: 143.29 s
2025-02-27 11:44:57.763719: Yayy! New best EMA pseudo Dice: 0.7357
2025-02-27 11:45:02.361477: 
2025-02-27 11:45:02.363729: Epoch 40
2025-02-27 11:45:02.365800: Current learning rate: 0.00631
2025-02-27 11:47:12.697206: train_loss -0.4354
2025-02-27 11:47:12.701112: val_loss -0.3899
2025-02-27 11:47:12.703605: Pseudo dice [0.8638, 0.7931, 0.8719, 0.6572]
2025-02-27 11:47:12.706208: Epoch time: 130.34 s
2025-02-27 11:47:12.708787: Yayy! New best EMA pseudo Dice: 0.7418
2025-02-27 11:47:16.974920: 
2025-02-27 11:47:16.977621: Epoch 41
2025-02-27 11:47:16.980212: Current learning rate: 0.00622
2025-02-27 11:49:38.499980: train_loss -0.4259
2025-02-27 11:49:38.503383: val_loss -0.4067
2025-02-27 11:49:38.506310: Pseudo dice [0.8312, 0.7864, 0.8494, 0.6868]
2025-02-27 11:49:38.508540: Epoch time: 141.53 s
2025-02-27 11:49:38.510658: Yayy! New best EMA pseudo Dice: 0.7464
2025-02-27 11:49:43.149206: 
2025-02-27 11:49:43.164001: Epoch 42
2025-02-27 11:49:43.167207: Current learning rate: 0.00612
2025-02-27 11:52:10.900580: train_loss -0.4406
2025-02-27 11:52:10.903872: val_loss -0.4293
2025-02-27 11:52:10.906139: Pseudo dice [0.8223, 0.826, 0.8389, 0.7033]
2025-02-27 11:52:10.908362: Epoch time: 147.75 s
2025-02-27 11:52:10.922137: Yayy! New best EMA pseudo Dice: 0.7516
2025-02-27 11:52:14.832340: 
2025-02-27 11:52:14.834871: Epoch 43
2025-02-27 11:52:14.848341: Current learning rate: 0.00603
2025-02-27 11:54:31.552074: train_loss -0.4277
2025-02-27 11:54:31.555620: val_loss -0.426
2025-02-27 11:54:31.558445: Pseudo dice [0.8375, 0.8177, 0.8324, 0.7044]
2025-02-27 11:54:31.561038: Epoch time: 136.72 s
2025-02-27 11:54:31.563125: Yayy! New best EMA pseudo Dice: 0.7562
2025-02-27 11:54:36.042611: 
2025-02-27 11:54:36.060999: Epoch 44
2025-02-27 11:54:36.063570: Current learning rate: 0.00593
2025-02-27 11:57:00.147245: train_loss -0.4414
2025-02-27 11:57:00.151987: val_loss -0.3998
2025-02-27 11:57:00.154352: Pseudo dice [0.8699, 0.7805, 0.8503, 0.6424]
2025-02-27 11:57:00.156504: Epoch time: 144.11 s
2025-02-27 11:57:00.158629: Yayy! New best EMA pseudo Dice: 0.7592
2025-02-27 11:57:04.209206: 
2025-02-27 11:57:04.211904: Epoch 45
2025-02-27 11:57:04.214241: Current learning rate: 0.00584
2025-02-27 11:59:14.992644: train_loss -0.4441
2025-02-27 11:59:14.997662: val_loss -0.418
2025-02-27 11:59:15.000264: Pseudo dice [0.7698, 0.8267, 0.8146, 0.7605]
2025-02-27 11:59:15.002966: Epoch time: 130.79 s
2025-02-27 11:59:15.005385: Yayy! New best EMA pseudo Dice: 0.7625
2025-02-27 11:59:19.086005: 
2025-02-27 11:59:19.088897: Epoch 46
2025-02-27 11:59:19.091125: Current learning rate: 0.00574
2025-02-27 12:01:34.377774: train_loss -0.4419
2025-02-27 12:01:34.382804: val_loss -0.4152
2025-02-27 12:01:34.385618: Pseudo dice [0.8153, 0.7834, 0.8352, 0.686]
2025-02-27 12:01:34.387508: Epoch time: 135.29 s
2025-02-27 12:01:34.389646: Yayy! New best EMA pseudo Dice: 0.7643
2025-02-27 12:01:38.172390: 
2025-02-27 12:01:38.174749: Epoch 47
2025-02-27 12:01:38.176969: Current learning rate: 0.00565
2025-02-27 12:03:50.688338: train_loss -0.4268
2025-02-27 12:03:50.692270: val_loss -0.4198
2025-02-27 12:03:50.694473: Pseudo dice [0.8196, 0.7906, 0.8382, 0.7501]
2025-02-27 12:03:50.696935: Epoch time: 132.52 s
2025-02-27 12:03:50.699099: Yayy! New best EMA pseudo Dice: 0.7678
2025-02-27 12:03:54.383466: 
2025-02-27 12:03:54.385329: Epoch 48
2025-02-27 12:03:54.386893: Current learning rate: 0.00555
2025-02-27 12:06:16.072905: train_loss -0.4389
2025-02-27 12:06:16.075972: val_loss -0.4185
2025-02-27 12:06:16.078150: Pseudo dice [0.8261, 0.848, 0.8368, 0.7661]
2025-02-27 12:06:16.080158: Epoch time: 141.69 s
2025-02-27 12:06:16.081787: Yayy! New best EMA pseudo Dice: 0.773
2025-02-27 12:06:19.911132: 
2025-02-27 12:06:19.913024: Epoch 49
2025-02-27 12:06:19.914613: Current learning rate: 0.00546
2025-02-27 12:08:55.015872: train_loss -0.4416
2025-02-27 12:08:55.021734: val_loss -0.4419
2025-02-27 12:08:55.024108: Pseudo dice [0.8684, 0.8405, 0.8524, 0.7569]
2025-02-27 12:08:55.026523: Epoch time: 155.11 s
2025-02-27 12:08:57.372114: Yayy! New best EMA pseudo Dice: 0.7786
2025-02-27 12:09:01.551942: 
2025-02-27 12:09:01.553965: Epoch 50
2025-02-27 12:09:01.555679: Current learning rate: 0.00536
2025-02-27 12:11:15.488386: train_loss -0.4393
2025-02-27 12:11:15.492800: val_loss -0.3998
2025-02-27 12:11:15.495215: Pseudo dice [0.8697, 0.7793, 0.8672, 0.5867]
2025-02-27 12:11:15.497576: Epoch time: 133.94 s
2025-02-27 12:11:17.667953: 
2025-02-27 12:11:17.670632: Epoch 51
2025-02-27 12:11:17.673006: Current learning rate: 0.00526
2025-02-27 12:13:38.326124: train_loss -0.4548
2025-02-27 12:13:38.330180: val_loss -0.4216
2025-02-27 12:13:38.332477: Pseudo dice [0.8495, 0.7956, 0.8688, 0.6969]
2025-02-27 12:13:38.334881: Epoch time: 140.66 s
2025-02-27 12:13:38.337263: Yayy! New best EMA pseudo Dice: 0.7808
2025-02-27 12:13:42.853120: 
2025-02-27 12:13:42.855390: Epoch 52
2025-02-27 12:13:42.857380: Current learning rate: 0.00517
2025-02-27 12:15:54.366835: train_loss -0.4635
2025-02-27 12:15:54.370272: val_loss -0.4291
2025-02-27 12:15:54.372899: Pseudo dice [0.8646, 0.8147, 0.8716, 0.7232]
2025-02-27 12:15:54.375478: Epoch time: 131.52 s
2025-02-27 12:15:54.377765: Yayy! New best EMA pseudo Dice: 0.7845
2025-02-27 12:15:58.237111: 
2025-02-27 12:15:58.238968: Epoch 53
2025-02-27 12:15:58.240767: Current learning rate: 0.00507
2025-02-27 12:18:09.944001: train_loss -0.4569
2025-02-27 12:18:09.947331: val_loss -0.4313
2025-02-27 12:18:09.949639: Pseudo dice [0.8693, 0.8318, 0.8618, 0.7449]
2025-02-27 12:18:09.951609: Epoch time: 131.71 s
2025-02-27 12:18:09.953607: Yayy! New best EMA pseudo Dice: 0.7888
2025-02-27 12:18:14.360944: 
2025-02-27 12:18:14.362997: Epoch 54
2025-02-27 12:18:14.364526: Current learning rate: 0.00497
2025-02-27 12:20:34.656255: train_loss -0.4628
2025-02-27 12:20:34.659606: val_loss -0.4164
2025-02-27 12:20:34.662236: Pseudo dice [0.8803, 0.8418, 0.8723, 0.7189]
2025-02-27 12:20:34.664473: Epoch time: 140.3 s
2025-02-27 12:20:34.666844: Yayy! New best EMA pseudo Dice: 0.7927
2025-02-27 12:20:39.106610: 
2025-02-27 12:20:39.109376: Epoch 55
2025-02-27 12:20:39.111636: Current learning rate: 0.00487
2025-02-27 12:23:00.529467: train_loss -0.4503
2025-02-27 12:23:00.532889: val_loss -0.411
2025-02-27 12:23:00.535412: Pseudo dice [0.8492, 0.815, 0.8505, 0.7093]
2025-02-27 12:23:00.537690: Epoch time: 141.43 s
2025-02-27 12:23:00.539861: Yayy! New best EMA pseudo Dice: 0.7941
2025-02-27 12:23:04.664441: 
2025-02-27 12:23:04.666660: Epoch 56
2025-02-27 12:23:04.668355: Current learning rate: 0.00478
2025-02-27 12:25:12.353929: train_loss -0.4605
2025-02-27 12:25:12.357657: val_loss -0.4258
2025-02-27 12:25:12.360488: Pseudo dice [0.8592, 0.8421, 0.8463, 0.7417]
2025-02-27 12:25:12.363301: Epoch time: 127.69 s
2025-02-27 12:25:12.365970: Yayy! New best EMA pseudo Dice: 0.7969
2025-02-27 12:25:16.599098: 
2025-02-27 12:25:16.601923: Epoch 57
2025-02-27 12:25:16.604601: Current learning rate: 0.00468
2025-02-27 12:27:35.950680: train_loss -0.4572
2025-02-27 12:27:35.953655: val_loss -0.3975
2025-02-27 12:27:35.955556: Pseudo dice [0.852, 0.7691, 0.8475, 0.5812]
2025-02-27 12:27:35.957685: Epoch time: 139.35 s
2025-02-27 12:27:37.949626: 
2025-02-27 12:27:37.952226: Epoch 58
2025-02-27 12:27:37.954659: Current learning rate: 0.00458
2025-02-27 12:29:51.435069: train_loss -0.4568
2025-02-27 12:29:51.438122: val_loss -0.4245
2025-02-27 12:29:51.440036: Pseudo dice [0.8759, 0.8147, 0.8741, 0.6842]
2025-02-27 12:29:51.442019: Epoch time: 133.49 s
2025-02-27 12:29:52.831587: 
2025-02-27 12:29:52.833649: Epoch 59
2025-02-27 12:29:52.835144: Current learning rate: 0.00448
2025-02-27 12:32:13.636963: train_loss -0.4698
2025-02-27 12:32:13.640813: val_loss -0.4225
2025-02-27 12:32:13.642584: Pseudo dice [0.8425, 0.8412, 0.8588, 0.7426]
2025-02-27 12:32:13.644568: Epoch time: 140.81 s
2025-02-27 12:32:13.646360: Yayy! New best EMA pseudo Dice: 0.7979
2025-02-27 12:32:18.094816: 
2025-02-27 12:32:18.097652: Epoch 60
2025-02-27 12:32:18.099866: Current learning rate: 0.00438
2025-02-27 12:34:35.914923: train_loss -0.4699
2025-02-27 12:34:35.919268: val_loss -0.4201
2025-02-27 12:34:35.921811: Pseudo dice [0.8868, 0.8562, 0.8829, 0.7555]
2025-02-27 12:34:35.923944: Epoch time: 137.82 s
2025-02-27 12:34:35.926059: Yayy! New best EMA pseudo Dice: 0.8027
2025-02-27 12:34:40.167028: 
2025-02-27 12:34:40.169490: Epoch 61
2025-02-27 12:34:40.171495: Current learning rate: 0.00429
2025-02-27 12:36:53.736912: train_loss -0.4803
2025-02-27 12:36:53.741328: val_loss -0.4301
2025-02-27 12:36:53.744003: Pseudo dice [0.8721, 0.8285, 0.8851, 0.7712]
2025-02-27 12:36:53.746239: Epoch time: 133.57 s
2025-02-27 12:36:53.748316: Yayy! New best EMA pseudo Dice: 0.8063
2025-02-27 12:36:57.461585: 
2025-02-27 12:36:57.463828: Epoch 62
2025-02-27 12:36:57.465626: Current learning rate: 0.00419
2025-02-27 12:39:11.300390: train_loss -0.4683
2025-02-27 12:39:11.304195: val_loss -0.4199
2025-02-27 12:39:11.306141: Pseudo dice [0.8668, 0.8256, 0.8588, 0.7504]
2025-02-27 12:39:11.308296: Epoch time: 133.84 s
2025-02-27 12:39:11.310076: Yayy! New best EMA pseudo Dice: 0.8082
2025-02-27 12:39:16.505703: 
2025-02-27 12:39:16.508339: Epoch 63
2025-02-27 12:39:16.510257: Current learning rate: 0.00409
2025-02-27 12:41:37.681633: train_loss -0.465
2025-02-27 12:41:37.686109: val_loss -0.409
2025-02-27 12:41:37.688215: Pseudo dice [0.8516, 0.8338, 0.8558, 0.743]
2025-02-27 12:41:37.690457: Epoch time: 141.18 s
2025-02-27 12:41:37.692529: Yayy! New best EMA pseudo Dice: 0.8095
2025-02-27 12:41:41.492939: 
2025-02-27 12:41:41.495167: Epoch 64
2025-02-27 12:41:41.497397: Current learning rate: 0.00399
2025-02-27 12:44:04.263762: train_loss -0.475
2025-02-27 12:44:04.267396: val_loss -0.4251
2025-02-27 12:44:04.270030: Pseudo dice [0.8565, 0.8496, 0.8637, 0.744]
2025-02-27 12:44:04.272403: Epoch time: 142.77 s
2025-02-27 12:44:04.274355: Yayy! New best EMA pseudo Dice: 0.8114
2025-02-27 12:44:09.017306: 
2025-02-27 12:44:09.019540: Epoch 65
2025-02-27 12:44:09.021544: Current learning rate: 0.00389
2025-02-27 12:46:27.104284: train_loss -0.4737
2025-02-27 12:46:27.107734: val_loss -0.4409
2025-02-27 12:46:27.110428: Pseudo dice [0.8679, 0.8371, 0.8732, 0.689]
2025-02-27 12:46:27.112872: Epoch time: 138.09 s
2025-02-27 12:46:27.115172: Yayy! New best EMA pseudo Dice: 0.8119
2025-02-27 12:46:31.923631: 
2025-02-27 12:46:31.925736: Epoch 66
2025-02-27 12:46:31.927440: Current learning rate: 0.00379
2025-02-27 12:48:54.562567: train_loss -0.4724
2025-02-27 12:48:54.566232: val_loss -0.4275
2025-02-27 12:48:54.568859: Pseudo dice [0.8745, 0.8077, 0.8586, 0.7005]
2025-02-27 12:48:54.571205: Epoch time: 142.64 s
2025-02-27 12:48:56.740366: 
2025-02-27 12:48:56.743004: Epoch 67
2025-02-27 12:48:56.745277: Current learning rate: 0.00369
2025-02-27 12:51:29.798779: train_loss -0.4736
2025-02-27 12:51:29.802025: val_loss -0.4431
2025-02-27 12:51:29.803742: Pseudo dice [0.8664, 0.8524, 0.8632, 0.7221]
2025-02-27 12:51:29.805408: Epoch time: 153.06 s
2025-02-27 12:51:29.807000: Yayy! New best EMA pseudo Dice: 0.8132
2025-02-27 12:51:33.908777: 
2025-02-27 12:51:33.910903: Epoch 68
2025-02-27 12:51:33.912776: Current learning rate: 0.00359
2025-02-27 12:53:50.504887: train_loss -0.4649
2025-02-27 12:53:50.509329: val_loss -0.4292
2025-02-27 12:53:50.511358: Pseudo dice [0.865, 0.8357, 0.8635, 0.7541]
2025-02-27 12:53:50.513337: Epoch time: 136.6 s
2025-02-27 12:53:50.515332: Yayy! New best EMA pseudo Dice: 0.8148
2025-02-27 12:53:54.366208: 
2025-02-27 12:53:54.368819: Epoch 69
2025-02-27 12:53:54.370794: Current learning rate: 0.00349
2025-02-27 12:56:07.129980: train_loss -0.4647
2025-02-27 12:56:07.133216: val_loss -0.4342
2025-02-27 12:56:07.135089: Pseudo dice [0.8794, 0.8393, 0.8742, 0.7359]
2025-02-27 12:56:07.136709: Epoch time: 132.77 s
2025-02-27 12:56:07.138338: Yayy! New best EMA pseudo Dice: 0.8166
2025-02-27 12:56:11.625803: 
2025-02-27 12:56:11.627878: Epoch 70
2025-02-27 12:56:11.629966: Current learning rate: 0.00338
2025-02-27 12:58:24.757830: train_loss -0.4748
2025-02-27 12:58:24.760609: val_loss -0.4077
2025-02-27 12:58:24.761776: Pseudo dice [0.8815, 0.8511, 0.8723, 0.7313]
2025-02-27 12:58:24.762979: Epoch time: 133.13 s
2025-02-27 12:58:24.764231: Yayy! New best EMA pseudo Dice: 0.8183
2025-02-27 12:58:28.923283: 
2025-02-27 12:58:28.925897: Epoch 71
2025-02-27 12:58:28.928218: Current learning rate: 0.00328
2025-02-27 13:00:37.357242: train_loss -0.4809
2025-02-27 13:00:37.361488: val_loss -0.4343
2025-02-27 13:00:37.363508: Pseudo dice [0.8675, 0.8411, 0.8386, 0.7174]
2025-02-27 13:00:37.365398: Epoch time: 128.43 s
2025-02-27 13:00:38.865106: 
2025-02-27 13:00:38.867340: Epoch 72
2025-02-27 13:00:38.869346: Current learning rate: 0.00318
2025-02-27 13:02:50.658687: train_loss -0.4849
2025-02-27 13:02:50.662028: val_loss -0.4183
2025-02-27 13:02:50.664405: Pseudo dice [0.8748, 0.841, 0.8728, 0.7521]
2025-02-27 13:02:50.666472: Epoch time: 131.79 s
2025-02-27 13:02:50.668350: Yayy! New best EMA pseudo Dice: 0.8198
2025-02-27 13:02:54.583730: 
2025-02-27 13:02:54.585675: Epoch 73
2025-02-27 13:02:54.587000: Current learning rate: 0.00308
2025-02-27 13:05:01.287803: train_loss -0.4917
2025-02-27 13:05:01.290742: val_loss -0.427
2025-02-27 13:05:01.292824: Pseudo dice [0.8884, 0.8299, 0.8696, 0.7084]
2025-02-27 13:05:01.294880: Epoch time: 126.71 s
2025-02-27 13:05:01.296971: Yayy! New best EMA pseudo Dice: 0.8202
2025-02-27 13:05:05.084712: 
2025-02-27 13:05:05.086921: Epoch 74
2025-02-27 13:05:05.088758: Current learning rate: 0.00297
2025-02-27 13:07:27.781337: train_loss -0.4857
2025-02-27 13:07:27.785216: val_loss -0.4242
2025-02-27 13:07:27.787310: Pseudo dice [0.8687, 0.818, 0.863, 0.6718]
2025-02-27 13:07:27.789328: Epoch time: 142.7 s
2025-02-27 13:07:30.583383: 
2025-02-27 13:07:30.585872: Epoch 75
2025-02-27 13:07:30.587873: Current learning rate: 0.00287
2025-02-27 13:09:47.789127: train_loss -0.4813
2025-02-27 13:09:47.793296: val_loss -0.4393
2025-02-27 13:09:47.795541: Pseudo dice [0.8742, 0.8222, 0.8612, 0.7303]
2025-02-27 13:09:47.797834: Epoch time: 137.21 s
2025-02-27 13:09:50.034824: 
2025-02-27 13:09:50.037153: Epoch 76
2025-02-27 13:09:50.038889: Current learning rate: 0.00277
2025-02-27 13:12:08.983632: train_loss -0.4959
2025-02-27 13:12:08.988399: val_loss -0.4364
2025-02-27 13:12:08.990363: Pseudo dice [0.8724, 0.8311, 0.8502, 0.7083]
2025-02-27 13:12:08.992487: Epoch time: 138.95 s
2025-02-27 13:12:10.733288: 
2025-02-27 13:12:10.735993: Epoch 77
2025-02-27 13:12:10.738001: Current learning rate: 0.00266
2025-02-27 13:14:20.663125: train_loss -0.4974
2025-02-27 13:14:20.665891: val_loss -0.4412
2025-02-27 13:14:20.667285: Pseudo dice [0.8792, 0.8687, 0.8776, 0.7868]
2025-02-27 13:14:20.668549: Epoch time: 129.93 s
2025-02-27 13:14:20.669806: Yayy! New best EMA pseudo Dice: 0.8222
2025-02-27 13:14:25.184807: 
2025-02-27 13:14:25.187222: Epoch 78
2025-02-27 13:14:25.189176: Current learning rate: 0.00256
2025-02-27 13:16:41.476126: train_loss -0.4899
2025-02-27 13:16:41.479761: val_loss -0.4438
2025-02-27 13:16:41.482188: Pseudo dice [0.8853, 0.8414, 0.8766, 0.7379]
2025-02-27 13:16:41.484527: Epoch time: 136.29 s
2025-02-27 13:16:41.486517: Yayy! New best EMA pseudo Dice: 0.8235
2025-02-27 13:16:45.524804: 
2025-02-27 13:16:45.527317: Epoch 79
2025-02-27 13:16:45.529133: Current learning rate: 0.00245
2025-02-27 13:18:59.850032: train_loss -0.4978
2025-02-27 13:18:59.852239: val_loss -0.4437
2025-02-27 13:18:59.853487: Pseudo dice [0.8909, 0.8699, 0.8868, 0.7389]
2025-02-27 13:18:59.854775: Epoch time: 134.33 s
2025-02-27 13:18:59.857007: Yayy! New best EMA pseudo Dice: 0.8258
2025-02-27 13:19:03.654958: 
2025-02-27 13:19:03.657152: Epoch 80
2025-02-27 13:19:03.658933: Current learning rate: 0.00235
2025-02-27 13:21:16.277725: train_loss -0.4891
2025-02-27 13:21:16.281017: val_loss -0.46
2025-02-27 13:21:16.283198: Pseudo dice [0.8776, 0.8408, 0.871, 0.7127]
2025-02-27 13:21:16.285204: Epoch time: 132.62 s
2025-02-27 13:21:18.659530: 
2025-02-27 13:21:18.662113: Epoch 81
2025-02-27 13:21:18.664515: Current learning rate: 0.00224
2025-02-27 13:23:32.595098: train_loss -0.4863
2025-02-27 13:23:32.598510: val_loss -0.4353
2025-02-27 13:23:32.601097: Pseudo dice [0.8803, 0.8452, 0.8672, 0.7359]
2025-02-27 13:23:32.603063: Epoch time: 133.94 s
2025-02-27 13:23:32.605422: Yayy! New best EMA pseudo Dice: 0.8264
2025-02-27 13:23:36.554053: 
2025-02-27 13:23:36.555379: Epoch 82
2025-02-27 13:23:36.556776: Current learning rate: 0.00214
2025-02-27 13:25:59.424632: train_loss -0.4828
2025-02-27 13:25:59.428431: val_loss -0.4433
2025-02-27 13:25:59.431152: Pseudo dice [0.871, 0.8318, 0.8715, 0.6823]
2025-02-27 13:25:59.433846: Epoch time: 142.87 s
2025-02-27 13:26:01.572567: 
2025-02-27 13:26:01.575209: Epoch 83
2025-02-27 13:26:01.577524: Current learning rate: 0.00203
2025-02-27 13:28:22.716231: train_loss -0.4938
2025-02-27 13:28:22.721052: val_loss -0.4372
2025-02-27 13:28:22.723549: Pseudo dice [0.881, 0.8411, 0.8851, 0.7164]
2025-02-27 13:28:22.725920: Epoch time: 141.15 s
2025-02-27 13:28:24.675036: 
2025-02-27 13:28:24.677541: Epoch 84
2025-02-27 13:28:24.679549: Current learning rate: 0.00192
2025-02-27 13:30:47.760037: train_loss -0.4906
2025-02-27 13:30:47.764787: val_loss -0.4266
2025-02-27 13:30:47.767066: Pseudo dice [0.8788, 0.8241, 0.874, 0.7093]
2025-02-27 13:30:47.769601: Epoch time: 143.09 s
2025-02-27 13:30:49.824566: 
2025-02-27 13:30:49.827096: Epoch 85
2025-02-27 13:30:49.829526: Current learning rate: 0.00181
2025-02-27 13:33:08.165503: train_loss -0.4867
2025-02-27 13:33:08.170288: val_loss -0.4106
2025-02-27 13:33:08.172993: Pseudo dice [0.8747, 0.8092, 0.8661, 0.7143]
2025-02-27 13:33:08.175275: Epoch time: 138.34 s
2025-02-27 13:33:10.330480: 
2025-02-27 13:33:10.333163: Epoch 86
2025-02-27 13:33:10.335399: Current learning rate: 0.0017
2025-02-27 13:35:28.455667: train_loss -0.4964
2025-02-27 13:35:28.460453: val_loss -0.4554
2025-02-27 13:35:28.462372: Pseudo dice [0.8657, 0.8454, 0.8695, 0.7572]
2025-02-27 13:35:28.464410: Epoch time: 138.13 s
2025-02-27 13:35:30.566891: 
2025-02-27 13:35:30.569763: Epoch 87
2025-02-27 13:35:30.572241: Current learning rate: 0.00159
2025-02-27 13:37:47.471198: train_loss -0.4874
2025-02-27 13:37:47.476354: val_loss -0.4085
2025-02-27 13:37:47.478822: Pseudo dice [0.8843, 0.8063, 0.8687, 0.7035]
2025-02-27 13:37:47.481333: Epoch time: 136.91 s
2025-02-27 13:37:49.547643: 
2025-02-27 13:37:49.550341: Epoch 88
2025-02-27 13:37:49.552623: Current learning rate: 0.00148
2025-02-27 13:40:07.846532: train_loss -0.505
2025-02-27 13:40:07.851179: val_loss -0.4392
2025-02-27 13:40:07.853829: Pseudo dice [0.8769, 0.8465, 0.8581, 0.7432]
2025-02-27 13:40:07.856075: Epoch time: 138.3 s
2025-02-27 13:40:09.230234: 
2025-02-27 13:40:09.232979: Epoch 89
2025-02-27 13:40:09.234931: Current learning rate: 0.00137
2025-02-27 13:42:28.698937: train_loss -0.4983
2025-02-27 13:42:28.703205: val_loss -0.4419
2025-02-27 13:42:28.705419: Pseudo dice [0.8707, 0.8461, 0.8737, 0.7216]
2025-02-27 13:42:28.707221: Epoch time: 139.47 s
2025-02-27 13:42:30.747058: 
2025-02-27 13:42:30.749814: Epoch 90
2025-02-27 13:42:30.752126: Current learning rate: 0.00126
2025-02-27 13:44:45.369768: train_loss -0.494
2025-02-27 13:44:45.372542: val_loss -0.3969
2025-02-27 13:44:45.374268: Pseudo dice [0.8706, 0.8204, 0.8642, 0.7243]
2025-02-27 13:44:45.376705: Epoch time: 134.62 s
2025-02-27 13:44:47.591600: 
2025-02-27 13:44:47.594194: Epoch 91
2025-02-27 13:44:47.596652: Current learning rate: 0.00115
2025-02-27 13:47:02.465802: train_loss -0.4947
2025-02-27 13:47:02.469075: val_loss -0.4425
2025-02-27 13:47:02.471571: Pseudo dice [0.8709, 0.8527, 0.8758, 0.7469]
2025-02-27 13:47:02.474339: Epoch time: 134.88 s
2025-02-27 13:47:04.794635: 
2025-02-27 13:47:04.796334: Epoch 92
2025-02-27 13:47:04.797764: Current learning rate: 0.00103
2025-02-27 13:49:14.584131: train_loss -0.4987
2025-02-27 13:49:14.829907: val_loss -0.4326
2025-02-27 13:49:15.035602: Pseudo dice [0.8798, 0.846, 0.8638, 0.7411]
2025-02-27 13:49:15.196533: Epoch time: 129.79 s
2025-02-27 13:49:15.298092: Yayy! New best EMA pseudo Dice: 0.8267
2025-02-27 13:49:19.023405: 
2025-02-27 13:49:19.025447: Epoch 93
2025-02-27 13:49:19.027112: Current learning rate: 0.00091
2025-02-27 13:51:27.632700: train_loss -0.4979
2025-02-27 13:51:27.636242: val_loss -0.4608
2025-02-27 13:51:27.638099: Pseudo dice [0.8928, 0.8495, 0.8819, 0.697]
2025-02-27 13:51:27.640079: Epoch time: 128.61 s
2025-02-27 13:51:27.641989: Yayy! New best EMA pseudo Dice: 0.8271
2025-02-27 13:51:31.586057: 
2025-02-27 13:51:31.588005: Epoch 94
2025-02-27 13:51:31.589800: Current learning rate: 0.00079
2025-02-27 13:53:49.537895: train_loss -0.4966
2025-02-27 13:53:49.541802: val_loss -0.4515
2025-02-27 13:53:49.543533: Pseudo dice [0.8921, 0.8383, 0.8769, 0.6976]
2025-02-27 13:53:49.545604: Epoch time: 137.95 s
2025-02-27 13:53:51.598097: 
2025-02-27 13:53:51.601098: Epoch 95
2025-02-27 13:53:51.603479: Current learning rate: 0.00067
2025-02-27 13:56:07.174402: train_loss -0.503
2025-02-27 13:56:07.179657: val_loss -0.4634
2025-02-27 13:56:07.181582: Pseudo dice [0.8899, 0.8539, 0.881, 0.7318]
2025-02-27 13:56:07.184057: Epoch time: 135.58 s
2025-02-27 13:56:07.186166: Yayy! New best EMA pseudo Dice: 0.8282
2025-02-27 13:56:11.858942: 
2025-02-27 13:56:11.860856: Epoch 96
2025-02-27 13:56:11.862049: Current learning rate: 0.00055
2025-02-27 13:58:17.414766: train_loss -0.505
2025-02-27 13:58:17.418190: val_loss -0.4401
2025-02-27 13:58:17.419976: Pseudo dice [0.8717, 0.8519, 0.8531, 0.7051]
2025-02-27 13:58:17.421788: Epoch time: 125.56 s
2025-02-27 13:58:18.821704: 
2025-02-27 13:58:18.824123: Epoch 97
2025-02-27 13:58:18.826011: Current learning rate: 0.00043
2025-02-27 14:00:32.395449: train_loss -0.509
2025-02-27 14:00:32.400151: val_loss -0.4531
2025-02-27 14:00:32.402108: Pseudo dice [0.8799, 0.8472, 0.8604, 0.757]
2025-02-27 14:00:32.404286: Epoch time: 133.58 s
2025-02-27 14:00:32.406385: Yayy! New best EMA pseudo Dice: 0.8283
2025-02-27 14:00:36.257094: 
2025-02-27 14:00:36.259583: Epoch 98
2025-02-27 14:00:36.261882: Current learning rate: 0.0003
2025-02-27 14:02:53.098857: train_loss -0.5101
2025-02-27 14:02:53.103972: val_loss -0.4643
2025-02-27 14:02:53.106214: Pseudo dice [0.8813, 0.8746, 0.8896, 0.7134]
2025-02-27 14:02:53.108475: Epoch time: 136.84 s
2025-02-27 14:02:53.110442: Yayy! New best EMA pseudo Dice: 0.8294
2025-02-27 14:02:56.831757: 
2025-02-27 14:02:56.834352: Epoch 99
2025-02-27 14:02:56.836365: Current learning rate: 0.00016
2025-02-27 14:05:13.638034: train_loss -0.5081
2025-02-27 14:05:13.642818: val_loss -0.4471
2025-02-27 14:05:13.645551: Pseudo dice [0.8827, 0.8572, 0.868, 0.7507]
2025-02-27 14:05:13.647989: Epoch time: 136.81 s
2025-02-27 14:05:13.650313: Yayy! New best EMA pseudo Dice: 0.8304
2025-02-27 14:05:20.310188: Training done.
2025-02-27 14:05:20.358226: Using splits from existing split file: /home3/hghr96/parm/work/AD_project/segmentation/nnUNet/data/nnUNet_preprocessed/Dataset501_AD/splits_final.json
2025-02-27 14:05:20.362223: The split file contains 5 splits.
2025-02-27 14:05:20.364661: Desired fold for training: 4
2025-02-27 14:05:20.366762: This split has 71 training and 17 validation cases.
2025-02-27 14:05:20.369555: predicting ad_002
2025-02-27 14:05:20.374372: ad_002, shape torch.Size([1, 159, 205, 159]), rank 0
2025-02-27 14:05:32.083386: predicting ad_008
2025-02-27 14:05:32.091601: ad_008, shape torch.Size([1, 170, 266, 170]), rank 0
2025-02-27 14:09:07.051073: predicting ad_011
2025-02-27 14:09:07.060177: ad_011, shape torch.Size([1, 158, 233, 158]), rank 0
2025-02-27 14:12:51.567347: predicting ad_012
2025-02-27 14:12:51.580831: ad_012, shape torch.Size([1, 181, 215, 181]), rank 0
2025-02-27 14:16:49.527720: predicting ad_015
2025-02-27 14:16:49.539286: ad_015, shape torch.Size([1, 142, 285, 142]), rank 0
2025-02-27 14:19:55.167413: predicting ad_024
2025-02-27 14:19:55.218321: ad_024, shape torch.Size([1, 152, 232, 152]), rank 0
2025-02-27 14:24:52.729258: predicting ad_030
2025-02-27 14:24:52.740958: ad_030, shape torch.Size([1, 169, 274, 169]), rank 0
2025-02-27 14:28:58.186900: predicting ad_035
2025-02-27 14:28:58.197417: ad_035, shape torch.Size([1, 177, 280, 177]), rank 0
2025-02-27 14:33:50.167058: predicting ad_037
2025-02-27 14:33:50.180246: ad_037, shape torch.Size([1, 220, 303, 220]), rank 0
2025-02-27 14:39:51.538962: predicting ad_039
2025-02-27 14:39:51.551161: ad_039, shape torch.Size([1, 187, 334, 187]), rank 0
2025-02-27 14:52:20.282277: predicting ad_042
2025-02-27 14:52:20.296365: ad_042, shape torch.Size([1, 220, 281, 220]), rank 0
2025-02-27 14:58:18.743430: predicting ad_044
2025-02-27 14:58:18.757852: ad_044, shape torch.Size([1, 162, 300, 162]), rank 0
2025-02-27 15:04:24.988764: predicting ad_070
2025-02-27 15:04:25.001610: ad_070, shape torch.Size([1, 134, 265, 134]), rank 0
2025-02-27 15:10:44.075597: predicting ad_086
2025-02-27 15:10:44.089077: ad_086, shape torch.Size([1, 162, 219, 162]), rank 0
2025-02-27 15:17:04.625925: predicting ad_095
2025-02-27 15:17:04.635552: ad_095, shape torch.Size([1, 198, 344, 198]), rank 0
2025-02-27 15:20:05.707386: predicting ad_104
2025-02-27 15:20:05.720576: ad_104, shape torch.Size([1, 187, 318, 187]), rank 0
2025-02-27 15:26:43.400619: predicting ad_105
2025-02-27 15:26:43.415494: ad_105, shape torch.Size([1, 169, 281, 169]), rank 0
2025-02-27 15:37:59.542746: Validation complete
2025-02-27 15:37:59.545531: Mean Validation Dice:  0.5840996762060356
Finished at Thu 27 Feb 2025 03:38:01 PM GMT
Total Execution Time: 19542 seconds
