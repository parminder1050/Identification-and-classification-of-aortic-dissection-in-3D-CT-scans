Starting at Thu 20 Feb 2025 12:26:34 PM GMT

############################
INFO: You are using the old nnU-Net default plans. We have updated our recommendations. Please consider using those instead! Read more here: https://github.com/MIC-DKFZ/nnUNet/blob/master/documentation/resenc_presets.md
############################

Using device: cuda:0

#######################################################################
Please cite the following paper when using nnU-Net:
Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.
#######################################################################

2025-02-20 12:26:55.932072: do_dummy_2d_data_aug: False
2025-02-20 12:26:55.943953: Using splits from existing split file: /home3/hghr96/parm/work/AD_project/segmentation/nnUNet/data/nnUNet_preprocess/Dataset501_AD/splits_final.json
2025-02-20 12:26:55.948591: The split file contains 5 splits.
2025-02-20 12:26:55.950602: Desired fold for training: 1
2025-02-20 12:26:55.952980: This split has 70 training and 18 validation cases.
using pin_memory on device 0
/home3/hghr96/miniconda3/envs/nnUnet/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
using pin_memory on device 0

This is the configuration used by this training:
Configuration name: 3d_fullres
 {'data_identifier': 'nnUNetPlans_3d_fullres', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 2, 'patch_size': [112, 192, 112], 'median_image_size_in_voxels': [512.0, 834.0, 512.0], 'spacing': [0.78515625, 0.7000000476837158, 0.78515625], 'normalization_schemes': ['CTNormalization'], 'use_mask_for_norm': [False], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.PlainConvUNet', 'arch_kwargs': {'n_stages': 6, 'features_per_stage': [32, 64, 128, 256, 320, 320], 'conv_op': 'torch.nn.modules.conv.Conv3d', 'kernel_sizes': [[3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]], 'strides': [[1, 1, 1], [2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2], [1, 2, 1]], 'n_conv_per_stage': [2, 2, 2, 2, 2, 2], 'n_conv_per_stage_decoder': [2, 2, 2, 2, 2], 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm3d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}}, '_kw_requires_import': ['conv_op', 'norm_op', 'dropout_op', 'nonlin']}, 'batch_dice': True} 

These are the global plan.json settings:
 {'dataset_name': 'Dataset501_AD', 'plans_name': 'nnUNetPlans', 'original_median_spacing_after_transp': [0.78515625, 0.7000000476837158, 0.78515625], 'original_median_shape_after_transp': [512, 800, 512], 'image_reader_writer': 'SimpleITKIO', 'transpose_forward': [1, 0, 2], 'transpose_backward': [1, 0, 2], 'experiment_planner_used': 'ExperimentPlanner', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 3071.0, 'mean': 161.64767456054688, 'median': 182.0, 'min': -1103.0, 'percentile_00_5': -840.0, 'percentile_99_5': 778.0, 'std': 241.90689086914062}}} 

2025-02-20 12:27:13.095949: unpacking dataset...
2025-02-20 12:28:01.135822: unpacking done...
2025-02-20 12:28:01.225712: Unable to plot network architecture:
2025-02-20 12:28:01.238395: No module named 'hiddenlayer'
2025-02-20 12:28:01.405735: 
2025-02-20 12:28:01.416726: Epoch 0
2025-02-20 12:28:01.429060: Current learning rate: 0.01
2025-02-20 12:36:38.631623: train_loss 0.5316
2025-02-20 12:36:38.645906: val_loss 0.3804
2025-02-20 12:36:38.650759: Pseudo dice [0.0, 0.0, 0.0, 0.0]
2025-02-20 12:36:38.655699: Epoch time: 517.23 s
2025-02-20 12:36:38.660684: Yayy! New best EMA pseudo Dice: 0.0
2025-02-20 12:36:42.756204: 
2025-02-20 12:36:42.767904: Epoch 1
2025-02-20 12:36:42.776963: Current learning rate: 0.00991
2025-02-20 12:41:33.754393: train_loss 0.4003
2025-02-20 12:41:33.774252: val_loss 0.3397
2025-02-20 12:41:33.779057: Pseudo dice [0.0, 0.0, 0.0, 0.0]
2025-02-20 12:41:33.783975: Epoch time: 291.0 s
2025-02-20 12:41:35.547928: 
2025-02-20 12:41:35.555011: Epoch 2
2025-02-20 12:41:35.559124: Current learning rate: 0.00982
2025-02-20 12:45:55.232241: train_loss 0.357
2025-02-20 12:45:55.238728: val_loss 0.3107
2025-02-20 12:45:55.241718: Pseudo dice [0.0, 0.0, 0.0, 0.0]
2025-02-20 12:45:55.245306: Epoch time: 259.69 s
2025-02-20 12:45:56.804675: 
2025-02-20 12:45:56.810016: Epoch 3
2025-02-20 12:45:56.816464: Current learning rate: 0.00973
2025-02-20 12:50:26.288424: train_loss 0.2979
2025-02-20 12:50:26.298563: val_loss 0.2644
2025-02-20 12:50:26.302215: Pseudo dice [0.0, 0.0, 0.0, 0.0]
2025-02-20 12:50:26.306768: Epoch time: 269.49 s
2025-02-20 12:50:27.808364: 
2025-02-20 12:50:27.812685: Epoch 4
2025-02-20 12:50:27.817736: Current learning rate: 0.00964
2025-02-20 12:55:04.834672: train_loss 0.2981
2025-02-20 12:55:04.846827: val_loss 0.2739
2025-02-20 12:55:04.849739: Pseudo dice [0.0, 0.0, 0.0, 0.1485]
2025-02-20 12:55:04.853511: Epoch time: 277.03 s
2025-02-20 12:55:04.856030: Yayy! New best EMA pseudo Dice: 0.0037
2025-02-20 12:55:08.943859: 
2025-02-20 12:55:08.947757: Epoch 5
2025-02-20 12:55:08.950555: Current learning rate: 0.00955
2025-02-20 12:59:49.438504: train_loss 0.2659
2025-02-20 12:59:49.451267: val_loss 0.2492
2025-02-20 12:59:49.456385: Pseudo dice [0.0, 0.0084, 0.1067, 0.2438]
2025-02-20 12:59:49.462467: Epoch time: 280.5 s
2025-02-20 12:59:49.467909: Yayy! New best EMA pseudo Dice: 0.0123
2025-02-20 12:59:53.460396: 
2025-02-20 12:59:53.465127: Epoch 6
2025-02-20 12:59:53.472134: Current learning rate: 0.00946
2025-02-20 13:04:51.059563: train_loss 0.2434
2025-02-20 13:04:51.068300: val_loss 0.2206
2025-02-20 13:04:51.074599: Pseudo dice [0.0, 0.0031, 0.1352, 0.2469]
2025-02-20 13:04:51.081019: Epoch time: 297.6 s
2025-02-20 13:04:51.083558: Yayy! New best EMA pseudo Dice: 0.0207
2025-02-20 13:04:55.278959: 
2025-02-20 13:04:55.283291: Epoch 7
2025-02-20 13:04:55.285676: Current learning rate: 0.00937
2025-02-20 13:10:03.526126: train_loss 0.2019
2025-02-20 13:10:03.542670: val_loss 0.1514
2025-02-20 13:10:03.547644: Pseudo dice [0.0, 0.0, 0.1956, 0.3117]
2025-02-20 13:10:03.555125: Epoch time: 308.25 s
2025-02-20 13:10:03.560372: Yayy! New best EMA pseudo Dice: 0.0313
2025-02-20 13:10:07.787900: 
2025-02-20 13:10:07.790754: Epoch 8
2025-02-20 13:10:07.792956: Current learning rate: 0.00928
2025-02-20 13:14:43.166081: train_loss 0.2356
2025-02-20 13:14:43.177655: val_loss 0.2076
2025-02-20 13:14:43.182308: Pseudo dice [0.0, 0.0, 0.1567, 0.3653]
2025-02-20 13:14:43.189643: Epoch time: 275.38 s
2025-02-20 13:14:43.194652: Yayy! New best EMA pseudo Dice: 0.0412
2025-02-20 13:14:49.069438: 
2025-02-20 13:14:49.072187: Epoch 9
2025-02-20 13:14:49.077931: Current learning rate: 0.00919
2025-02-20 13:19:38.144720: train_loss 0.2125
2025-02-20 13:19:38.165006: val_loss 0.1951
2025-02-20 13:19:38.172340: Pseudo dice [0.0, 0.0, 0.2708, 0.3028]
2025-02-20 13:19:38.182573: Epoch time: 289.08 s
2025-02-20 13:19:38.190350: Yayy! New best EMA pseudo Dice: 0.0515
2025-02-20 13:19:42.635233: 
2025-02-20 13:19:42.637458: Epoch 10
2025-02-20 13:19:42.640680: Current learning rate: 0.0091
2025-02-20 13:24:27.267399: train_loss 0.1989
2025-02-20 13:24:27.284210: val_loss 0.1805
2025-02-20 13:24:27.287549: Pseudo dice [0.0, 0.0, 0.1658, 0.3143]
2025-02-20 13:24:27.293422: Epoch time: 284.63 s
2025-02-20 13:24:27.296095: Yayy! New best EMA pseudo Dice: 0.0583
2025-02-20 13:24:31.383915: 
2025-02-20 13:24:31.388455: Epoch 11
2025-02-20 13:24:31.395471: Current learning rate: 0.009
2025-02-20 13:29:27.547513: train_loss 0.2032
2025-02-20 13:29:27.558878: val_loss 0.1319
2025-02-20 13:29:27.565065: Pseudo dice [0.0, 0.0002, 0.2095, 0.3926]
2025-02-20 13:29:27.570879: Epoch time: 296.16 s
2025-02-20 13:29:27.578763: Yayy! New best EMA pseudo Dice: 0.0675
2025-02-20 13:29:31.491289: 
2025-02-20 13:29:31.499652: Epoch 12
2025-02-20 13:29:31.504141: Current learning rate: 0.00891
2025-02-20 13:34:24.040530: train_loss 0.1489
2025-02-20 13:34:24.075093: val_loss 0.1482
2025-02-20 13:34:24.079898: Pseudo dice [0.0428, 0.24, 0.3437, 0.4671]
2025-02-20 13:34:24.082971: Epoch time: 292.55 s
2025-02-20 13:34:24.086046: Yayy! New best EMA pseudo Dice: 0.0881
2025-02-20 13:34:28.074024: 
2025-02-20 13:34:28.079938: Epoch 13
2025-02-20 13:34:28.089089: Current learning rate: 0.00882
2025-02-20 13:39:04.278719: train_loss 0.1436
2025-02-20 13:39:04.289262: val_loss 0.1502
2025-02-20 13:39:04.293281: Pseudo dice [0.0, 0.0043, 0.27, 0.3976]
2025-02-20 13:39:04.311080: Epoch time: 276.2 s
2025-02-20 13:39:04.317333: Yayy! New best EMA pseudo Dice: 0.0961
2025-02-20 13:39:08.369406: 
2025-02-20 13:39:08.373821: Epoch 14
2025-02-20 13:39:08.378515: Current learning rate: 0.00873
2025-02-20 13:43:57.161413: train_loss 0.1496
2025-02-20 13:43:57.168671: val_loss 0.0766
2025-02-20 13:43:57.171975: Pseudo dice [0.0, 0.0, 0.3408, 0.37]
2025-02-20 13:43:57.175050: Epoch time: 288.79 s
2025-02-20 13:43:57.178424: Yayy! New best EMA pseudo Dice: 0.1043
2025-02-20 13:44:03.872075: 
2025-02-20 13:44:03.874637: Epoch 15
2025-02-20 13:44:03.884908: Current learning rate: 0.00864
2025-02-20 13:49:03.336965: train_loss 0.1166
2025-02-20 13:49:03.371138: val_loss 0.0815
2025-02-20 13:49:03.376197: Pseudo dice [0.4371, 0.0, 0.4197, 0.4006]
2025-02-20 13:49:03.384965: Epoch time: 299.47 s
2025-02-20 13:49:03.390476: Yayy! New best EMA pseudo Dice: 0.1253
2025-02-20 13:49:07.855134: 
2025-02-20 13:49:07.857662: Epoch 16
2025-02-20 13:49:07.860138: Current learning rate: 0.00855
2025-02-20 13:53:57.571151: train_loss 0.1125
2025-02-20 13:53:57.582746: val_loss 0.0578
2025-02-20 13:53:57.589518: Pseudo dice [0.0, 0.0778, 0.6039, 0.4432]
2025-02-20 13:53:57.595027: Epoch time: 289.72 s
2025-02-20 13:53:57.600447: Yayy! New best EMA pseudo Dice: 0.1409
2025-02-20 13:54:01.741643: 
2025-02-20 13:54:01.744857: Epoch 17
2025-02-20 13:54:01.748210: Current learning rate: 0.00846
2025-02-20 13:58:50.286970: train_loss 0.1684
2025-02-20 13:58:50.300274: val_loss 0.122
2025-02-20 13:58:50.305266: Pseudo dice [0.0, 0.0219, 0.3947, 0.3677]
2025-02-20 13:58:50.311463: Epoch time: 288.55 s
2025-02-20 13:58:50.317237: Yayy! New best EMA pseudo Dice: 0.1464
2025-02-20 13:58:54.383320: 
2025-02-20 13:58:54.388448: Epoch 18
2025-02-20 13:58:54.394531: Current learning rate: 0.00836
2025-02-20 14:03:52.881430: train_loss 0.1231
2025-02-20 14:03:52.893388: val_loss 0.0845
2025-02-20 14:03:52.897068: Pseudo dice [0.0, 0.0, 0.4228, 0.4538]
2025-02-20 14:03:52.902730: Epoch time: 298.5 s
2025-02-20 14:03:52.908363: Yayy! New best EMA pseudo Dice: 0.1537
2025-02-20 14:03:56.930246: 
2025-02-20 14:03:56.936339: Epoch 19
2025-02-20 14:03:56.942715: Current learning rate: 0.00827
2025-02-20 14:08:27.790279: train_loss 0.1141
2025-02-20 14:08:27.810570: val_loss 0.0247
2025-02-20 14:08:27.816799: Pseudo dice [0.0, 0.2742, 0.5514, 0.5316]
2025-02-20 14:08:27.825701: Epoch time: 270.86 s
2025-02-20 14:08:27.831982: Yayy! New best EMA pseudo Dice: 0.1722
2025-02-20 14:08:31.896166: 
2025-02-20 14:08:31.901980: Epoch 20
2025-02-20 14:08:31.908279: Current learning rate: 0.00818
2025-02-20 14:13:27.295017: train_loss 0.0676
2025-02-20 14:13:27.305088: val_loss 0.0187
2025-02-20 14:13:27.311124: Pseudo dice [0.0, 0.1026, 0.5051, 0.4481]
2025-02-20 14:13:27.317113: Epoch time: 295.4 s
2025-02-20 14:13:27.329723: Yayy! New best EMA pseudo Dice: 0.1814
2025-02-20 14:13:31.469181: 
2025-02-20 14:13:31.474820: Epoch 21
2025-02-20 14:13:31.481263: Current learning rate: 0.00809
2025-02-20 14:17:55.576071: train_loss 0.0768
2025-02-20 14:17:55.582966: val_loss 0.072
2025-02-20 14:17:55.586141: Pseudo dice [0.3336, 0.0217, 0.4646, 0.4307]
2025-02-20 14:17:55.589341: Epoch time: 264.11 s
2025-02-20 14:17:55.592506: Yayy! New best EMA pseudo Dice: 0.1945
2025-02-20 14:18:01.476345: 
2025-02-20 14:18:01.482202: Epoch 22
2025-02-20 14:18:01.488457: Current learning rate: 0.008
2025-02-20 14:22:21.219773: train_loss 0.0846
2025-02-20 14:22:21.230157: val_loss 0.0667
2025-02-20 14:22:21.235664: Pseudo dice [0.0, 0.0448, 0.5346, 0.3909]
2025-02-20 14:22:21.240176: Epoch time: 259.74 s
2025-02-20 14:22:21.245451: Yayy! New best EMA pseudo Dice: 0.1993
2025-02-20 14:22:26.634304: 
2025-02-20 14:22:26.638471: Epoch 23
2025-02-20 14:22:26.646037: Current learning rate: 0.0079
2025-02-20 14:26:59.114806: train_loss 0.0656
2025-02-20 14:26:59.119754: val_loss 0.0172
2025-02-20 14:26:59.123048: Pseudo dice [0.3062, 0.0531, 0.5194, 0.2948]
2025-02-20 14:26:59.126236: Epoch time: 272.48 s
2025-02-20 14:26:59.129397: Yayy! New best EMA pseudo Dice: 0.2087
2025-02-20 14:27:03.038164: 
2025-02-20 14:27:03.040742: Epoch 24
2025-02-20 14:27:03.044757: Current learning rate: 0.00781
2025-02-20 14:32:09.976291: train_loss 0.0322
2025-02-20 14:32:09.998892: val_loss -0.0159
2025-02-20 14:32:10.005362: Pseudo dice [0.1807, 0.433, 0.5427, 0.4768]
2025-02-20 14:32:10.013290: Epoch time: 306.94 s
2025-02-20 14:32:10.019894: Yayy! New best EMA pseudo Dice: 0.2287
2025-02-20 14:32:14.018332: 
2025-02-20 14:32:14.020506: Epoch 25
2025-02-20 14:32:14.037212: Current learning rate: 0.00772
2025-02-20 14:36:46.671144: train_loss 0.0461
2025-02-20 14:36:46.676984: val_loss 0.0418
2025-02-20 14:36:46.680614: Pseudo dice [0.2222, 0.1175, 0.4822, 0.4299]
2025-02-20 14:36:46.683661: Epoch time: 272.65 s
2025-02-20 14:36:46.687818: Yayy! New best EMA pseudo Dice: 0.2371
2025-02-20 14:36:50.636923: 
2025-02-20 14:36:50.643366: Epoch 26
2025-02-20 14:36:50.649749: Current learning rate: 0.00763
2025-02-20 14:41:30.177911: train_loss 0.0548
2025-02-20 14:41:30.188563: val_loss 0.0409
2025-02-20 14:41:30.192408: Pseudo dice [0.4285, 0.1733, 0.5789, 0.4341]
2025-02-20 14:41:30.206275: Epoch time: 279.54 s
2025-02-20 14:41:30.211321: Yayy! New best EMA pseudo Dice: 0.2538
2025-02-20 14:41:35.465777: 
2025-02-20 14:41:35.468820: Epoch 27
2025-02-20 14:41:35.472991: Current learning rate: 0.00753
2025-02-20 14:46:18.205149: train_loss 0.0385
2025-02-20 14:46:18.213436: val_loss 0.0299
2025-02-20 14:46:18.217871: Pseudo dice [0.0, 0.335, 0.3925, 0.4896]
2025-02-20 14:46:18.221890: Epoch time: 282.74 s
2025-02-20 14:46:18.250673: Yayy! New best EMA pseudo Dice: 0.2588
2025-02-20 14:46:22.146421: 
2025-02-20 14:46:22.157029: Epoch 28
2025-02-20 14:46:22.163248: Current learning rate: 0.00744
2025-02-20 14:51:05.294640: train_loss 0.0385
2025-02-20 14:51:05.314487: val_loss 0.0789
2025-02-20 14:51:05.320325: Pseudo dice [0.0, 0.1799, 0.433, 0.5411]
2025-02-20 14:51:05.329393: Epoch time: 283.15 s
2025-02-20 14:51:05.335917: Yayy! New best EMA pseudo Dice: 0.2618
2025-02-20 14:51:12.544306: 
2025-02-20 14:51:12.546314: Epoch 29
2025-02-20 14:51:12.548166: Current learning rate: 0.00735
2025-02-20 14:55:44.455674: train_loss 0.0198
2025-02-20 14:55:44.474876: val_loss -0.0299
2025-02-20 14:55:44.480573: Pseudo dice [0.0, 0.0762, 0.5631, 0.4489]
2025-02-20 14:55:44.484754: Epoch time: 271.91 s
2025-02-20 14:55:44.487749: Yayy! New best EMA pseudo Dice: 0.2628
2025-02-20 14:55:48.551624: 
2025-02-20 14:55:48.557269: Epoch 30
2025-02-20 14:55:48.560047: Current learning rate: 0.00725
2025-02-20 15:00:26.150353: train_loss 0.0285
2025-02-20 15:00:26.164688: val_loss -0.0429
2025-02-20 15:00:26.170022: Pseudo dice [0.0535, 0.4779, 0.4647, 0.4416]
2025-02-20 15:00:26.179030: Epoch time: 277.6 s
2025-02-20 15:00:26.185236: Yayy! New best EMA pseudo Dice: 0.2725
2025-02-20 15:00:30.297125: 
2025-02-20 15:00:30.305718: Epoch 31
2025-02-20 15:00:30.314362: Current learning rate: 0.00716
2025-02-20 15:05:15.826738: train_loss 0.0268
2025-02-20 15:05:15.839003: val_loss -0.0442
2025-02-20 15:05:15.843540: Pseudo dice [0.0, 0.6025, 0.6587, 0.4185]
2025-02-20 15:05:15.846788: Epoch time: 285.53 s
2025-02-20 15:05:15.851444: Yayy! New best EMA pseudo Dice: 0.2872
2025-02-20 15:05:19.822519: 
2025-02-20 15:05:19.827936: Epoch 32
2025-02-20 15:05:19.832062: Current learning rate: 0.00707
2025-02-20 15:10:01.252848: train_loss 0.0187
2025-02-20 15:10:01.267045: val_loss -0.0534
2025-02-20 15:10:01.270720: Pseudo dice [0.4666, 0.6384, 0.6612, 0.3807]
2025-02-20 15:10:01.272921: Epoch time: 281.43 s
2025-02-20 15:10:01.275516: Yayy! New best EMA pseudo Dice: 0.3122
2025-02-20 15:10:05.459285: 
2025-02-20 15:10:05.464326: Epoch 33
2025-02-20 15:10:05.470762: Current learning rate: 0.00697
2025-02-20 15:15:02.651201: train_loss 0.0235
2025-02-20 15:15:02.664464: val_loss -0.0014
2025-02-20 15:15:02.668124: Pseudo dice [0.3358, 0.4602, 0.6733, 0.427]
2025-02-20 15:15:02.674049: Epoch time: 297.19 s
2025-02-20 15:15:02.677047: Yayy! New best EMA pseudo Dice: 0.3284
2025-02-20 15:15:06.883140: 
2025-02-20 15:15:06.885660: Epoch 34
2025-02-20 15:15:06.887504: Current learning rate: 0.00688
2025-02-20 15:19:56.452450: train_loss 0.0246
2025-02-20 15:19:56.471160: val_loss -0.0329
2025-02-20 15:19:56.475527: Pseudo dice [0.0065, 0.6061, 0.536, 0.4327]
2025-02-20 15:19:56.484511: Epoch time: 289.57 s
2025-02-20 15:19:56.491943: Yayy! New best EMA pseudo Dice: 0.3351
2025-02-20 15:20:02.762403: 
2025-02-20 15:20:02.766768: Epoch 35
2025-02-20 15:20:02.770190: Current learning rate: 0.00679
2025-02-20 15:24:48.789745: train_loss -0.0044
2025-02-20 15:24:48.825148: val_loss -0.0846
2025-02-20 15:24:48.831569: Pseudo dice [0.103, 0.4658, 0.6986, 0.5735]
2025-02-20 15:24:48.841604: Epoch time: 286.03 s
2025-02-20 15:24:48.849187: Yayy! New best EMA pseudo Dice: 0.3476
2025-02-20 15:24:52.830508: 
2025-02-20 15:24:52.833153: Epoch 36
2025-02-20 15:24:52.836116: Current learning rate: 0.00669
2025-02-20 15:29:25.928534: train_loss -0.019
2025-02-20 15:29:25.944116: val_loss -0.023
2025-02-20 15:29:25.948940: Pseudo dice [0.5144, 0.4135, 0.5816, 0.4795]
2025-02-20 15:29:25.957204: Epoch time: 273.1 s
2025-02-20 15:29:25.959505: Yayy! New best EMA pseudo Dice: 0.3625
2025-02-20 15:29:30.033265: 
2025-02-20 15:29:30.035869: Epoch 37
2025-02-20 15:29:30.042054: Current learning rate: 0.0066
2025-02-20 15:34:10.602280: train_loss -0.011
2025-02-20 15:34:10.613525: val_loss -0.0339
2025-02-20 15:34:10.618568: Pseudo dice [0.3961, 0.5942, 0.6535, 0.5556]
2025-02-20 15:34:10.624161: Epoch time: 280.57 s
2025-02-20 15:34:10.628188: Yayy! New best EMA pseudo Dice: 0.3813
2025-02-20 15:34:14.910875: 
2025-02-20 15:34:14.915254: Epoch 38
2025-02-20 15:34:14.920941: Current learning rate: 0.0065
2025-02-20 15:38:49.044134: train_loss 0.0077
2025-02-20 15:38:49.062768: val_loss -0.0191
2025-02-20 15:38:49.068989: Pseudo dice [0.0, 0.563, 0.5641, 0.4079]
2025-02-20 15:38:49.076714: Epoch time: 274.13 s
2025-02-20 15:38:49.081671: Yayy! New best EMA pseudo Dice: 0.3815
2025-02-20 15:38:53.392960: 
2025-02-20 15:38:53.400139: Epoch 39
2025-02-20 15:38:53.421195: Current learning rate: 0.00641
2025-02-20 15:43:30.242316: train_loss -0.0205
2025-02-20 15:43:30.246750: val_loss -0.0711
2025-02-20 15:43:30.249113: Pseudo dice [0.1557, 0.6551, 0.6448, 0.4568]
2025-02-20 15:43:30.251693: Epoch time: 276.85 s
2025-02-20 15:43:30.255156: Yayy! New best EMA pseudo Dice: 0.3912
2025-02-20 15:43:34.394517: 
2025-02-20 15:43:34.397255: Epoch 40
2025-02-20 15:43:34.399444: Current learning rate: 0.00631
2025-02-20 15:48:11.039142: train_loss -0.0238
2025-02-20 15:48:11.060913: val_loss -0.0634
2025-02-20 15:48:11.069795: Pseudo dice [0.5727, 0.3781, 0.746, 0.4758]
2025-02-20 15:48:11.079974: Epoch time: 276.65 s
2025-02-20 15:48:11.090250: Yayy! New best EMA pseudo Dice: 0.4064
2025-02-20 15:48:16.358733: 
2025-02-20 15:48:16.365193: Epoch 41
2025-02-20 15:48:16.371685: Current learning rate: 0.00622
2025-02-20 15:52:49.545532: train_loss -0.048
2025-02-20 15:52:49.606752: val_loss -0.0819
2025-02-20 15:52:49.613394: Pseudo dice [0.5257, 0.5344, 0.651, 0.6031]
2025-02-20 15:52:49.620419: Epoch time: 273.19 s
2025-02-20 15:52:49.623971: Yayy! New best EMA pseudo Dice: 0.4236
2025-02-20 15:52:53.683279: 
2025-02-20 15:52:53.688091: Epoch 42
2025-02-20 15:52:53.691909: Current learning rate: 0.00612
2025-02-20 15:57:32.690916: train_loss -0.0473
2025-02-20 15:57:32.710929: val_loss -0.0728
2025-02-20 15:57:32.719049: Pseudo dice [0.4168, 0.5768, 0.6822, 0.5725]
2025-02-20 15:57:32.728974: Epoch time: 279.01 s
2025-02-20 15:57:32.735513: Yayy! New best EMA pseudo Dice: 0.4374
2025-02-20 15:57:36.677878: 
2025-02-20 15:57:36.681129: Epoch 43
2025-02-20 15:57:36.683993: Current learning rate: 0.00603
2025-02-20 16:02:11.167252: train_loss -0.0358
2025-02-20 16:02:11.178645: val_loss -0.0639
2025-02-20 16:02:11.184692: Pseudo dice [0.1372, 0.6585, 0.544, 0.4208]
2025-02-20 16:02:11.191345: Epoch time: 274.49 s
2025-02-20 16:02:11.197309: Yayy! New best EMA pseudo Dice: 0.4377
2025-02-20 16:02:15.463143: 
2025-02-20 16:02:15.470908: Epoch 44
2025-02-20 16:02:15.476248: Current learning rate: 0.00593
2025-02-20 16:07:06.974175: train_loss -0.0228
2025-02-20 16:07:06.992044: val_loss -0.0502
2025-02-20 16:07:06.999201: Pseudo dice [0.5415, 0.4791, 0.6301, 0.4195]
2025-02-20 16:07:07.007948: Epoch time: 291.51 s
2025-02-20 16:07:07.015568: Yayy! New best EMA pseudo Dice: 0.4457
2025-02-20 16:07:11.374218: 
2025-02-20 16:07:11.376403: Epoch 45
2025-02-20 16:07:11.381675: Current learning rate: 0.00584
2025-02-20 16:11:56.116072: train_loss -0.0404
2025-02-20 16:11:56.128542: val_loss -0.0245
2025-02-20 16:11:56.135681: Pseudo dice [0.117, 0.581, 0.5802, 0.5196]
2025-02-20 16:11:56.141248: Epoch time: 284.74 s
2025-02-20 16:11:56.145464: Yayy! New best EMA pseudo Dice: 0.4461
2025-02-20 16:12:00.088807: 
2025-02-20 16:12:00.102269: Epoch 46
2025-02-20 16:12:00.106014: Current learning rate: 0.00574
2025-02-20 16:16:27.863711: train_loss -0.0439
2025-02-20 16:16:27.871898: val_loss -0.1017
2025-02-20 16:16:27.874262: Pseudo dice [0.1226, 0.6721, 0.6666, 0.5881]
2025-02-20 16:16:27.877302: Epoch time: 267.78 s
2025-02-20 16:16:27.879294: Yayy! New best EMA pseudo Dice: 0.4527
2025-02-20 16:16:31.691956: 
2025-02-20 16:16:31.694449: Epoch 47
2025-02-20 16:16:31.695899: Current learning rate: 0.00565
2025-02-20 16:20:58.103492: train_loss -0.0213
2025-02-20 16:20:58.114787: val_loss -0.0676
2025-02-20 16:20:58.120305: Pseudo dice [0.5952, 0.6699, 0.6003, 0.5426]
2025-02-20 16:20:58.124799: Epoch time: 266.41 s
2025-02-20 16:20:58.129125: Yayy! New best EMA pseudo Dice: 0.4676
2025-02-20 16:21:04.454725: 
2025-02-20 16:21:04.457417: Epoch 48
2025-02-20 16:21:04.461957: Current learning rate: 0.00555
2025-02-20 16:25:31.634335: train_loss -0.0372
2025-02-20 16:25:31.654968: val_loss -0.1027
2025-02-20 16:25:31.658143: Pseudo dice [0.4458, 0.6973, 0.6325, 0.5056]
2025-02-20 16:25:31.666061: Epoch time: 267.18 s
2025-02-20 16:25:31.668799: Yayy! New best EMA pseudo Dice: 0.4779
2025-02-20 16:25:35.476233: 
2025-02-20 16:25:35.480618: Epoch 49
2025-02-20 16:25:35.484822: Current learning rate: 0.00546
2025-02-20 16:30:03.600594: train_loss -0.052
2025-02-20 16:30:03.613629: val_loss -0.0619
2025-02-20 16:30:03.619723: Pseudo dice [0.6005, 0.404, 0.7662, 0.4188]
2025-02-20 16:30:03.627878: Epoch time: 268.13 s
2025-02-20 16:30:06.268096: Yayy! New best EMA pseudo Dice: 0.4848
2025-02-20 16:30:10.160081: 
2025-02-20 16:30:10.165189: Epoch 50
2025-02-20 16:30:10.168861: Current learning rate: 0.00536
2025-02-20 16:34:53.403257: train_loss -0.0436
2025-02-20 16:34:53.421910: val_loss -0.1057
2025-02-20 16:34:53.428050: Pseudo dice [0.7006, 0.6381, 0.7326, 0.5864]
2025-02-20 16:34:53.437018: Epoch time: 283.24 s
2025-02-20 16:34:53.443815: Yayy! New best EMA pseudo Dice: 0.5028
2025-02-20 16:34:57.528302: 
2025-02-20 16:34:57.534060: Epoch 51
2025-02-20 16:34:57.537347: Current learning rate: 0.00526
2025-02-20 16:39:36.081404: train_loss -0.0814
2025-02-20 16:39:36.087747: val_loss -0.0934
2025-02-20 16:39:36.089968: Pseudo dice [0.5493, 0.5831, 0.7292, 0.4978]
2025-02-20 16:39:36.092419: Epoch time: 278.55 s
2025-02-20 16:39:36.095090: Yayy! New best EMA pseudo Dice: 0.5115
2025-02-20 16:39:40.319086: 
2025-02-20 16:39:40.321599: Epoch 52
2025-02-20 16:39:40.327975: Current learning rate: 0.00517
2025-02-20 16:44:14.234215: train_loss -0.0885
2025-02-20 16:44:14.251154: val_loss -0.1203
2025-02-20 16:44:14.256226: Pseudo dice [0.6685, 0.6063, 0.7322, 0.613]
2025-02-20 16:44:14.268420: Epoch time: 273.92 s
2025-02-20 16:44:14.275610: Yayy! New best EMA pseudo Dice: 0.5258
2025-02-20 16:44:18.349859: 
2025-02-20 16:44:18.354491: Epoch 53
2025-02-20 16:44:18.359843: Current learning rate: 0.00507
2025-02-20 16:48:53.491417: train_loss -0.1087
2025-02-20 16:48:53.503519: val_loss -0.1552
2025-02-20 16:48:53.505661: Pseudo dice [0.7254, 0.7214, 0.7509, 0.6039]
2025-02-20 16:48:53.507303: Epoch time: 275.14 s
2025-02-20 16:48:53.508819: Yayy! New best EMA pseudo Dice: 0.5433
2025-02-20 16:48:57.644455: 
2025-02-20 16:48:57.648203: Epoch 54
2025-02-20 16:48:57.653874: Current learning rate: 0.00497
2025-02-20 16:53:31.005828: train_loss -0.0744
2025-02-20 16:53:31.017913: val_loss -0.0963
2025-02-20 16:53:31.023235: Pseudo dice [0.5929, 0.7199, 0.7418, 0.5752]
2025-02-20 16:53:31.028106: Epoch time: 273.36 s
2025-02-20 16:53:31.034065: Yayy! New best EMA pseudo Dice: 0.5547
2025-02-20 16:53:37.321629: 
2025-02-20 16:53:37.327549: Epoch 55
2025-02-20 16:53:37.332641: Current learning rate: 0.00487
2025-02-20 16:58:43.882844: train_loss -0.0924
2025-02-20 16:58:43.912382: val_loss -0.1772
2025-02-20 16:58:43.920758: Pseudo dice [0.6059, 0.7767, 0.8006, 0.5761]
2025-02-20 16:58:43.932362: Epoch time: 306.56 s
2025-02-20 16:58:43.942389: Yayy! New best EMA pseudo Dice: 0.5682
2025-02-20 16:58:47.777080: 
2025-02-20 16:58:47.784240: Epoch 56
2025-02-20 16:58:47.788610: Current learning rate: 0.00478
2025-02-20 17:03:19.883245: train_loss -0.1114
2025-02-20 17:03:19.892813: val_loss -0.1574
2025-02-20 17:03:19.896162: Pseudo dice [0.7105, 0.7846, 0.7312, 0.5623]
2025-02-20 17:03:19.902104: Epoch time: 272.11 s
2025-02-20 17:03:19.907837: Yayy! New best EMA pseudo Dice: 0.5811
2025-02-20 17:03:23.678141: 
2025-02-20 17:03:23.682131: Epoch 57
2025-02-20 17:03:23.685655: Current learning rate: 0.00468
2025-02-20 17:08:06.007208: train_loss -0.0817
2025-02-20 17:08:06.018378: val_loss -0.1343
2025-02-20 17:08:06.024580: Pseudo dice [0.7453, 0.6486, 0.7594, 0.6159]
2025-02-20 17:08:06.030637: Epoch time: 282.33 s
2025-02-20 17:08:06.036581: Yayy! New best EMA pseudo Dice: 0.5922
2025-02-20 17:08:09.799899: 
2025-02-20 17:08:09.807074: Epoch 58
2025-02-20 17:08:09.811651: Current learning rate: 0.00458
2025-02-20 17:14:25.965701: train_loss -0.089
2025-02-20 17:14:26.099783: val_loss -0.2385
2025-02-20 17:14:26.114924: Pseudo dice [0.8117, 0.8235, 0.7928, 0.6184]
2025-02-20 17:14:26.120409: Epoch time: 376.16 s
2025-02-20 17:14:26.125323: Yayy! New best EMA pseudo Dice: 0.6092
2025-02-20 17:14:30.142459: 
2025-02-20 17:14:30.173721: Epoch 59
2025-02-20 17:14:30.261120: Current learning rate: 0.00448
2025-02-20 17:19:11.078301: train_loss -0.101
2025-02-20 17:19:11.093796: val_loss -0.1465
2025-02-20 17:19:11.098786: Pseudo dice [0.7503, 0.711, 0.6909, 0.5702]
2025-02-20 17:19:11.106656: Epoch time: 280.94 s
2025-02-20 17:19:11.111969: Yayy! New best EMA pseudo Dice: 0.6163
2025-02-20 17:19:15.002198: 
2025-02-20 17:19:15.008590: Epoch 60
2025-02-20 17:19:15.012827: Current learning rate: 0.00438
2025-02-20 17:24:33.966548: train_loss -0.0945
2025-02-20 17:24:33.976565: val_loss -0.1927
2025-02-20 17:24:33.980019: Pseudo dice [0.7553, 0.6835, 0.7953, 0.6071]
2025-02-20 17:24:33.986242: Epoch time: 318.96 s
2025-02-20 17:24:33.991153: Yayy! New best EMA pseudo Dice: 0.6257
2025-02-20 17:24:40.237560: 
2025-02-20 17:24:40.242586: Epoch 61
2025-02-20 17:24:40.248485: Current learning rate: 0.00429
2025-02-20 17:28:50.973282: train_loss -0.137
2025-02-20 17:28:50.981910: val_loss -0.1561
2025-02-20 17:28:50.987321: Pseudo dice [0.7402, 0.7995, 0.7839, 0.6613]
2025-02-20 17:28:50.993176: Epoch time: 250.74 s
2025-02-20 17:28:50.996134: Yayy! New best EMA pseudo Dice: 0.6378
2025-02-20 17:28:55.028096: 
2025-02-20 17:28:55.031087: Epoch 62
2025-02-20 17:28:55.036531: Current learning rate: 0.00419
2025-02-20 17:34:05.600637: train_loss -0.111
2025-02-20 17:34:05.607095: val_loss -0.1549
2025-02-20 17:34:05.610060: Pseudo dice [0.6375, 0.7409, 0.7333, 0.6486]
2025-02-20 17:34:05.613052: Epoch time: 310.57 s
2025-02-20 17:34:05.615618: Yayy! New best EMA pseudo Dice: 0.643
2025-02-20 17:34:09.471843: 
2025-02-20 17:34:09.473855: Epoch 63
2025-02-20 17:34:09.475561: Current learning rate: 0.00409
2025-02-20 17:38:25.045820: train_loss -0.1131
2025-02-20 17:38:25.058440: val_loss -0.1698
2025-02-20 17:38:25.063737: Pseudo dice [0.6516, 0.7493, 0.7309, 0.7447]
2025-02-20 17:38:25.068906: Epoch time: 255.57 s
2025-02-20 17:38:25.075216: Yayy! New best EMA pseudo Dice: 0.6506
2025-02-20 17:38:28.958477: 
2025-02-20 17:38:28.960113: Epoch 64
2025-02-20 17:38:28.961724: Current learning rate: 0.00399
2025-02-20 17:42:41.438188: train_loss -0.1288
2025-02-20 17:42:41.452172: val_loss -0.1967
2025-02-20 17:42:41.456850: Pseudo dice [0.8069, 0.8154, 0.8156, 0.6965]
2025-02-20 17:42:41.462934: Epoch time: 252.48 s
2025-02-20 17:42:41.466982: Yayy! New best EMA pseudo Dice: 0.6639
2025-02-20 17:42:45.376121: 
2025-02-20 17:42:45.378346: Epoch 65
2025-02-20 17:42:45.382266: Current learning rate: 0.00389
2025-02-20 17:47:07.393872: train_loss -0.1366
2025-02-20 17:47:07.404752: val_loss -0.1705
2025-02-20 17:47:07.409587: Pseudo dice [0.8247, 0.6775, 0.8107, 0.734]
2025-02-20 17:47:07.412404: Epoch time: 262.02 s
2025-02-20 17:47:07.416553: Yayy! New best EMA pseudo Dice: 0.6737
2025-02-20 17:47:11.336257: 
2025-02-20 17:47:11.342770: Epoch 66
2025-02-20 17:47:11.348751: Current learning rate: 0.00379
2025-02-20 17:51:21.688035: train_loss -0.1519
2025-02-20 17:51:21.697457: val_loss -0.219
2025-02-20 17:51:21.703596: Pseudo dice [0.8161, 0.7705, 0.8548, 0.6153]
2025-02-20 17:51:21.706789: Epoch time: 250.35 s
2025-02-20 17:51:21.712283: Yayy! New best EMA pseudo Dice: 0.6827
2025-02-20 17:51:25.619883: 
2025-02-20 17:51:25.623004: Epoch 67
2025-02-20 17:51:25.625560: Current learning rate: 0.00369
2025-02-20 17:55:51.665590: train_loss -0.1535
2025-02-20 17:55:51.680302: val_loss -0.2037
2025-02-20 17:55:51.686589: Pseudo dice [0.6324, 0.7933, 0.7966, 0.6597]
2025-02-20 17:55:51.693303: Epoch time: 266.05 s
2025-02-20 17:55:51.701146: Yayy! New best EMA pseudo Dice: 0.6865
2025-02-20 17:55:58.052054: 
2025-02-20 17:55:58.056975: Epoch 68
2025-02-20 17:55:58.062536: Current learning rate: 0.00359
2025-02-20 18:00:14.546069: train_loss -0.143
2025-02-20 18:00:14.555848: val_loss -0.1451
2025-02-20 18:00:14.559356: Pseudo dice [0.5683, 0.7691, 0.7762, 0.6396]
2025-02-20 18:00:14.562632: Epoch time: 256.5 s
2025-02-20 18:00:14.566281: Yayy! New best EMA pseudo Dice: 0.6867
2025-02-20 18:00:18.509053: 
2025-02-20 18:00:18.514674: Epoch 69
2025-02-20 18:00:18.519729: Current learning rate: 0.00349
2025-02-20 18:04:40.415404: train_loss -0.1339
2025-02-20 18:04:40.434950: val_loss -0.2454
2025-02-20 18:04:40.441253: Pseudo dice [0.7944, 0.8153, 0.8471, 0.719]
2025-02-20 18:04:40.485752: Epoch time: 261.91 s
2025-02-20 18:04:40.495676: Yayy! New best EMA pseudo Dice: 0.6974
2025-02-20 18:04:44.509605: 
2025-02-20 18:04:44.515935: Epoch 70
2025-02-20 18:04:44.520964: Current learning rate: 0.00338
2025-02-20 18:09:09.236304: train_loss -0.167
2025-02-20 18:09:09.267608: val_loss -0.19
2025-02-20 18:09:09.272399: Pseudo dice [0.8225, 0.8224, 0.821, 0.6214]
2025-02-20 18:09:09.274235: Epoch time: 264.73 s
2025-02-20 18:09:09.277978: Yayy! New best EMA pseudo Dice: 0.7049
2025-02-20 18:09:13.406981: 
2025-02-20 18:09:13.412278: Epoch 71
2025-02-20 18:09:13.414930: Current learning rate: 0.00328
2025-02-20 18:13:41.683039: train_loss -0.1355
2025-02-20 18:13:41.691036: val_loss -0.222
2025-02-20 18:13:41.694709: Pseudo dice [0.8184, 0.7895, 0.8317, 0.6715]
2025-02-20 18:13:41.697762: Epoch time: 268.28 s
2025-02-20 18:13:41.699918: Yayy! New best EMA pseudo Dice: 0.7122
2025-02-20 18:13:45.764858: 
2025-02-20 18:13:45.769172: Epoch 72
2025-02-20 18:13:45.772613: Current learning rate: 0.00318
2025-02-20 18:20:58.533749: train_loss -0.1318
2025-02-20 18:20:58.543549: val_loss -0.154
2025-02-20 18:20:58.546859: Pseudo dice [0.6934, 0.6678, 0.8071, 0.7435]
2025-02-20 18:20:58.551250: Epoch time: 432.77 s
2025-02-20 18:20:58.556709: Yayy! New best EMA pseudo Dice: 0.7137
2025-02-20 18:21:02.590160: 
2025-02-20 18:21:02.593557: Epoch 73
2025-02-20 18:21:02.628560: Current learning rate: 0.00308
2025-02-20 18:34:02.795110: train_loss -0.1508
2025-02-20 18:34:02.817031: val_loss -0.2193
2025-02-20 18:34:02.823060: Pseudo dice [0.802, 0.8045, 0.8154, 0.7067]
2025-02-20 18:34:02.834118: Epoch time: 780.21 s
2025-02-20 18:34:02.839414: Yayy! New best EMA pseudo Dice: 0.7206
2025-02-20 18:34:08.959118: 
2025-02-20 18:34:08.964156: Epoch 74
2025-02-20 18:34:08.970249: Current learning rate: 0.00297
2025-02-20 18:38:11.324882: train_loss -0.1916
2025-02-20 18:38:11.334730: val_loss -0.2293
2025-02-20 18:38:11.343114: Pseudo dice [0.8799, 0.7414, 0.8683, 0.7529]
2025-02-20 18:38:11.350277: Epoch time: 242.37 s
2025-02-20 18:38:11.354224: Yayy! New best EMA pseudo Dice: 0.7296
2025-02-20 18:38:15.202567: 
2025-02-20 18:38:15.208704: Epoch 75
2025-02-20 18:38:15.218496: Current learning rate: 0.00287
2025-02-20 18:42:30.348755: train_loss -0.1685
2025-02-20 18:42:30.363126: val_loss -0.1948
2025-02-20 18:42:30.372031: Pseudo dice [0.7504, 0.7369, 0.7997, 0.6756]
2025-02-20 18:42:30.379323: Epoch time: 255.15 s
2025-02-20 18:42:30.385224: Yayy! New best EMA pseudo Dice: 0.7307
2025-02-20 18:42:34.326738: 
2025-02-20 18:42:34.330568: Epoch 76
2025-02-20 18:42:34.338427: Current learning rate: 0.00277
2025-02-20 18:47:04.754735: train_loss -0.1808
2025-02-20 18:47:04.765573: val_loss -0.1934
2025-02-20 18:47:04.771266: Pseudo dice [0.7486, 0.7464, 0.8498, 0.6946]
2025-02-20 18:47:04.780066: Epoch time: 270.43 s
2025-02-20 18:47:04.783383: Yayy! New best EMA pseudo Dice: 0.7336
2025-02-20 18:47:08.830029: 
2025-02-20 18:47:08.834327: Epoch 77
2025-02-20 18:47:08.837693: Current learning rate: 0.00266
2025-02-20 18:54:07.695011: train_loss -0.1762
2025-02-20 18:54:07.712950: val_loss -0.2319
2025-02-20 18:54:07.718552: Pseudo dice [0.8055, 0.8449, 0.8327, 0.7024]
2025-02-20 18:54:07.724643: Epoch time: 418.87 s
2025-02-20 18:54:07.730165: Yayy! New best EMA pseudo Dice: 0.7399
2025-02-20 18:54:11.775464: 
2025-02-20 18:54:11.779014: Epoch 78
2025-02-20 18:54:11.782979: Current learning rate: 0.00256
2025-02-20 18:58:36.236414: train_loss -0.2062
2025-02-20 18:58:36.242264: val_loss -0.261
2025-02-20 18:58:36.244206: Pseudo dice [0.8525, 0.8223, 0.8618, 0.7186]
2025-02-20 18:58:36.246169: Epoch time: 264.46 s
2025-02-20 18:58:36.248312: Yayy! New best EMA pseudo Dice: 0.7473
2025-02-20 18:58:40.304497: 
2025-02-20 18:58:40.309504: Epoch 79
2025-02-20 18:58:40.315583: Current learning rate: 0.00245
2025-02-20 19:02:55.525890: train_loss -0.1915
2025-02-20 19:02:55.538435: val_loss -0.2342
2025-02-20 19:02:55.541886: Pseudo dice [0.817, 0.7992, 0.8135, 0.6401]
2025-02-20 19:02:55.545407: Epoch time: 255.22 s
2025-02-20 19:02:55.548865: Yayy! New best EMA pseudo Dice: 0.7493
2025-02-20 19:02:59.541003: 
2025-02-20 19:02:59.546895: Epoch 80
2025-02-20 19:02:59.552545: Current learning rate: 0.00235
2025-02-20 19:07:16.208249: train_loss -0.2184
2025-02-20 19:07:16.217261: val_loss -0.2305
2025-02-20 19:07:16.220892: Pseudo dice [0.8416, 0.7985, 0.822, 0.6407]
2025-02-20 19:07:16.225837: Epoch time: 256.67 s
2025-02-20 19:07:16.229667: Yayy! New best EMA pseudo Dice: 0.7519
2025-02-20 19:07:22.532737: 
2025-02-20 19:07:22.538836: Epoch 81
2025-02-20 19:07:22.544528: Current learning rate: 0.00224
2025-02-20 19:12:44.744469: train_loss -0.1957
2025-02-20 19:12:44.762759: val_loss -0.2236
2025-02-20 19:12:44.769442: Pseudo dice [0.8286, 0.7633, 0.8126, 0.7602]
2025-02-20 19:12:44.779494: Epoch time: 322.21 s
2025-02-20 19:12:44.786422: Yayy! New best EMA pseudo Dice: 0.7559
2025-02-20 19:12:48.592161: 
2025-02-20 19:12:48.594987: Epoch 82
2025-02-20 19:12:48.602828: Current learning rate: 0.00214
2025-02-20 19:17:04.284893: train_loss -0.1974
2025-02-20 19:17:04.296459: val_loss -0.1869
2025-02-20 19:17:04.309306: Pseudo dice [0.7412, 0.7084, 0.7717, 0.6418]
2025-02-20 19:17:04.318151: Epoch time: 255.69 s
2025-02-20 19:17:05.762686: 
2025-02-20 19:17:05.768891: Epoch 83
2025-02-20 19:17:05.774157: Current learning rate: 0.00203
2025-02-20 19:22:48.698406: train_loss -0.212
2025-02-20 19:22:48.707624: val_loss -0.2007
2025-02-20 19:22:48.722937: Pseudo dice [0.7414, 0.8012, 0.741, 0.7083]
2025-02-20 19:22:48.733190: Epoch time: 342.94 s
2025-02-20 19:22:50.397848: 
2025-02-20 19:22:50.409115: Epoch 84
2025-02-20 19:22:50.426158: Current learning rate: 0.00192
2025-02-20 19:27:27.210038: train_loss -0.198
2025-02-20 19:27:27.280434: val_loss -0.2154
2025-02-20 19:27:27.382219: Pseudo dice [0.7534, 0.7275, 0.8567, 0.7022]
2025-02-20 19:27:27.461924: Epoch time: 276.81 s
2025-02-20 19:27:29.145405: 
2025-02-20 19:27:29.154023: Epoch 85
2025-02-20 19:27:29.160767: Current learning rate: 0.00181
2025-02-20 19:33:28.808669: train_loss -0.2121
2025-02-20 19:33:28.817662: val_loss -0.2681
2025-02-20 19:33:28.820735: Pseudo dice [0.9, 0.8247, 0.86, 0.7282]
2025-02-20 19:33:28.823510: Epoch time: 359.66 s
2025-02-20 19:33:28.825385: Yayy! New best EMA pseudo Dice: 0.7599
2025-02-20 19:33:32.766136: 
2025-02-20 19:33:32.772049: Epoch 86
2025-02-20 19:33:32.778104: Current learning rate: 0.0017
2025-02-20 19:37:47.000426: train_loss -0.2198
2025-02-20 19:37:47.006917: val_loss -0.2521
2025-02-20 19:37:47.009142: Pseudo dice [0.8761, 0.8128, 0.8683, 0.6951]
2025-02-20 19:37:47.011841: Epoch time: 254.24 s
2025-02-20 19:37:47.014102: Yayy! New best EMA pseudo Dice: 0.7652
2025-02-20 19:37:54.604914: 
2025-02-20 19:37:54.606757: Epoch 87
2025-02-20 19:37:54.608169: Current learning rate: 0.00159
2025-02-20 19:43:38.431627: train_loss -0.2279
2025-02-20 19:43:38.443874: val_loss -0.2311
2025-02-20 19:43:38.450366: Pseudo dice [0.8106, 0.7951, 0.7872, 0.7318]
2025-02-20 19:43:38.455942: Epoch time: 343.83 s
2025-02-20 19:43:38.462412: Yayy! New best EMA pseudo Dice: 0.7668
2025-02-20 19:43:42.332062: 
2025-02-20 19:43:42.338161: Epoch 88
2025-02-20 19:43:42.343162: Current learning rate: 0.00148
2025-02-20 19:48:03.750784: train_loss -0.2058
2025-02-20 19:48:03.767817: val_loss -0.2719
2025-02-20 19:48:03.777761: Pseudo dice [0.8631, 0.8417, 0.8271, 0.688]
2025-02-20 19:48:03.786750: Epoch time: 261.42 s
2025-02-20 19:48:03.790425: Yayy! New best EMA pseudo Dice: 0.7706
2025-02-20 19:48:07.747846: 
2025-02-20 19:48:07.750442: Epoch 89
2025-02-20 19:48:07.752884: Current learning rate: 0.00137
2025-02-20 19:53:37.939033: train_loss -0.2201
2025-02-20 19:53:37.995841: val_loss -0.2835
2025-02-20 19:53:38.057729: Pseudo dice [0.8831, 0.8425, 0.8531, 0.7352]
2025-02-20 19:53:38.097220: Epoch time: 330.19 s
2025-02-20 19:53:38.140919: Yayy! New best EMA pseudo Dice: 0.7764
2025-02-20 19:53:42.187052: 
2025-02-20 19:53:42.255852: Epoch 90
2025-02-20 19:53:42.338046: Current learning rate: 0.00126
2025-02-20 19:58:15.460544: train_loss -0.2281
2025-02-20 19:58:15.472038: val_loss -0.2529
2025-02-20 19:58:15.477783: Pseudo dice [0.8347, 0.8511, 0.8574, 0.7227]
2025-02-20 19:58:15.483908: Epoch time: 273.28 s
2025-02-20 19:58:15.490091: Yayy! New best EMA pseudo Dice: 0.7804
2025-02-20 19:58:19.303289: 
2025-02-20 19:58:19.306060: Epoch 91
2025-02-20 19:58:19.311002: Current learning rate: 0.00115
2025-02-20 20:02:32.930088: train_loss -0.2233
2025-02-20 20:02:32.972056: val_loss -0.2929
2025-02-20 20:02:33.023345: Pseudo dice [0.8727, 0.8274, 0.8474, 0.7023]
2025-02-20 20:02:33.072532: Epoch time: 253.63 s
2025-02-20 20:02:33.117934: Yayy! New best EMA pseudo Dice: 0.7836
2025-02-20 20:02:37.113630: 
2025-02-20 20:02:37.121228: Epoch 92
2025-02-20 20:02:37.127392: Current learning rate: 0.00103
2025-02-20 20:08:21.539770: train_loss -0.2214
2025-02-20 20:08:21.551577: val_loss -0.3049
2025-02-20 20:08:21.562039: Pseudo dice [0.8573, 0.8451, 0.8804, 0.7453]
2025-02-20 20:08:21.568839: Epoch time: 344.43 s
2025-02-20 20:08:21.577300: Yayy! New best EMA pseudo Dice: 0.7885
2025-02-20 20:08:25.440814: 
2025-02-20 20:08:25.445910: Epoch 93
2025-02-20 20:08:25.454274: Current learning rate: 0.00091
2025-02-20 20:12:48.957456: train_loss -0.2511
2025-02-20 20:12:48.977326: val_loss -0.2718
2025-02-20 20:12:48.984767: Pseudo dice [0.8697, 0.8257, 0.8607, 0.7635]
2025-02-20 20:12:49.033095: Epoch time: 263.52 s
2025-02-20 20:12:49.040400: Yayy! New best EMA pseudo Dice: 0.7926
2025-02-20 20:12:55.329879: 
2025-02-20 20:12:55.333449: Epoch 94
2025-02-20 20:12:55.340343: Current learning rate: 0.00079
2025-02-20 20:18:56.761330: train_loss -0.2431
2025-02-20 20:18:56.868402: val_loss -0.2641
2025-02-20 20:18:56.905295: Pseudo dice [0.8405, 0.8743, 0.8558, 0.7806]
2025-02-20 20:18:56.910842: Epoch time: 361.43 s
2025-02-20 20:18:56.916544: Yayy! New best EMA pseudo Dice: 0.7971
2025-02-20 20:19:00.916367: 
2025-02-20 20:19:00.919755: Epoch 95
2025-02-20 20:19:00.922956: Current learning rate: 0.00067
2025-02-20 20:23:25.588508: train_loss -0.2492
2025-02-20 20:23:25.661355: val_loss -0.3061
2025-02-20 20:23:25.668849: Pseudo dice [0.854, 0.8227, 0.8719, 0.709]
2025-02-20 20:23:25.674502: Epoch time: 264.67 s
2025-02-20 20:23:25.678452: Yayy! New best EMA pseudo Dice: 0.7989
2025-02-20 20:23:29.641547: 
2025-02-20 20:23:29.644351: Epoch 96
2025-02-20 20:23:29.646731: Current learning rate: 0.00055
2025-02-20 20:29:35.355410: train_loss -0.2371
2025-02-20 20:29:35.364701: val_loss -0.256
2025-02-20 20:29:35.368309: Pseudo dice [0.8362, 0.828, 0.854, 0.7131]
2025-02-20 20:29:35.373209: Epoch time: 365.71 s
2025-02-20 20:29:35.376436: Yayy! New best EMA pseudo Dice: 0.7997
2025-02-20 20:29:39.211383: 
2025-02-20 20:29:39.215017: Epoch 97
2025-02-20 20:29:39.217422: Current learning rate: 0.00043
2025-02-20 20:34:03.400785: train_loss -0.2503
2025-02-20 20:34:03.422837: val_loss -0.2679
2025-02-20 20:34:03.430874: Pseudo dice [0.8549, 0.824, 0.8717, 0.7618]
2025-02-20 20:34:03.435937: Epoch time: 264.19 s
2025-02-20 20:34:03.441797: Yayy! New best EMA pseudo Dice: 0.8026
2025-02-20 20:34:07.428000: 
2025-02-20 20:34:07.430575: Epoch 98
2025-02-20 20:34:07.436084: Current learning rate: 0.0003
2025-02-20 20:38:23.758487: train_loss -0.24
2025-02-20 20:38:23.763003: val_loss -0.2558
2025-02-20 20:38:23.767856: Pseudo dice [0.8455, 0.845, 0.8833, 0.747]
2025-02-20 20:38:23.769943: Epoch time: 256.33 s
2025-02-20 20:38:23.771996: Yayy! New best EMA pseudo Dice: 0.8053
2025-02-20 20:38:27.651135: 
2025-02-20 20:38:27.658813: Epoch 99
2025-02-20 20:38:27.663428: Current learning rate: 0.00016
2025-02-20 20:42:51.185803: train_loss -0.2688
2025-02-20 20:42:51.233254: val_loss -0.2815
2025-02-20 20:42:51.280728: Pseudo dice [0.8935, 0.8169, 0.875, 0.7874]
2025-02-20 20:42:51.330647: Epoch time: 263.54 s
2025-02-20 20:42:51.379101: Yayy! New best EMA pseudo Dice: 0.8091
2025-02-20 20:42:57.950797: Training done.
2025-02-20 20:42:58.029765: Using splits from existing split file: /home3/hghr96/parm/work/AD_project/segmentation/nnUNet/data/nnUNet_preprocess/Dataset501_AD/splits_final.json
2025-02-20 20:42:58.038416: The split file contains 5 splits.
2025-02-20 20:42:58.041841: Desired fold for training: 1
2025-02-20 20:42:58.044282: This split has 70 training and 18 validation cases.
2025-02-20 20:42:58.047318: predicting ad_001
2025-02-20 20:42:58.072286: ad_001, shape torch.Size([1, 450, 514, 450]), rank 0
2025-02-20 20:45:01.260655: predicting ad_019
2025-02-20 20:45:01.321440: ad_019, shape torch.Size([1, 483, 1074, 483]), rank 0
2025-02-20 20:49:31.597323: predicting ad_022
2025-02-20 20:49:31.662493: ad_022, shape torch.Size([1, 413, 873, 413]), rank 0
2025-02-20 20:52:19.031405: predicting ad_023
2025-02-20 20:52:19.108444: ad_023, shape torch.Size([1, 490, 1056, 490]), rank 0
2025-02-20 20:57:01.497689: predicting ad_026
2025-02-20 20:57:01.606885: ad_026, shape torch.Size([1, 307, 729, 307]), rank 0
2025-02-20 21:03:00.546213: predicting ad_027
2025-02-20 21:03:00.613418: ad_027, shape torch.Size([1, 555, 835, 555]), rank 0
2025-02-20 21:10:17.896557: predicting ad_029
2025-02-20 21:10:17.994786: ad_029, shape torch.Size([1, 512, 800, 512]), rank 0
2025-02-20 21:15:13.755257: predicting ad_034
2025-02-20 21:15:13.907819: ad_034, shape torch.Size([1, 512, 1128, 512]), rank 0
2025-02-20 21:20:55.091683: predicting ad_036
2025-02-20 21:20:55.200367: ad_036, shape torch.Size([1, 536, 923, 536]), rank 0
2025-02-20 21:25:40.596020: predicting ad_041
2025-02-20 21:25:40.697260: ad_041, shape torch.Size([1, 614, 939, 614]), rank 0
2025-02-20 21:34:33.227611: predicting ad_048
2025-02-20 21:34:33.329837: ad_048, shape torch.Size([1, 558, 1020, 558]), rank 0
2025-02-20 21:40:08.205617: predicting ad_057
2025-02-20 21:40:08.301758: ad_057, shape torch.Size([1, 526, 943, 526]), rank 0
2025-02-20 21:47:44.551195: predicting ad_064
2025-02-20 21:47:44.647223: ad_064, shape torch.Size([1, 512, 800, 512]), rank 0
2025-02-20 21:54:19.018868: predicting ad_078
2025-02-20 21:54:19.114026: ad_078, shape torch.Size([1, 367, 643, 367]), rank 0
2025-02-20 21:59:59.171734: predicting ad_081
2025-02-20 21:59:59.236169: ad_081, shape torch.Size([1, 600, 877, 600]), rank 0
2025-02-20 22:06:09.318878: predicting ad_085
2025-02-20 22:06:09.422156: ad_085, shape torch.Size([1, 637, 2236, 637]), rank 0
Prediction on device was unsuccessful, probably due to a lack of memory. Moving results arrays to CPU
2025-02-20 22:43:38.810118: predicting ad_087
2025-02-20 22:43:38.981702: ad_087, shape torch.Size([1, 490, 814, 490]), rank 0
2025-02-20 22:46:58.440296: predicting ad_093
2025-02-20 22:46:58.557907: ad_093, shape torch.Size([1, 581, 794, 581]), rank 0
2025-02-20 23:22:08.160634: Validation complete
2025-02-20 23:22:08.163576: Mean Validation Dice:  0.49535434366719056
Finished at Thu 20 Feb 2025 11:22:15 PM GMT
Total Execution Time: 39341 seconds
