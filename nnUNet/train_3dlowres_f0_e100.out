Starting at Tue 25 Feb 2025 10:38:43 AM GMT

############################
INFO: You are using the old nnU-Net default plans. We have updated our recommendations. Please consider using those instead! Read more here: https://github.com/MIC-DKFZ/nnUNet/blob/master/documentation/resenc_presets.md
############################

Using device: cuda:0

#######################################################################
Please cite the following paper when using nnU-Net:
Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.
#######################################################################

2025-02-25 10:38:57.909915: do_dummy_2d_data_aug: False
2025-02-25 10:38:57.917026: Using splits from existing split file: /home3/hghr96/parm/work/AD_project/segmentation/nnUNet/data/nnUNet_preprocessed/Dataset501_AD/splits_final.json
2025-02-25 10:38:57.921253: The split file contains 5 splits.
2025-02-25 10:38:57.922993: Desired fold for training: 0
2025-02-25 10:38:57.925056: This split has 70 training and 18 validation cases.
using pin_memory on device 0
/home3/hghr96/miniconda3/envs/nnUnet/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
using pin_memory on device 0
2025-02-25 10:39:04.195117: Using torch.compile...

This is the configuration used by this training:
Configuration name: 3d_lowres
 {'data_identifier': 'nnUNetPlans_3d_lowres', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 2, 'patch_size': [112, 192, 112], 'median_image_size_in_voxels': [177, 288, 177], 'spacing': [2.275601343470847, 2.028794967802552, 2.275601343470847], 'normalization_schemes': ['CTNormalization'], 'use_mask_for_norm': [False], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.PlainConvUNet', 'arch_kwargs': {'n_stages': 6, 'features_per_stage': [32, 64, 128, 256, 320, 320], 'conv_op': 'torch.nn.modules.conv.Conv3d', 'kernel_sizes': [[3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]], 'strides': [[1, 1, 1], [2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2], [1, 2, 1]], 'n_conv_per_stage': [2, 2, 2, 2, 2, 2], 'n_conv_per_stage_decoder': [2, 2, 2, 2, 2], 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm3d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}}, '_kw_requires_import': ['conv_op', 'norm_op', 'dropout_op', 'nonlin']}, 'batch_dice': False, 'next_stage': '3d_cascade_fullres'} 

These are the global plan.json settings:
 {'dataset_name': 'Dataset501_AD', 'plans_name': 'nnUNetPlans', 'original_median_spacing_after_transp': [0.78515625, 0.7000000476837158, 0.78515625], 'original_median_shape_after_transp': [512, 800, 512], 'image_reader_writer': 'SimpleITKIO', 'transpose_forward': [1, 0, 2], 'transpose_backward': [1, 0, 2], 'experiment_planner_used': 'ExperimentPlanner', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 3071.0, 'mean': 161.64767456054688, 'median': 182.0, 'min': -1103.0, 'percentile_00_5': -840.0, 'percentile_99_5': 778.0, 'std': 241.90689086914062}}} 

2025-02-25 10:39:10.398627: unpacking dataset...
2025-02-25 10:40:29.322491: unpacking done...
2025-02-25 10:40:29.350917: Unable to plot network architecture: nnUNet_compile is enabled!
2025-02-25 10:40:29.613250: 
2025-02-25 10:40:29.615395: Epoch 0
2025-02-25 10:40:29.617444: Current learning rate: 0.01
2025-02-25 10:44:44.297969: train_loss 0.1188
2025-02-25 10:44:44.302096: val_loss 0.0269
2025-02-25 10:44:44.304267: Pseudo dice [0.0, 0.0031, 0.0, 0.0008]
2025-02-25 10:44:44.306561: Epoch time: 254.69 s
2025-02-25 10:44:44.308634: Yayy! New best EMA pseudo Dice: 0.001
2025-02-25 10:44:48.122661: 
2025-02-25 10:44:48.124447: Epoch 1
2025-02-25 10:44:48.126252: Current learning rate: 0.00991
2025-02-25 10:46:53.666170: train_loss -0.0282
2025-02-25 10:46:53.678753: val_loss -0.0468
2025-02-25 10:46:53.680861: Pseudo dice [0.0, 0.0005, 0.0, 0.4203]
2025-02-25 10:46:53.682484: Epoch time: 125.54 s
2025-02-25 10:46:53.684068: Yayy! New best EMA pseudo Dice: 0.0114
2025-02-25 10:46:58.265426: 
2025-02-25 10:46:58.269251: Epoch 2
2025-02-25 10:46:58.271253: Current learning rate: 0.00982
2025-02-25 10:49:21.692492: train_loss -0.0825
2025-02-25 10:49:21.696630: val_loss -0.0978
2025-02-25 10:49:21.698768: Pseudo dice [0.0, 0.1675, 0.0, 0.4662]
2025-02-25 10:49:21.701016: Epoch time: 143.43 s
2025-02-25 10:49:21.703166: Yayy! New best EMA pseudo Dice: 0.0261
2025-02-25 10:49:26.527491: 
2025-02-25 10:49:26.530303: Epoch 3
2025-02-25 10:49:26.532469: Current learning rate: 0.00973
2025-02-25 10:51:37.761249: train_loss -0.1235
2025-02-25 10:51:37.767819: val_loss -0.1471
2025-02-25 10:51:37.771377: Pseudo dice [0.4345, 0.3672, 0.0017, 0.4757]
2025-02-25 10:51:37.773960: Epoch time: 131.24 s
2025-02-25 10:51:37.776566: Yayy! New best EMA pseudo Dice: 0.0555
2025-02-25 10:51:42.370131: 
2025-02-25 10:51:42.372680: Epoch 4
2025-02-25 10:51:42.375079: Current learning rate: 0.00964
2025-02-25 10:53:52.578045: train_loss -0.1852
2025-02-25 10:53:52.584686: val_loss -0.1971
2025-02-25 10:53:52.586566: Pseudo dice [0.2473, 0.3989, 0.5862, 0.4339]
2025-02-25 10:53:52.588371: Epoch time: 130.21 s
2025-02-25 10:53:52.599760: Yayy! New best EMA pseudo Dice: 0.0916
2025-02-25 10:53:57.265916: 
2025-02-25 10:53:57.268350: Epoch 5
2025-02-25 10:53:57.270590: Current learning rate: 0.00955
2025-02-25 10:56:15.614144: train_loss -0.207
2025-02-25 10:56:15.918992: val_loss -0.2065
2025-02-25 10:56:16.052918: Pseudo dice [0.3013, 0.411, 0.5984, 0.4644]
2025-02-25 10:56:16.063168: Epoch time: 138.35 s
2025-02-25 10:56:16.064387: Yayy! New best EMA pseudo Dice: 0.1268
2025-02-25 10:56:20.091738: 
2025-02-25 10:56:20.121031: Epoch 6
2025-02-25 10:56:20.299953: Current learning rate: 0.00946
2025-02-25 10:58:18.266353: train_loss -0.2232
2025-02-25 10:58:18.297222: val_loss -0.2281
2025-02-25 10:58:18.299826: Pseudo dice [0.4461, 0.5434, 0.616, 0.4411]
2025-02-25 10:58:18.302089: Epoch time: 118.18 s
2025-02-25 10:58:18.304211: Yayy! New best EMA pseudo Dice: 0.1653
2025-02-25 10:58:22.996960: 
2025-02-25 10:58:22.999730: Epoch 7
2025-02-25 10:58:23.001895: Current learning rate: 0.00937
2025-02-25 11:00:33.365341: train_loss -0.2397
2025-02-25 11:00:33.369693: val_loss -0.2313
2025-02-25 11:00:33.371581: Pseudo dice [0.5182, 0.5445, 0.5832, 0.3967]
2025-02-25 11:00:33.373099: Epoch time: 130.37 s
2025-02-25 11:00:33.374688: Yayy! New best EMA pseudo Dice: 0.1998
2025-02-25 11:00:37.558850: 
2025-02-25 11:00:37.564187: Epoch 8
2025-02-25 11:00:37.566467: Current learning rate: 0.00928
2025-02-25 11:02:47.255935: train_loss -0.2416
2025-02-25 11:02:47.271733: val_loss -0.2789
2025-02-25 11:02:47.277714: Pseudo dice [0.4698, 0.5973, 0.7076, 0.5442]
2025-02-25 11:02:47.280464: Epoch time: 129.7 s
2025-02-25 11:02:47.283039: Yayy! New best EMA pseudo Dice: 0.2378
2025-02-25 11:02:52.407523: 
2025-02-25 11:02:52.411754: Epoch 9
2025-02-25 11:02:52.414187: Current learning rate: 0.00919
2025-02-25 11:04:56.826408: train_loss -0.2685
2025-02-25 11:04:56.830046: val_loss -0.2637
2025-02-25 11:04:56.831754: Pseudo dice [0.5467, 0.5582, 0.6195, 0.5309]
2025-02-25 11:04:56.833648: Epoch time: 124.42 s
2025-02-25 11:04:56.835257: Yayy! New best EMA pseudo Dice: 0.2704
2025-02-25 11:05:01.436585: 
2025-02-25 11:05:01.439072: Epoch 10
2025-02-25 11:05:01.441097: Current learning rate: 0.0091
2025-02-25 11:07:11.852819: train_loss -0.2792
2025-02-25 11:07:11.971468: val_loss -0.2503
2025-02-25 11:07:12.073906: Pseudo dice [0.519, 0.5947, 0.6654, 0.48]
2025-02-25 11:07:12.075840: Epoch time: 130.42 s
2025-02-25 11:07:12.078016: Yayy! New best EMA pseudo Dice: 0.2998
2025-02-25 11:07:16.360968: 
2025-02-25 11:07:16.487016: Epoch 11
2025-02-25 11:07:16.515562: Current learning rate: 0.009
2025-02-25 11:09:23.208662: train_loss -0.2777
2025-02-25 11:09:23.430892: val_loss -0.2775
2025-02-25 11:09:23.441823: Pseudo dice [0.5511, 0.6616, 0.7122, 0.5377]
2025-02-25 11:09:23.443905: Epoch time: 126.85 s
2025-02-25 11:09:23.533433: Yayy! New best EMA pseudo Dice: 0.3314
2025-02-25 11:09:27.991833: 
2025-02-25 11:09:27.994099: Epoch 12
2025-02-25 11:09:27.996083: Current learning rate: 0.00891
2025-02-25 11:11:34.321742: train_loss -0.2869
2025-02-25 11:11:34.325282: val_loss -0.3009
2025-02-25 11:11:34.327363: Pseudo dice [0.6326, 0.6322, 0.7086, 0.5965]
2025-02-25 11:11:34.331214: Epoch time: 126.33 s
2025-02-25 11:11:34.335811: Yayy! New best EMA pseudo Dice: 0.3625
2025-02-25 11:11:39.012620: 
2025-02-25 11:11:39.190579: Epoch 13
2025-02-25 11:11:39.324996: Current learning rate: 0.00882
2025-02-25 11:13:48.286838: train_loss -0.2935
2025-02-25 11:13:48.290708: val_loss -0.2911
2025-02-25 11:13:48.292870: Pseudo dice [0.6684, 0.6558, 0.6692, 0.5798]
2025-02-25 11:13:48.294729: Epoch time: 129.28 s
2025-02-25 11:13:48.296641: Yayy! New best EMA pseudo Dice: 0.3906
2025-02-25 11:13:52.972414: 
2025-02-25 11:13:53.150687: Epoch 14
2025-02-25 11:13:53.302182: Current learning rate: 0.00873
2025-02-25 11:16:12.686235: train_loss -0.3076
2025-02-25 11:16:12.690513: val_loss -0.3125
2025-02-25 11:16:12.692839: Pseudo dice [0.6695, 0.673, 0.7648, 0.5079]
2025-02-25 11:16:12.694977: Epoch time: 139.72 s
2025-02-25 11:16:12.697154: Yayy! New best EMA pseudo Dice: 0.4169
2025-02-25 11:16:16.722458: 
2025-02-25 11:16:16.724671: Epoch 15
2025-02-25 11:16:16.726390: Current learning rate: 0.00864
2025-02-25 11:18:30.532422: train_loss -0.3185
2025-02-25 11:18:30.538970: val_loss -0.3051
2025-02-25 11:18:30.543685: Pseudo dice [0.7052, 0.5969, 0.7681, 0.5944]
2025-02-25 11:18:30.545626: Epoch time: 133.81 s
2025-02-25 11:18:30.547401: Yayy! New best EMA pseudo Dice: 0.4419
2025-02-25 11:18:35.155103: 
2025-02-25 11:18:35.157147: Epoch 16
2025-02-25 11:18:35.159146: Current learning rate: 0.00855
2025-02-25 11:20:42.000832: train_loss -0.3183
2025-02-25 11:20:42.017222: val_loss -0.3276
2025-02-25 11:20:42.019621: Pseudo dice [0.599, 0.6608, 0.7589, 0.5392]
2025-02-25 11:20:42.021916: Epoch time: 126.85 s
2025-02-25 11:20:42.024112: Yayy! New best EMA pseudo Dice: 0.4616
2025-02-25 11:20:46.612164: 
2025-02-25 11:20:46.614523: Epoch 17
2025-02-25 11:20:46.616523: Current learning rate: 0.00846
2025-02-25 11:23:01.029797: train_loss -0.3247
2025-02-25 11:23:01.047229: val_loss -0.3442
2025-02-25 11:23:01.049301: Pseudo dice [0.6302, 0.7172, 0.7367, 0.57]
2025-02-25 11:23:01.051330: Epoch time: 134.42 s
2025-02-25 11:23:01.053322: Yayy! New best EMA pseudo Dice: 0.4818
2025-02-25 11:23:04.933796: 
2025-02-25 11:23:04.936088: Epoch 18
2025-02-25 11:23:04.938418: Current learning rate: 0.00836
2025-02-25 11:25:14.965329: train_loss -0.3414
2025-02-25 11:25:14.969374: val_loss -0.3005
2025-02-25 11:25:14.971704: Pseudo dice [0.6958, 0.6341, 0.7537, 0.5138]
2025-02-25 11:25:14.973890: Epoch time: 130.03 s
2025-02-25 11:25:14.976291: Yayy! New best EMA pseudo Dice: 0.4986
2025-02-25 11:25:19.302613: 
2025-02-25 11:25:19.304553: Epoch 19
2025-02-25 11:25:19.306136: Current learning rate: 0.00827
2025-02-25 11:27:27.229525: train_loss -0.3548
2025-02-25 11:27:27.243079: val_loss -0.3252
2025-02-25 11:27:27.245142: Pseudo dice [0.6397, 0.6218, 0.7975, 0.6206]
2025-02-25 11:27:27.247170: Epoch time: 127.93 s
2025-02-25 11:27:27.249161: Yayy! New best EMA pseudo Dice: 0.5157
2025-02-25 11:27:31.834032: 
2025-02-25 11:27:31.836584: Epoch 20
2025-02-25 11:27:31.838977: Current learning rate: 0.00818
2025-02-25 11:29:50.044348: train_loss -0.3572
2025-02-25 11:29:50.048801: val_loss -0.3621
2025-02-25 11:29:50.052616: Pseudo dice [0.7926, 0.628, 0.8168, 0.6665]
2025-02-25 11:29:50.064467: Epoch time: 138.21 s
2025-02-25 11:29:50.066704: Yayy! New best EMA pseudo Dice: 0.5367
2025-02-25 11:29:54.662456: 
2025-02-25 11:29:54.664477: Epoch 21
2025-02-25 11:29:54.666255: Current learning rate: 0.00809
2025-02-25 11:32:05.213344: train_loss -0.3557
2025-02-25 11:32:05.220696: val_loss -0.3444
2025-02-25 11:32:05.223214: Pseudo dice [0.5995, 0.73, 0.7189, 0.6476]
2025-02-25 11:32:05.237592: Epoch time: 130.55 s
2025-02-25 11:32:05.239716: Yayy! New best EMA pseudo Dice: 0.5505
2025-02-25 11:32:09.439017: 
2025-02-25 11:32:09.440998: Epoch 22
2025-02-25 11:32:09.442976: Current learning rate: 0.008
2025-02-25 11:34:13.596825: train_loss -0.3652
2025-02-25 11:34:13.612414: val_loss -0.3504
2025-02-25 11:34:13.614387: Pseudo dice [0.6268, 0.7665, 0.7489, 0.6688]
2025-02-25 11:34:13.616318: Epoch time: 124.16 s
2025-02-25 11:34:13.617991: Yayy! New best EMA pseudo Dice: 0.5657
2025-02-25 11:34:18.123316: 
2025-02-25 11:34:18.125616: Epoch 23
2025-02-25 11:34:18.127635: Current learning rate: 0.0079
2025-02-25 11:36:31.412381: train_loss -0.3679
2025-02-25 11:36:31.422363: val_loss -0.3502
2025-02-25 11:36:31.426944: Pseudo dice [0.7571, 0.6942, 0.8099, 0.6401]
2025-02-25 11:36:31.428920: Epoch time: 133.29 s
2025-02-25 11:36:31.431943: Yayy! New best EMA pseudo Dice: 0.5817
2025-02-25 11:36:35.439513: 
2025-02-25 11:36:35.441761: Epoch 24
2025-02-25 11:36:35.444468: Current learning rate: 0.00781
2025-02-25 11:38:41.269634: train_loss -0.3781
2025-02-25 11:38:41.273844: val_loss -0.3573
2025-02-25 11:38:41.276111: Pseudo dice [0.6144, 0.7791, 0.7788, 0.6436]
2025-02-25 11:38:41.278362: Epoch time: 125.83 s
2025-02-25 11:38:41.280499: Yayy! New best EMA pseudo Dice: 0.5939
2025-02-25 11:38:46.050139: 
2025-02-25 11:38:46.052514: Epoch 25
2025-02-25 11:38:46.054308: Current learning rate: 0.00772
2025-02-25 11:41:08.251314: train_loss -0.3759
2025-02-25 11:41:08.272470: val_loss -0.3652
2025-02-25 11:41:08.274753: Pseudo dice [0.7596, 0.7667, 0.8092, 0.6337]
2025-02-25 11:41:08.277066: Epoch time: 142.2 s
2025-02-25 11:41:08.279149: Yayy! New best EMA pseudo Dice: 0.6087
2025-02-25 11:41:12.773834: 
2025-02-25 11:41:12.775983: Epoch 26
2025-02-25 11:41:12.777908: Current learning rate: 0.00763
2025-02-25 11:43:30.792078: train_loss -0.3647
2025-02-25 11:43:30.796285: val_loss -0.3461
2025-02-25 11:43:30.798237: Pseudo dice [0.6596, 0.6902, 0.7795, 0.6646]
2025-02-25 11:43:30.799993: Epoch time: 138.02 s
2025-02-25 11:43:30.801670: Yayy! New best EMA pseudo Dice: 0.6177
2025-02-25 11:43:35.442913: 
2025-02-25 11:43:35.446141: Epoch 27
2025-02-25 11:43:35.449283: Current learning rate: 0.00753
2025-02-25 11:45:49.510523: train_loss -0.3673
2025-02-25 11:45:49.517606: val_loss -0.3259
2025-02-25 11:45:49.520101: Pseudo dice [0.6953, 0.6946, 0.757, 0.6366]
2025-02-25 11:45:49.522573: Epoch time: 134.07 s
2025-02-25 11:45:49.524694: Yayy! New best EMA pseudo Dice: 0.6255
2025-02-25 11:45:53.939876: 
2025-02-25 11:45:53.942765: Epoch 28
2025-02-25 11:45:53.945792: Current learning rate: 0.00744
2025-02-25 11:47:56.906087: train_loss -0.381
2025-02-25 11:47:56.909967: val_loss -0.3618
2025-02-25 11:47:56.912159: Pseudo dice [0.737, 0.7532, 0.7868, 0.649]
2025-02-25 11:47:56.914146: Epoch time: 122.97 s
2025-02-25 11:47:56.916215: Yayy! New best EMA pseudo Dice: 0.6361
2025-02-25 11:48:01.565977: 
2025-02-25 11:48:01.567818: Epoch 29
2025-02-25 11:48:01.569209: Current learning rate: 0.00735
2025-02-25 11:50:03.289744: train_loss -0.3847
2025-02-25 11:50:03.293912: val_loss -0.4179
2025-02-25 11:50:03.296337: Pseudo dice [0.7492, 0.7829, 0.7747, 0.748]
2025-02-25 11:50:03.298634: Epoch time: 121.73 s
2025-02-25 11:50:03.300748: Yayy! New best EMA pseudo Dice: 0.6489
2025-02-25 11:50:07.775326: 
2025-02-25 11:50:07.778324: Epoch 30
2025-02-25 11:50:07.780930: Current learning rate: 0.00725
2025-02-25 11:52:14.110671: train_loss -0.3883
2025-02-25 11:52:14.114972: val_loss -0.3427
2025-02-25 11:52:14.117422: Pseudo dice [0.7002, 0.7459, 0.7752, 0.5631]
2025-02-25 11:52:14.119596: Epoch time: 126.34 s
2025-02-25 11:52:14.123653: Yayy! New best EMA pseudo Dice: 0.6536
2025-02-25 11:52:18.275226: 
2025-02-25 11:52:18.277608: Epoch 31
2025-02-25 11:52:18.279798: Current learning rate: 0.00716
2025-02-25 11:54:16.906511: train_loss -0.4069
2025-02-25 11:54:16.911705: val_loss -0.385
2025-02-25 11:54:16.913816: Pseudo dice [0.7374, 0.7656, 0.8043, 0.7271]
2025-02-25 11:54:16.915814: Epoch time: 118.63 s
2025-02-25 11:54:16.930556: Yayy! New best EMA pseudo Dice: 0.6641
2025-02-25 11:54:21.573753: 
2025-02-25 11:54:21.576133: Epoch 32
2025-02-25 11:54:21.578261: Current learning rate: 0.00707
2025-02-25 11:56:25.275569: train_loss -0.4003
2025-02-25 11:56:25.280920: val_loss -0.3762
2025-02-25 11:56:25.283283: Pseudo dice [0.7065, 0.7613, 0.8064, 0.6513]
2025-02-25 11:56:25.285537: Epoch time: 123.7 s
2025-02-25 11:56:25.288088: Yayy! New best EMA pseudo Dice: 0.6708
2025-02-25 11:56:29.961905: 
2025-02-25 11:56:29.964324: Epoch 33
2025-02-25 11:56:29.966587: Current learning rate: 0.00697
2025-02-25 11:58:36.362305: train_loss -0.4001
2025-02-25 11:58:36.380177: val_loss -0.3655
2025-02-25 11:58:36.382570: Pseudo dice [0.7189, 0.7567, 0.7214, 0.5606]
2025-02-25 11:58:36.384926: Epoch time: 126.4 s
2025-02-25 11:58:36.386916: Yayy! New best EMA pseudo Dice: 0.6727
2025-02-25 11:58:41.126792: 
2025-02-25 11:58:41.128909: Epoch 34
2025-02-25 11:58:41.130578: Current learning rate: 0.00688
2025-02-25 12:00:42.692948: train_loss -0.4185
2025-02-25 12:00:42.696646: val_loss -0.3869
2025-02-25 12:00:42.698616: Pseudo dice [0.7596, 0.7672, 0.8258, 0.6635]
2025-02-25 12:00:42.700416: Epoch time: 121.57 s
2025-02-25 12:00:42.702087: Yayy! New best EMA pseudo Dice: 0.6808
2025-02-25 12:00:47.015994: 
2025-02-25 12:00:47.018382: Epoch 35
2025-02-25 12:00:47.020516: Current learning rate: 0.00679
2025-02-25 12:02:44.018428: train_loss -0.4163
2025-02-25 12:02:44.022022: val_loss -0.41
2025-02-25 12:02:44.038596: Pseudo dice [0.7338, 0.8309, 0.8089, 0.741]
2025-02-25 12:02:44.041082: Epoch time: 117.01 s
2025-02-25 12:02:44.043183: Yayy! New best EMA pseudo Dice: 0.6906
2025-02-25 12:02:48.077760: 
2025-02-25 12:02:48.080133: Epoch 36
2025-02-25 12:02:48.082094: Current learning rate: 0.00669
2025-02-25 12:04:52.935556: train_loss -0.412
2025-02-25 12:04:52.939818: val_loss -0.3844
2025-02-25 12:04:52.942171: Pseudo dice [0.5821, 0.8086, 0.8027, 0.7394]
2025-02-25 12:04:52.944674: Epoch time: 124.86 s
2025-02-25 12:04:52.946720: Yayy! New best EMA pseudo Dice: 0.6949
2025-02-25 12:04:56.962706: 
2025-02-25 12:04:56.965135: Epoch 37
2025-02-25 12:04:56.967160: Current learning rate: 0.0066
2025-02-25 12:06:59.459951: train_loss -0.4072
2025-02-25 12:06:59.463825: val_loss -0.3683
2025-02-25 12:06:59.478862: Pseudo dice [0.7916, 0.7505, 0.8195, 0.5792]
2025-02-25 12:06:59.481263: Epoch time: 122.5 s
2025-02-25 12:06:59.489602: Yayy! New best EMA pseudo Dice: 0.6989
2025-02-25 12:07:04.120537: 
2025-02-25 12:07:04.122984: Epoch 38
2025-02-25 12:07:04.125181: Current learning rate: 0.0065
2025-02-25 12:09:11.425610: train_loss -0.4117
2025-02-25 12:09:11.430092: val_loss -0.3897
2025-02-25 12:09:11.441533: Pseudo dice [0.785, 0.7129, 0.8515, 0.7195]
2025-02-25 12:09:11.444060: Epoch time: 127.31 s
2025-02-25 12:09:11.446364: Yayy! New best EMA pseudo Dice: 0.7057
2025-02-25 12:09:15.717321: 
2025-02-25 12:09:15.719985: Epoch 39
2025-02-25 12:09:15.721965: Current learning rate: 0.00641
2025-02-25 12:11:21.972205: train_loss -0.4063
2025-02-25 12:11:21.976223: val_loss -0.3783
2025-02-25 12:11:21.978398: Pseudo dice [0.6956, 0.817, 0.7241, 0.7369]
2025-02-25 12:11:21.980530: Epoch time: 126.26 s
2025-02-25 12:11:21.982559: Yayy! New best EMA pseudo Dice: 0.7095
2025-02-25 12:11:25.907323: 
2025-02-25 12:11:25.909810: Epoch 40
2025-02-25 12:11:25.912179: Current learning rate: 0.00631
2025-02-25 12:13:33.340374: train_loss -0.4204
2025-02-25 12:13:33.344869: val_loss -0.4231
2025-02-25 12:13:33.347081: Pseudo dice [0.787, 0.8109, 0.8005, 0.7101]
2025-02-25 12:13:33.349208: Epoch time: 127.43 s
2025-02-25 12:13:33.351491: Yayy! New best EMA pseudo Dice: 0.7163
2025-02-25 12:13:37.928069: 
2025-02-25 12:13:37.930485: Epoch 41
2025-02-25 12:13:37.932724: Current learning rate: 0.00622
2025-02-25 12:15:51.099176: train_loss -0.4256
2025-02-25 12:15:51.103495: val_loss -0.392
2025-02-25 12:15:51.105309: Pseudo dice [0.7311, 0.8231, 0.7827, 0.75]
2025-02-25 12:15:51.107070: Epoch time: 133.17 s
2025-02-25 12:15:51.109002: Yayy! New best EMA pseudo Dice: 0.7218
2025-02-25 12:15:55.580035: 
2025-02-25 12:15:55.582653: Epoch 42
2025-02-25 12:15:55.585108: Current learning rate: 0.00612
2025-02-25 12:18:15.742923: train_loss -0.4341
2025-02-25 12:18:15.761582: val_loss -0.3909
2025-02-25 12:18:15.763652: Pseudo dice [0.7621, 0.787, 0.8113, 0.6561]
2025-02-25 12:18:15.765929: Epoch time: 140.17 s
2025-02-25 12:18:15.767830: Yayy! New best EMA pseudo Dice: 0.725
2025-02-25 12:18:19.521080: 
2025-02-25 12:18:19.523626: Epoch 43
2025-02-25 12:18:19.525879: Current learning rate: 0.00603
2025-02-25 12:20:35.849115: train_loss -0.4268
2025-02-25 12:20:35.856564: val_loss -0.4026
2025-02-25 12:20:35.858354: Pseudo dice [0.7156, 0.8091, 0.7987, 0.7269]
2025-02-25 12:20:35.860107: Epoch time: 136.33 s
2025-02-25 12:20:35.861917: Yayy! New best EMA pseudo Dice: 0.7288
2025-02-25 12:20:41.382470: 
2025-02-25 12:20:41.385030: Epoch 44
2025-02-25 12:20:41.387042: Current learning rate: 0.00593
2025-02-25 12:22:55.088470: train_loss -0.4348
2025-02-25 12:22:55.105706: val_loss -0.3661
2025-02-25 12:22:55.108379: Pseudo dice [0.7143, 0.7092, 0.8341, 0.723]
2025-02-25 12:22:55.110725: Epoch time: 133.71 s
2025-02-25 12:22:55.112928: Yayy! New best EMA pseudo Dice: 0.7304
2025-02-25 12:22:59.210677: 
2025-02-25 12:22:59.213174: Epoch 45
2025-02-25 12:22:59.215422: Current learning rate: 0.00584
2025-02-25 12:25:12.555495: train_loss -0.4278
2025-02-25 12:25:12.560765: val_loss -0.3775
2025-02-25 12:25:12.563392: Pseudo dice [0.594, 0.796, 0.7448, 0.7583]
2025-02-25 12:25:12.566098: Epoch time: 133.35 s
2025-02-25 12:25:14.146531: 
2025-02-25 12:25:14.149601: Epoch 46
2025-02-25 12:25:14.151717: Current learning rate: 0.00574
2025-02-25 12:27:30.827221: train_loss -0.4397
2025-02-25 12:27:30.841099: val_loss -0.4112
2025-02-25 12:27:30.843371: Pseudo dice [0.7448, 0.8101, 0.7971, 0.7104]
2025-02-25 12:27:30.845626: Epoch time: 136.68 s
2025-02-25 12:27:30.847913: Yayy! New best EMA pseudo Dice: 0.7333
2025-02-25 12:27:34.804933: 
2025-02-25 12:27:34.807683: Epoch 47
2025-02-25 12:27:34.810490: Current learning rate: 0.00565
2025-02-25 12:29:52.649407: train_loss -0.4295
2025-02-25 12:29:52.667508: val_loss -0.3795
2025-02-25 12:29:52.669867: Pseudo dice [0.7505, 0.7788, 0.8266, 0.6083]
2025-02-25 12:29:52.672238: Epoch time: 137.85 s
2025-02-25 12:29:52.674506: Yayy! New best EMA pseudo Dice: 0.7341
2025-02-25 12:29:57.065567: 
2025-02-25 12:29:57.068023: Epoch 48
2025-02-25 12:29:57.070470: Current learning rate: 0.00555
2025-02-25 12:32:02.401687: train_loss -0.4382
2025-02-25 12:32:02.415595: val_loss -0.3774
2025-02-25 12:32:02.417697: Pseudo dice [0.7764, 0.7726, 0.8179, 0.6787]
2025-02-25 12:32:02.419556: Epoch time: 125.34 s
2025-02-25 12:32:02.421335: Yayy! New best EMA pseudo Dice: 0.7368
2025-02-25 12:32:06.988048: 
2025-02-25 12:32:06.990747: Epoch 49
2025-02-25 12:32:06.992930: Current learning rate: 0.00546
2025-02-25 12:34:24.396742: train_loss -0.4517
2025-02-25 12:34:24.401554: val_loss -0.4
2025-02-25 12:34:24.403636: Pseudo dice [0.7927, 0.822, 0.8214, 0.7306]
2025-02-25 12:34:24.406466: Epoch time: 137.41 s
2025-02-25 12:34:26.730708: Yayy! New best EMA pseudo Dice: 0.7423
2025-02-25 12:34:30.410722: 
2025-02-25 12:34:30.413204: Epoch 50
2025-02-25 12:34:30.415125: Current learning rate: 0.00536
2025-02-25 12:36:22.591302: train_loss -0.4438
2025-02-25 12:36:22.609378: val_loss -0.3867
2025-02-25 12:36:22.611812: Pseudo dice [0.7382, 0.8038, 0.8149, 0.7242]
2025-02-25 12:36:22.614066: Epoch time: 112.18 s
2025-02-25 12:36:22.616311: Yayy! New best EMA pseudo Dice: 0.7451
2025-02-25 12:36:26.988664: 
2025-02-25 12:36:26.990760: Epoch 51
2025-02-25 12:36:26.993786: Current learning rate: 0.00526
2025-02-25 12:38:29.469076: train_loss -0.454
2025-02-25 12:38:29.476473: val_loss -0.3827
2025-02-25 12:38:29.488953: Pseudo dice [0.7861, 0.7972, 0.8092, 0.6814]
2025-02-25 12:38:29.490543: Epoch time: 122.48 s
2025-02-25 12:38:29.492088: Yayy! New best EMA pseudo Dice: 0.7474
2025-02-25 12:38:33.993853: 
2025-02-25 12:38:33.996044: Epoch 52
2025-02-25 12:38:33.997975: Current learning rate: 0.00517
2025-02-25 12:40:37.522885: train_loss -0.4556
2025-02-25 12:40:37.528318: val_loss -0.4042
2025-02-25 12:40:37.530907: Pseudo dice [0.76, 0.8354, 0.8363, 0.7576]
2025-02-25 12:40:37.533751: Epoch time: 123.53 s
2025-02-25 12:40:37.536364: Yayy! New best EMA pseudo Dice: 0.7524
2025-02-25 12:40:42.291239: 
2025-02-25 12:40:42.292680: Epoch 53
2025-02-25 12:40:42.293829: Current learning rate: 0.00507
2025-02-25 12:42:56.624782: train_loss -0.447
2025-02-25 12:42:56.638594: val_loss -0.3787
2025-02-25 12:42:56.641258: Pseudo dice [0.807, 0.824, 0.8188, 0.6432]
2025-02-25 12:42:56.643462: Epoch time: 134.34 s
2025-02-25 12:42:56.645625: Yayy! New best EMA pseudo Dice: 0.7545
2025-02-25 12:43:01.311306: 
2025-02-25 12:43:01.313815: Epoch 54
2025-02-25 12:43:01.315661: Current learning rate: 0.00497
2025-02-25 12:45:06.086787: train_loss -0.4533
2025-02-25 12:45:06.091017: val_loss -0.3996
2025-02-25 12:45:06.093328: Pseudo dice [0.7766, 0.8052, 0.8117, 0.7203]
2025-02-25 12:45:06.095459: Epoch time: 124.78 s
2025-02-25 12:45:06.097464: Yayy! New best EMA pseudo Dice: 0.7569
2025-02-25 12:45:10.513420: 
2025-02-25 12:45:10.515650: Epoch 55
2025-02-25 12:45:10.517708: Current learning rate: 0.00487
2025-02-25 12:47:20.579142: train_loss -0.4496
2025-02-25 12:47:20.582128: val_loss -0.4306
2025-02-25 12:47:20.583963: Pseudo dice [0.8345, 0.8352, 0.8544, 0.7431]
2025-02-25 12:47:20.586193: Epoch time: 130.07 s
2025-02-25 12:47:20.587899: Yayy! New best EMA pseudo Dice: 0.7629
2025-02-25 12:47:25.156641: 
2025-02-25 12:47:25.158978: Epoch 56
2025-02-25 12:47:25.161480: Current learning rate: 0.00478
2025-02-25 12:49:31.620980: train_loss -0.4405
2025-02-25 12:49:31.624631: val_loss -0.3921
2025-02-25 12:49:31.626684: Pseudo dice [0.8281, 0.7554, 0.847, 0.67]
2025-02-25 12:49:31.629056: Epoch time: 126.47 s
2025-02-25 12:49:31.632046: Yayy! New best EMA pseudo Dice: 0.7641
2025-02-25 12:49:35.738315: 
2025-02-25 12:49:35.740583: Epoch 57
2025-02-25 12:49:35.742406: Current learning rate: 0.00468
2025-02-25 12:51:54.336042: train_loss -0.4626
2025-02-25 12:51:54.339956: val_loss -0.4551
2025-02-25 12:51:54.342184: Pseudo dice [0.805, 0.8477, 0.8353, 0.7449]
2025-02-25 12:51:54.344436: Epoch time: 138.6 s
2025-02-25 12:51:54.346615: Yayy! New best EMA pseudo Dice: 0.7685
2025-02-25 12:51:58.472546: 
2025-02-25 12:51:58.474957: Epoch 58
2025-02-25 12:51:58.479686: Current learning rate: 0.00458
2025-02-25 12:54:12.576441: train_loss -0.4537
2025-02-25 12:54:12.580973: val_loss -0.4551
2025-02-25 12:54:12.583375: Pseudo dice [0.7955, 0.8534, 0.8022, 0.7262]
2025-02-25 12:54:12.585749: Epoch time: 134.11 s
2025-02-25 12:54:12.588231: Yayy! New best EMA pseudo Dice: 0.7711
2025-02-25 12:54:17.411237: 
2025-02-25 12:54:17.413867: Epoch 59
2025-02-25 12:54:17.416452: Current learning rate: 0.00448
2025-02-25 12:56:20.275567: train_loss -0.449
2025-02-25 12:56:20.280368: val_loss -0.4527
2025-02-25 12:56:20.282706: Pseudo dice [0.8227, 0.8496, 0.8094, 0.7362]
2025-02-25 12:56:20.285702: Epoch time: 122.87 s
2025-02-25 12:56:20.289595: Yayy! New best EMA pseudo Dice: 0.7744
2025-02-25 12:56:24.911075: 
2025-02-25 12:56:24.913815: Epoch 60
2025-02-25 12:56:24.916205: Current learning rate: 0.00438
2025-02-25 12:58:31.276702: train_loss -0.4498
2025-02-25 12:58:31.294095: val_loss -0.412
2025-02-25 12:58:31.297000: Pseudo dice [0.7271, 0.8466, 0.7996, 0.773]
2025-02-25 12:58:31.299870: Epoch time: 126.37 s
2025-02-25 12:58:31.301842: Yayy! New best EMA pseudo Dice: 0.7757
2025-02-25 12:58:35.905251: 
2025-02-25 12:58:35.907982: Epoch 61
2025-02-25 12:58:35.910357: Current learning rate: 0.00429
2025-02-25 13:00:46.704049: train_loss -0.448
2025-02-25 13:00:46.709574: val_loss -0.4051
2025-02-25 13:00:46.714073: Pseudo dice [0.8, 0.825, 0.8453, 0.6988]
2025-02-25 13:00:46.718323: Epoch time: 130.8 s
2025-02-25 13:00:46.728640: Yayy! New best EMA pseudo Dice: 0.7773
2025-02-25 13:00:50.577089: 
2025-02-25 13:00:50.579660: Epoch 62
2025-02-25 13:00:50.581911: Current learning rate: 0.00419
2025-02-25 13:02:57.332801: train_loss -0.4608
2025-02-25 13:02:57.342262: val_loss -0.4134
2025-02-25 13:02:57.344999: Pseudo dice [0.7846, 0.8081, 0.8435, 0.7381]
2025-02-25 13:02:57.356193: Epoch time: 126.76 s
2025-02-25 13:02:57.359169: Yayy! New best EMA pseudo Dice: 0.7789
2025-02-25 13:03:02.750529: 
2025-02-25 13:03:02.753415: Epoch 63
2025-02-25 13:03:02.755276: Current learning rate: 0.00409
2025-02-25 13:05:10.671548: train_loss -0.4533
2025-02-25 13:05:10.684616: val_loss -0.4406
2025-02-25 13:05:10.687819: Pseudo dice [0.8092, 0.8423, 0.8517, 0.7613]
2025-02-25 13:05:10.690644: Epoch time: 127.92 s
2025-02-25 13:05:10.693856: Yayy! New best EMA pseudo Dice: 0.7827
2025-02-25 13:05:15.177661: 
2025-02-25 13:05:15.182569: Epoch 64
2025-02-25 13:05:15.185148: Current learning rate: 0.00399
2025-02-25 13:07:16.003580: train_loss -0.4591
2025-02-25 13:07:16.008073: val_loss -0.4121
2025-02-25 13:07:16.010423: Pseudo dice [0.7647, 0.8433, 0.8063, 0.7717]
2025-02-25 13:07:16.012717: Epoch time: 120.83 s
2025-02-25 13:07:16.014638: Yayy! New best EMA pseudo Dice: 0.784
2025-02-25 13:07:19.969182: 
2025-02-25 13:07:19.972012: Epoch 65
2025-02-25 13:07:19.974295: Current learning rate: 0.00389
2025-02-25 13:09:26.831825: train_loss -0.4628
2025-02-25 13:09:26.837606: val_loss -0.4072
2025-02-25 13:09:26.840490: Pseudo dice [0.7427, 0.8167, 0.7845, 0.6945]
2025-02-25 13:09:26.843015: Epoch time: 126.86 s
2025-02-25 13:09:29.176198: 
2025-02-25 13:09:29.178219: Epoch 66
2025-02-25 13:09:29.180493: Current learning rate: 0.00379
2025-02-25 13:11:50.943140: train_loss -0.4716
2025-02-25 13:11:50.951078: val_loss -0.4054
2025-02-25 13:11:50.964528: Pseudo dice [0.8289, 0.8033, 0.8555, 0.6658]
2025-02-25 13:11:50.967061: Epoch time: 141.77 s
2025-02-25 13:11:52.628678: 
2025-02-25 13:11:52.631593: Epoch 67
2025-02-25 13:11:52.633899: Current learning rate: 0.00369
2025-02-25 13:13:58.673652: train_loss -0.4569
2025-02-25 13:13:58.678473: val_loss -0.3932
2025-02-25 13:13:58.681798: Pseudo dice [0.7161, 0.8083, 0.769, 0.7119]
2025-02-25 13:13:58.695753: Epoch time: 126.05 s
2025-02-25 13:14:00.358043: 
2025-02-25 13:14:00.361223: Epoch 68
2025-02-25 13:14:00.363717: Current learning rate: 0.00359
2025-02-25 13:16:12.732346: train_loss -0.4621
2025-02-25 13:16:12.737396: val_loss -0.3818
2025-02-25 13:16:12.739512: Pseudo dice [0.6081, 0.7923, 0.738, 0.7185]
2025-02-25 13:16:12.741960: Epoch time: 132.38 s
2025-02-25 13:16:14.989351: 
2025-02-25 13:16:14.992439: Epoch 69
2025-02-25 13:16:14.995155: Current learning rate: 0.00349
2025-02-25 13:18:23.136862: train_loss -0.4648
2025-02-25 13:18:23.142344: val_loss -0.4287
2025-02-25 13:18:23.144936: Pseudo dice [0.7783, 0.811, 0.8407, 0.7082]
2025-02-25 13:18:23.147392: Epoch time: 128.15 s
2025-02-25 13:18:24.824905: 
2025-02-25 13:18:24.827528: Epoch 70
2025-02-25 13:18:24.829798: Current learning rate: 0.00338
2025-02-25 13:20:30.042060: train_loss -0.492
2025-02-25 13:20:30.046496: val_loss -0.418
2025-02-25 13:20:30.048993: Pseudo dice [0.7956, 0.8359, 0.8435, 0.7376]
2025-02-25 13:20:30.068743: Epoch time: 125.22 s
2025-02-25 13:20:31.836660: 
2025-02-25 13:20:32.032896: Epoch 71
2025-02-25 13:20:32.185213: Current learning rate: 0.00328
2025-02-25 13:22:42.057070: train_loss -0.4745
2025-02-25 13:22:42.332742: val_loss -0.4463
2025-02-25 13:22:42.352353: Pseudo dice [0.756, 0.8635, 0.818, 0.8075]
2025-02-25 13:22:42.354012: Epoch time: 130.22 s
2025-02-25 13:22:44.806117: 
2025-02-25 13:22:44.968845: Epoch 72
2025-02-25 13:22:45.094472: Current learning rate: 0.00318
2025-02-25 13:24:51.557798: train_loss -0.4769
2025-02-25 13:24:51.837782: val_loss -0.4434
2025-02-25 13:24:51.874950: Pseudo dice [0.8416, 0.8678, 0.8583, 0.792]
2025-02-25 13:24:51.877310: Epoch time: 126.75 s
2025-02-25 13:24:51.948698: Yayy! New best EMA pseudo Dice: 0.7862
2025-02-25 13:24:56.365574: 
2025-02-25 13:24:56.448619: Epoch 73
2025-02-25 13:24:56.451625: Current learning rate: 0.00308
2025-02-25 13:27:01.068564: train_loss -0.4658
2025-02-25 13:27:01.092309: val_loss -0.4145
2025-02-25 13:27:01.094430: Pseudo dice [0.7503, 0.8468, 0.8078, 0.7773]
2025-02-25 13:27:01.096502: Epoch time: 124.7 s
2025-02-25 13:27:01.097839: Yayy! New best EMA pseudo Dice: 0.7871
2025-02-25 13:27:05.262252: 
2025-02-25 13:27:05.467110: Epoch 74
2025-02-25 13:27:05.601553: Current learning rate: 0.00297
2025-02-25 13:29:23.259277: train_loss -0.4768
2025-02-25 13:29:23.263837: val_loss -0.4001
2025-02-25 13:29:23.266273: Pseudo dice [0.6064, 0.8241, 0.722, 0.753]
2025-02-25 13:29:23.268529: Epoch time: 138.0 s
2025-02-25 13:29:25.516027: 
2025-02-25 13:29:25.520086: Epoch 75
2025-02-25 13:29:25.522355: Current learning rate: 0.00287
2025-02-25 13:31:30.760827: train_loss -0.4799
2025-02-25 13:31:31.032017: val_loss -0.4059
2025-02-25 13:31:31.157551: Pseudo dice [0.7519, 0.8351, 0.8345, 0.775]
2025-02-25 13:31:31.159912: Epoch time: 125.25 s
2025-02-25 13:31:33.527859: 
2025-02-25 13:31:33.674073: Epoch 76
2025-02-25 13:31:33.781290: Current learning rate: 0.00277
2025-02-25 13:33:51.344588: train_loss -0.4833
2025-02-25 13:33:51.369085: val_loss -0.4308
2025-02-25 13:33:51.372322: Pseudo dice [0.7469, 0.817, 0.7762, 0.7658]
2025-02-25 13:33:51.384225: Epoch time: 137.82 s
2025-02-25 13:33:53.129261: 
2025-02-25 13:33:53.296147: Epoch 77
2025-02-25 13:33:53.412414: Current learning rate: 0.00266
2025-02-25 13:36:10.939207: train_loss -0.4734
2025-02-25 13:36:11.037458: val_loss -0.4396
2025-02-25 13:36:11.132162: Pseudo dice [0.6983, 0.8548, 0.8163, 0.8045]
2025-02-25 13:36:11.136065: Epoch time: 137.81 s
2025-02-25 13:36:13.486475: 
2025-02-25 13:36:13.578457: Epoch 78
2025-02-25 13:36:13.584023: Current learning rate: 0.00256
2025-02-25 13:38:25.579442: train_loss -0.4737
2025-02-25 13:38:25.846822: val_loss -0.4243
2025-02-25 13:38:25.945370: Pseudo dice [0.7126, 0.8501, 0.7738, 0.7782]
2025-02-25 13:38:25.947708: Epoch time: 132.09 s
2025-02-25 13:38:28.463121: 
2025-02-25 13:38:28.573733: Epoch 79
2025-02-25 13:38:28.575907: Current learning rate: 0.00245
2025-02-25 13:40:36.171051: train_loss -0.4784
2025-02-25 13:40:36.184804: val_loss -0.4391
2025-02-25 13:40:36.187150: Pseudo dice [0.8111, 0.8373, 0.8545, 0.7279]
2025-02-25 13:40:36.189397: Epoch time: 127.71 s
2025-02-25 13:40:39.302868: 
2025-02-25 13:40:39.305043: Epoch 80
2025-02-25 13:40:39.307013: Current learning rate: 0.00235
2025-02-25 13:42:49.621856: train_loss -0.484
2025-02-25 13:42:49.723555: val_loss -0.4241
2025-02-25 13:42:49.725748: Pseudo dice [0.8, 0.839, 0.848, 0.7417]
2025-02-25 13:42:49.728382: Epoch time: 130.32 s
2025-02-25 13:42:49.730311: Yayy! New best EMA pseudo Dice: 0.7875
2025-02-25 13:42:54.037010: 
2025-02-25 13:42:54.039580: Epoch 81
2025-02-25 13:42:54.041233: Current learning rate: 0.00224
2025-02-25 13:45:06.435144: train_loss -0.4887
2025-02-25 13:45:06.437557: val_loss -0.3749
2025-02-25 13:45:06.438749: Pseudo dice [0.622, 0.8265, 0.697, 0.7446]
2025-02-25 13:45:06.439875: Epoch time: 132.4 s
2025-02-25 13:45:08.805268: 
2025-02-25 13:45:08.807614: Epoch 82
2025-02-25 13:45:08.809507: Current learning rate: 0.00214
2025-02-25 13:47:19.930922: train_loss -0.4808
2025-02-25 13:47:19.937365: val_loss -0.4183
2025-02-25 13:47:19.940030: Pseudo dice [0.7829, 0.8346, 0.806, 0.7062]
2025-02-25 13:47:19.945018: Epoch time: 131.13 s
2025-02-25 13:47:21.547075: 
2025-02-25 13:47:21.549669: Epoch 83
2025-02-25 13:47:21.552063: Current learning rate: 0.00203
2025-02-25 13:49:23.994224: train_loss -0.4756
2025-02-25 13:49:24.000129: val_loss -0.4412
2025-02-25 13:49:24.002900: Pseudo dice [0.7981, 0.858, 0.839, 0.7825]
2025-02-25 13:49:24.005545: Epoch time: 122.45 s
2025-02-25 13:49:26.231445: 
2025-02-25 13:49:26.234426: Epoch 84
2025-02-25 13:49:26.236957: Current learning rate: 0.00192
2025-02-25 13:51:37.605639: train_loss -0.4891
2025-02-25 13:51:37.610587: val_loss -0.4351
2025-02-25 13:51:37.613083: Pseudo dice [0.7559, 0.8441, 0.7929, 0.7674]
2025-02-25 13:51:37.615101: Epoch time: 131.38 s
2025-02-25 13:51:39.746151: 
2025-02-25 13:51:39.749867: Epoch 85
2025-02-25 13:51:39.751981: Current learning rate: 0.00181
2025-02-25 13:53:54.410701: train_loss -0.4856
2025-02-25 13:53:54.420589: val_loss -0.4121
2025-02-25 13:53:54.425900: Pseudo dice [0.7901, 0.822, 0.8535, 0.6954]
2025-02-25 13:53:54.431420: Epoch time: 134.67 s
2025-02-25 13:53:56.629403: 
2025-02-25 13:53:56.632838: Epoch 86
2025-02-25 13:53:56.636242: Current learning rate: 0.0017
2025-02-25 13:56:01.777194: train_loss -0.4844
2025-02-25 13:56:01.782712: val_loss -0.4352
2025-02-25 13:56:01.786761: Pseudo dice [0.7397, 0.8582, 0.7462, 0.7675]
2025-02-25 13:56:01.790583: Epoch time: 125.15 s
2025-02-25 13:56:04.075227: 
2025-02-25 13:56:04.077924: Epoch 87
2025-02-25 13:56:04.079803: Current learning rate: 0.00159
2025-02-25 13:58:10.891591: train_loss -0.4865
2025-02-25 13:58:10.898846: val_loss -0.4248
2025-02-25 13:58:10.900433: Pseudo dice [0.8227, 0.8516, 0.8603, 0.7683]
2025-02-25 13:58:10.902163: Epoch time: 126.82 s
2025-02-25 13:58:10.904598: Yayy! New best EMA pseudo Dice: 0.7892
2025-02-25 13:58:15.326159: 
2025-02-25 13:58:15.328762: Epoch 88
2025-02-25 13:58:15.330939: Current learning rate: 0.00148
2025-02-25 14:00:18.399498: train_loss -0.4846
2025-02-25 14:00:18.416755: val_loss -0.4184
2025-02-25 14:00:18.419538: Pseudo dice [0.7375, 0.8359, 0.794, 0.7426]
2025-02-25 14:00:18.422405: Epoch time: 123.08 s
2025-02-25 14:00:20.029105: 
2025-02-25 14:00:20.031835: Epoch 89
2025-02-25 14:00:20.034206: Current learning rate: 0.00137
2025-02-25 14:02:30.903061: train_loss -0.503
2025-02-25 14:02:30.920614: val_loss -0.4379
2025-02-25 14:02:30.922684: Pseudo dice [0.826, 0.8463, 0.8391, 0.7576]
2025-02-25 14:02:30.924639: Epoch time: 130.88 s
2025-02-25 14:02:30.926961: Yayy! New best EMA pseudo Dice: 0.791
2025-02-25 14:02:35.601345: 
2025-02-25 14:02:35.603915: Epoch 90
2025-02-25 14:02:35.606256: Current learning rate: 0.00126
2025-02-25 14:04:35.925150: train_loss -0.4866
2025-02-25 14:04:35.928472: val_loss -0.4297
2025-02-25 14:04:35.930272: Pseudo dice [0.786, 0.8363, 0.8428, 0.7489]
2025-02-25 14:04:35.931934: Epoch time: 120.33 s
2025-02-25 14:04:35.933518: Yayy! New best EMA pseudo Dice: 0.7922
2025-02-25 14:04:40.370129: 
2025-02-25 14:04:40.372544: Epoch 91
2025-02-25 14:04:40.374713: Current learning rate: 0.00115
2025-02-25 14:06:54.196749: train_loss -0.499
2025-02-25 14:06:54.213845: val_loss -0.4239
2025-02-25 14:06:54.216194: Pseudo dice [0.7128, 0.8707, 0.8036, 0.7914]
2025-02-25 14:06:54.218236: Epoch time: 133.83 s
2025-02-25 14:06:54.219698: Yayy! New best EMA pseudo Dice: 0.7925
2025-02-25 14:06:58.521773: 
2025-02-25 14:06:58.524332: Epoch 92
2025-02-25 14:06:58.526433: Current learning rate: 0.00103
2025-02-25 14:09:02.359477: train_loss -0.4979
2025-02-25 14:09:02.376127: val_loss -0.4064
2025-02-25 14:09:02.378998: Pseudo dice [0.8072, 0.8258, 0.8499, 0.7417]
2025-02-25 14:09:02.381475: Epoch time: 123.84 s
2025-02-25 14:09:02.383808: Yayy! New best EMA pseudo Dice: 0.7938
2025-02-25 14:09:06.427892: 
2025-02-25 14:09:06.430406: Epoch 93
2025-02-25 14:09:06.432781: Current learning rate: 0.00091
2025-02-25 14:11:12.711922: train_loss -0.4956
2025-02-25 14:11:12.716528: val_loss -0.4594
2025-02-25 14:11:12.719128: Pseudo dice [0.7683, 0.8841, 0.8233, 0.7804]
2025-02-25 14:11:12.721705: Epoch time: 126.29 s
2025-02-25 14:11:12.723958: Yayy! New best EMA pseudo Dice: 0.7959
2025-02-25 14:11:17.506540: 
2025-02-25 14:11:17.508859: Epoch 94
2025-02-25 14:11:17.511085: Current learning rate: 0.00079
2025-02-25 14:13:25.276013: train_loss -0.4921
2025-02-25 14:13:25.284753: val_loss -0.4038
2025-02-25 14:13:25.287492: Pseudo dice [0.7727, 0.8554, 0.8059, 0.7647]
2025-02-25 14:13:25.290195: Epoch time: 127.77 s
2025-02-25 14:13:25.292077: Yayy! New best EMA pseudo Dice: 0.7962
2025-02-25 14:13:29.880026: 
2025-02-25 14:13:29.883070: Epoch 95
2025-02-25 14:13:29.885636: Current learning rate: 0.00067
2025-02-25 14:15:42.021129: train_loss -0.4938
2025-02-25 14:15:42.027196: val_loss -0.4151
2025-02-25 14:15:42.029895: Pseudo dice [0.7078, 0.8682, 0.7634, 0.7672]
2025-02-25 14:15:42.032403: Epoch time: 132.14 s
2025-02-25 14:15:44.131878: 
2025-02-25 14:15:44.135037: Epoch 96
2025-02-25 14:15:44.137451: Current learning rate: 0.00055
2025-02-25 14:17:53.729656: train_loss -0.5035
2025-02-25 14:17:53.735269: val_loss -0.4544
2025-02-25 14:17:53.738534: Pseudo dice [0.8087, 0.8657, 0.8261, 0.7725]
2025-02-25 14:17:53.745585: Epoch time: 129.6 s
2025-02-25 14:17:53.748113: Yayy! New best EMA pseudo Dice: 0.7967
2025-02-25 14:17:58.399056: 
2025-02-25 14:17:58.402499: Epoch 97
2025-02-25 14:17:58.406114: Current learning rate: 0.00043
2025-02-25 14:20:06.195241: train_loss -0.4935
2025-02-25 14:20:06.201104: val_loss -0.4133
2025-02-25 14:20:06.216056: Pseudo dice [0.7321, 0.8577, 0.7932, 0.7446]
2025-02-25 14:20:06.217793: Epoch time: 127.8 s
2025-02-25 14:20:08.356188: 
2025-02-25 14:20:08.358420: Epoch 98
2025-02-25 14:20:08.360726: Current learning rate: 0.0003
2025-02-25 14:22:15.578192: train_loss -0.5056
2025-02-25 14:22:15.615852: val_loss -0.4272
2025-02-25 14:22:15.669857: Pseudo dice [0.7367, 0.8604, 0.8187, 0.7679]
2025-02-25 14:22:15.723942: Epoch time: 127.22 s
2025-02-25 14:22:18.690665: 
2025-02-25 14:22:18.692412: Epoch 99
2025-02-25 14:22:18.693955: Current learning rate: 0.00016
2025-02-25 14:24:20.832520: train_loss -0.4959
2025-02-25 14:24:20.837538: val_loss -0.4149
2025-02-25 14:24:20.853044: Pseudo dice [0.6845, 0.8566, 0.7799, 0.7793]
2025-02-25 14:24:20.859826: Epoch time: 122.14 s
2025-02-25 14:24:24.748980: Training done.
2025-02-25 14:24:24.803144: Using splits from existing split file: /home3/hghr96/parm/work/AD_project/segmentation/nnUNet/data/nnUNet_preprocessed/Dataset501_AD/splits_final.json
2025-02-25 14:24:24.816181: The split file contains 5 splits.
2025-02-25 14:24:24.819665: Desired fold for training: 0
2025-02-25 14:24:24.830165: This split has 70 training and 18 validation cases.
2025-02-25 14:24:24.841136: predicting ad_003
2025-02-25 14:24:24.849440: ad_003, shape torch.Size([1, 178, 266, 178]), rank 0
2025-02-25 14:24:48.478007: predicting ad_005
2025-02-25 14:24:48.482254: ad_005, shape torch.Size([1, 134, 252, 134]), rank 0
2025-02-25 14:31:44.344490: predicting ad_007
2025-02-25 14:31:44.360026: ad_007, shape torch.Size([1, 181, 215, 181]), rank 0
2025-02-25 14:36:06.823669: predicting ad_010
2025-02-25 14:36:06.835247: ad_010, shape torch.Size([1, 170, 295, 170]), rank 0
2025-02-25 14:39:17.374113: predicting ad_014
2025-02-25 14:39:17.386541: ad_014, shape torch.Size([1, 179, 192, 179]), rank 0
2025-02-25 14:48:14.672208: predicting ad_021
2025-02-25 14:48:14.688507: ad_021, shape torch.Size([1, 175, 287, 175]), rank 0
2025-02-25 14:51:04.461651: predicting ad_031
2025-02-25 14:51:04.477200: ad_031, shape torch.Size([1, 189, 377, 189]), rank 0
2025-02-25 14:55:20.809448: predicting ad_038
2025-02-25 14:55:20.824686: ad_038, shape torch.Size([1, 197, 334, 197]), rank 0
2025-02-25 15:02:45.273937: predicting ad_040
2025-02-25 15:02:45.290639: ad_040, shape torch.Size([1, 177, 339, 177]), rank 0
2025-02-25 15:10:33.374672: predicting ad_043
2025-02-25 15:10:33.389220: ad_043, shape torch.Size([1, 164, 304, 164]), rank 0
2025-02-25 15:18:08.705325: predicting ad_046
2025-02-25 15:18:08.718748: ad_046, shape torch.Size([1, 176, 323, 176]), rank 0
2025-02-25 15:22:23.122338: predicting ad_049
2025-02-25 15:22:23.134460: ad_049, shape torch.Size([1, 182, 327, 182]), rank 0
2025-02-25 15:28:07.545057: predicting ad_053
2025-02-25 15:28:07.560518: ad_053, shape torch.Size([1, 154, 330, 154]), rank 0
2025-02-25 15:38:52.083193: predicting ad_073
2025-02-25 15:38:52.098241: ad_073, shape torch.Size([1, 163, 293, 163]), rank 0
2025-02-25 15:44:19.016415: predicting ad_079
2025-02-25 15:44:19.032943: ad_079, shape torch.Size([1, 207, 341, 207]), rank 0
2025-02-25 15:48:30.378650: predicting ad_084
2025-02-25 15:48:30.394579: ad_084, shape torch.Size([1, 181, 265, 181]), rank 0
2025-02-25 15:57:09.497276: predicting ad_094
2025-02-25 15:57:09.515283: ad_094, shape torch.Size([1, 284, 215, 284]), rank 0
2025-02-25 16:03:09.661183: predicting ad_102
2025-02-25 16:03:09.680257: ad_102, shape torch.Size([1, 162, 219, 162]), rank 0
2025-02-25 16:15:12.998371: Validation complete
2025-02-25 16:15:13.002027: Mean Validation Dice:  0.6329007323268875
Finished at Tue 25 Feb 2025 04:15:16 PM GMT
Total Execution Time: 20193 seconds
