Starting at Thu 20 Feb 2025 11:18:04 PM GMT

############################
INFO: You are using the old nnU-Net default plans. We have updated our recommendations. Please consider using those instead! Read more here: https://github.com/MIC-DKFZ/nnUNet/blob/master/documentation/resenc_presets.md
############################

Using device: cuda:0

#######################################################################
Please cite the following paper when using nnU-Net:
Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.
#######################################################################

2025-02-20 23:18:32.618724: do_dummy_2d_data_aug: False
2025-02-20 23:18:32.641688: Using splits from existing split file: /home3/hghr96/parm/work/AD_project/segmentation/nnUNet/data/nnUNet_preprocess/Dataset501_AD/splits_final.json
2025-02-20 23:18:32.648662: The split file contains 5 splits.
2025-02-20 23:18:32.651047: Desired fold for training: 3
2025-02-20 23:18:32.653396: This split has 71 training and 17 validation cases.
using pin_memory on device 0
/home3/hghr96/miniconda3/envs/nnUnet/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
using pin_memory on device 0

This is the configuration used by this training:
Configuration name: 3d_fullres
 {'data_identifier': 'nnUNetPlans_3d_fullres', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 2, 'patch_size': [112, 192, 112], 'median_image_size_in_voxels': [512.0, 834.0, 512.0], 'spacing': [0.78515625, 0.7000000476837158, 0.78515625], 'normalization_schemes': ['CTNormalization'], 'use_mask_for_norm': [False], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.PlainConvUNet', 'arch_kwargs': {'n_stages': 6, 'features_per_stage': [32, 64, 128, 256, 320, 320], 'conv_op': 'torch.nn.modules.conv.Conv3d', 'kernel_sizes': [[3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]], 'strides': [[1, 1, 1], [2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2], [1, 2, 1]], 'n_conv_per_stage': [2, 2, 2, 2, 2, 2], 'n_conv_per_stage_decoder': [2, 2, 2, 2, 2], 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm3d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}}, '_kw_requires_import': ['conv_op', 'norm_op', 'dropout_op', 'nonlin']}, 'batch_dice': True} 

These are the global plan.json settings:
 {'dataset_name': 'Dataset501_AD', 'plans_name': 'nnUNetPlans', 'original_median_spacing_after_transp': [0.78515625, 0.7000000476837158, 0.78515625], 'original_median_shape_after_transp': [512, 800, 512], 'image_reader_writer': 'SimpleITKIO', 'transpose_forward': [1, 0, 2], 'transpose_backward': [1, 0, 2], 'experiment_planner_used': 'ExperimentPlanner', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 3071.0, 'mean': 161.64767456054688, 'median': 182.0, 'min': -1103.0, 'percentile_00_5': -840.0, 'percentile_99_5': 778.0, 'std': 241.90689086914062}}} 

2025-02-20 23:18:43.023433: unpacking dataset...
2025-02-20 23:19:02.722046: unpacking done...
2025-02-20 23:19:02.808308: Unable to plot network architecture:
2025-02-20 23:19:02.820834: No module named 'hiddenlayer'
2025-02-20 23:19:02.905012: 
2025-02-20 23:19:02.916929: Epoch 0
2025-02-20 23:19:02.928579: Current learning rate: 0.01
2025-02-20 23:24:03.043669: train_loss 0.5033
2025-02-20 23:24:03.049798: val_loss 0.3656
2025-02-20 23:24:03.057041: Pseudo dice [0.0, 0.0, 0.0, 0.0]
2025-02-20 23:24:03.062447: Epoch time: 300.14 s
2025-02-20 23:24:03.069173: Yayy! New best EMA pseudo Dice: 0.0
2025-02-20 23:24:06.733714: 
2025-02-20 23:24:06.736660: Epoch 1
2025-02-20 23:24:06.739238: Current learning rate: 0.00991
2025-02-20 23:27:10.902340: train_loss 0.3788
2025-02-20 23:27:10.907780: val_loss 0.3738
2025-02-20 23:27:10.911243: Pseudo dice [0.0, 0.0, 0.0, 0.0]
2025-02-20 23:27:10.914865: Epoch time: 184.17 s
2025-02-20 23:27:12.580460: 
2025-02-20 23:27:12.583506: Epoch 2
2025-02-20 23:27:12.586599: Current learning rate: 0.00982
2025-02-20 23:29:41.598418: train_loss 0.3353
2025-02-20 23:29:41.602436: val_loss 0.3216
2025-02-20 23:29:41.605371: Pseudo dice [0.0, 0.0, 0.0, 0.0]
2025-02-20 23:29:41.607629: Epoch time: 149.02 s
2025-02-20 23:29:43.089508: 
2025-02-20 23:29:43.097285: Epoch 3
2025-02-20 23:29:43.102123: Current learning rate: 0.00973
2025-02-20 23:32:07.718601: train_loss 0.3198
2025-02-20 23:32:07.723503: val_loss 0.3334
2025-02-20 23:32:07.727036: Pseudo dice [0.0, 0.0, 0.0, 0.0]
2025-02-20 23:32:07.730426: Epoch time: 144.63 s
2025-02-20 23:32:09.401268: 
2025-02-20 23:32:09.404083: Epoch 4
2025-02-20 23:32:09.406503: Current learning rate: 0.00964
2025-02-20 23:34:24.399657: train_loss 0.2675
2025-02-20 23:34:24.403436: val_loss 0.2465
2025-02-20 23:34:24.406460: Pseudo dice [0.0, 0.0, 0.0431, 0.3693]
2025-02-20 23:34:24.409068: Epoch time: 135.0 s
2025-02-20 23:34:24.413752: Yayy! New best EMA pseudo Dice: 0.0103
2025-02-20 23:34:28.306026: 
2025-02-20 23:34:28.310531: Epoch 5
2025-02-20 23:34:28.315411: Current learning rate: 0.00955
2025-02-20 23:36:36.141724: train_loss 0.251
2025-02-20 23:36:36.148655: val_loss 0.2247
2025-02-20 23:36:36.151293: Pseudo dice [0.0, 0.2543, 0.1148, 0.0563]
2025-02-20 23:36:36.153851: Epoch time: 127.84 s
2025-02-20 23:36:36.156435: Yayy! New best EMA pseudo Dice: 0.0199
2025-02-20 23:36:40.449816: 
2025-02-20 23:36:40.452482: Epoch 6
2025-02-20 23:36:40.454610: Current learning rate: 0.00946
2025-02-20 23:38:40.810830: train_loss 0.2356
2025-02-20 23:38:40.818689: val_loss 0.1971
2025-02-20 23:38:40.824378: Pseudo dice [0.0, 0.1212, 0.0091, 0.3059]
2025-02-20 23:38:40.830837: Epoch time: 120.36 s
2025-02-20 23:38:40.837288: Yayy! New best EMA pseudo Dice: 0.0288
2025-02-20 23:38:45.236833: 
2025-02-20 23:38:45.240062: Epoch 7
2025-02-20 23:38:45.242696: Current learning rate: 0.00937
2025-02-20 23:40:47.714885: train_loss 0.2065
2025-02-20 23:40:47.730510: val_loss 0.1847
2025-02-20 23:40:47.735560: Pseudo dice [0.0, 0.0007, 0.0015, 0.4248]
2025-02-20 23:40:47.744731: Epoch time: 122.48 s
2025-02-20 23:40:47.752475: Yayy! New best EMA pseudo Dice: 0.0366
2025-02-20 23:40:52.295898: 
2025-02-20 23:40:52.298261: Epoch 8
2025-02-20 23:40:52.300580: Current learning rate: 0.00928
2025-02-20 23:42:44.015187: train_loss 0.2069
2025-02-20 23:42:44.020503: val_loss 0.1647
2025-02-20 23:42:44.026315: Pseudo dice [0.0, 0.1972, 0.0, 0.4505]
2025-02-20 23:42:44.029335: Epoch time: 111.72 s
2025-02-20 23:42:44.034135: Yayy! New best EMA pseudo Dice: 0.0491
2025-02-20 23:42:48.142004: 
2025-02-20 23:42:48.145501: Epoch 9
2025-02-20 23:42:48.148395: Current learning rate: 0.00919
2025-02-20 23:44:35.966647: train_loss 0.1765
2025-02-20 23:44:35.970245: val_loss 0.1896
2025-02-20 23:44:35.973039: Pseudo dice [0.0, 0.2906, 0.4113, 0.3672]
2025-02-20 23:44:35.975553: Epoch time: 107.83 s
2025-02-20 23:44:35.977952: Yayy! New best EMA pseudo Dice: 0.071
2025-02-20 23:44:39.714231: 
2025-02-20 23:44:39.718250: Epoch 10
2025-02-20 23:44:39.723531: Current learning rate: 0.0091
2025-02-20 23:46:38.879730: train_loss 0.1893
2025-02-20 23:46:38.884965: val_loss 0.1277
2025-02-20 23:46:38.887351: Pseudo dice [0.0, 0.0282, 0.3111, 0.5662]
2025-02-20 23:46:38.889732: Epoch time: 119.17 s
2025-02-20 23:46:38.892287: Yayy! New best EMA pseudo Dice: 0.0865
2025-02-20 23:46:43.337818: 
2025-02-20 23:46:43.341057: Epoch 11
2025-02-20 23:46:43.343781: Current learning rate: 0.009
2025-02-20 23:48:33.461953: train_loss 0.158
2025-02-20 23:48:33.467241: val_loss 0.1177
2025-02-20 23:48:33.469984: Pseudo dice [0.0, 0.3396, 0.4383, 0.2647]
2025-02-20 23:48:33.472474: Epoch time: 110.13 s
2025-02-20 23:48:33.475089: Yayy! New best EMA pseudo Dice: 0.1039
2025-02-20 23:48:37.471228: 
2025-02-20 23:48:37.474040: Epoch 12
2025-02-20 23:48:37.476353: Current learning rate: 0.00891
2025-02-20 23:50:40.514348: train_loss 0.1498
2025-02-20 23:50:40.522046: val_loss 0.0973
2025-02-20 23:50:40.524451: Pseudo dice [0.2628, 0.2427, 0.1005, 0.5296]
2025-02-20 23:50:40.526533: Epoch time: 123.04 s
2025-02-20 23:50:40.528605: Yayy! New best EMA pseudo Dice: 0.1219
2025-02-20 23:50:44.440906: 
2025-02-20 23:50:44.443367: Epoch 13
2025-02-20 23:50:44.447593: Current learning rate: 0.00882
2025-02-20 23:52:48.953790: train_loss 0.1473
2025-02-20 23:52:48.957349: val_loss 0.1087
2025-02-20 23:52:48.959589: Pseudo dice [0.0001, 0.3882, 0.3174, 0.3615]
2025-02-20 23:52:48.961811: Epoch time: 124.51 s
2025-02-20 23:52:48.964048: Yayy! New best EMA pseudo Dice: 0.1364
2025-02-20 23:52:52.814643: 
2025-02-20 23:52:52.816859: Epoch 14
2025-02-20 23:52:52.818677: Current learning rate: 0.00873
2025-02-20 23:54:59.565977: train_loss 0.1607
2025-02-20 23:54:59.571165: val_loss 0.1163
2025-02-20 23:54:59.583093: Pseudo dice [0.2532, 0.2523, 0.2402, 0.4547]
2025-02-20 23:54:59.585718: Epoch time: 126.75 s
2025-02-20 23:54:59.588378: Yayy! New best EMA pseudo Dice: 0.1528
2025-02-20 23:55:04.606811: 
2025-02-20 23:55:04.609260: Epoch 15
2025-02-20 23:55:04.611628: Current learning rate: 0.00864
2025-02-20 23:57:01.689379: train_loss 0.1101
2025-02-20 23:57:01.692827: val_loss 0.0581
2025-02-20 23:57:01.695136: Pseudo dice [0.0, 0.0256, 0.4779, 0.5479]
2025-02-20 23:57:01.697999: Epoch time: 117.08 s
2025-02-20 23:57:01.700312: Yayy! New best EMA pseudo Dice: 0.1638
2025-02-20 23:57:05.513076: 
2025-02-20 23:57:05.515888: Epoch 16
2025-02-20 23:57:05.518026: Current learning rate: 0.00855
2025-02-20 23:58:52.926553: train_loss 0.1206
2025-02-20 23:58:52.931423: val_loss 0.0817
2025-02-20 23:58:52.933501: Pseudo dice [0.209, 0.2177, 0.4008, 0.526]
2025-02-20 23:58:52.935918: Epoch time: 107.41 s
2025-02-20 23:58:52.938005: Yayy! New best EMA pseudo Dice: 0.1812
2025-02-20 23:58:57.549279: 
2025-02-20 23:58:57.552171: Epoch 17
2025-02-20 23:58:57.554320: Current learning rate: 0.00846
2025-02-21 00:00:46.644634: train_loss 0.118
2025-02-21 00:00:46.652169: val_loss 0.0921
2025-02-21 00:00:46.656722: Pseudo dice [0.0943, 0.3195, 0.5906, 0.4266]
2025-02-21 00:00:46.659893: Epoch time: 109.1 s
2025-02-21 00:00:46.663336: Yayy! New best EMA pseudo Dice: 0.1989
2025-02-21 00:00:51.023708: 
2025-02-21 00:00:51.026759: Epoch 18
2025-02-21 00:00:51.029702: Current learning rate: 0.00836
2025-02-21 00:06:35.446106: train_loss 0.0824
2025-02-21 00:06:35.449911: val_loss 0.0758
2025-02-21 00:06:35.452338: Pseudo dice [0.2793, 0.2582, 0.4181, 0.3992]
2025-02-21 00:06:35.454758: Epoch time: 344.42 s
2025-02-21 00:06:35.457093: Yayy! New best EMA pseudo Dice: 0.2129
2025-02-21 00:06:39.221065: 
2025-02-21 00:06:39.223867: Epoch 19
2025-02-21 00:06:39.226774: Current learning rate: 0.00827
2025-02-21 00:09:17.151582: train_loss 0.0875
2025-02-21 00:09:17.171621: val_loss 0.0669
2025-02-21 00:09:17.181356: Pseudo dice [0.0, 0.3424, 0.526, 0.5674]
2025-02-21 00:09:17.189350: Epoch time: 157.93 s
2025-02-21 00:09:17.200535: Yayy! New best EMA pseudo Dice: 0.2275
2025-02-21 00:09:21.492050: 
2025-02-21 00:09:21.494921: Epoch 20
2025-02-21 00:09:21.497797: Current learning rate: 0.00818
2025-02-21 00:11:58.096822: train_loss 0.0842
2025-02-21 00:11:58.112174: val_loss -0.0209
2025-02-21 00:11:58.122035: Pseudo dice [0.0088, 0.3456, 0.6798, 0.6039]
2025-02-21 00:11:58.130473: Epoch time: 156.61 s
2025-02-21 00:11:58.140131: Yayy! New best EMA pseudo Dice: 0.2457
2025-02-21 00:12:03.260782: 
2025-02-21 00:12:03.263823: Epoch 21
2025-02-21 00:12:03.266562: Current learning rate: 0.00809
2025-02-21 00:14:28.585025: train_loss 0.0577
2025-02-21 00:14:28.605219: val_loss 0.0749
2025-02-21 00:14:28.607486: Pseudo dice [0.0, 0.2961, 0.5328, 0.1009]
2025-02-21 00:14:28.609998: Epoch time: 145.33 s
2025-02-21 00:14:30.091155: 
2025-02-21 00:14:30.093950: Epoch 22
2025-02-21 00:14:30.096169: Current learning rate: 0.008
2025-02-21 00:17:01.253932: train_loss 0.057
2025-02-21 00:17:01.257838: val_loss 0.0395
2025-02-21 00:17:01.260597: Pseudo dice [0.2129, 0.3282, 0.4967, 0.5836]
2025-02-21 00:17:01.263024: Epoch time: 151.16 s
2025-02-21 00:17:01.265467: Yayy! New best EMA pseudo Dice: 0.2605
2025-02-21 00:17:05.795281: 
2025-02-21 00:17:05.798340: Epoch 23
2025-02-21 00:17:05.800771: Current learning rate: 0.0079
2025-02-21 00:19:44.332212: train_loss 0.0535
2025-02-21 00:19:44.338836: val_loss 0.0049
2025-02-21 00:19:44.341659: Pseudo dice [0.0, 0.2605, 0.6423, 0.5733]
2025-02-21 00:19:44.343913: Epoch time: 158.54 s
2025-02-21 00:19:44.346303: Yayy! New best EMA pseudo Dice: 0.2713
2025-02-21 00:19:48.999681: 
2025-02-21 00:19:49.005355: Epoch 24
2025-02-21 00:19:49.007536: Current learning rate: 0.00781
2025-02-21 00:22:10.262938: train_loss 0.0386
2025-02-21 00:22:10.286462: val_loss 0.0555
2025-02-21 00:22:10.289015: Pseudo dice [0.0941, 0.4122, 0.587, 0.027]
2025-02-21 00:22:10.293903: Epoch time: 141.27 s
2025-02-21 00:22:10.300659: Yayy! New best EMA pseudo Dice: 0.2722
2025-02-21 00:22:14.355645: 
2025-02-21 00:22:14.358345: Epoch 25
2025-02-21 00:22:14.360493: Current learning rate: 0.00772
2025-02-21 00:24:39.808755: train_loss 0.0289
2025-02-21 00:24:39.832026: val_loss -0.0291
2025-02-21 00:24:39.876526: Pseudo dice [0.0271, 0.394, 0.6327, 0.3801]
2025-02-21 00:24:39.879465: Epoch time: 145.45 s
2025-02-21 00:24:39.881781: Yayy! New best EMA pseudo Dice: 0.2808
2025-02-21 00:24:44.164422: 
2025-02-21 00:24:44.166855: Epoch 26
2025-02-21 00:24:44.169558: Current learning rate: 0.00763
2025-02-21 00:27:09.871101: train_loss 0.0247
2025-02-21 00:27:09.875938: val_loss 0.0672
2025-02-21 00:27:09.878645: Pseudo dice [0.1401, 0.4361, 0.5893, 0.077]
2025-02-21 00:27:09.880969: Epoch time: 145.71 s
2025-02-21 00:27:09.883167: Yayy! New best EMA pseudo Dice: 0.2838
2025-02-21 00:27:14.211525: 
2025-02-21 00:27:14.214204: Epoch 27
2025-02-21 00:27:14.216226: Current learning rate: 0.00753
2025-02-21 00:29:43.488987: train_loss 0.0293
2025-02-21 00:29:43.492831: val_loss 0.0516
2025-02-21 00:29:43.495924: Pseudo dice [0.0507, 0.2248, 0.5488, 0.597]
2025-02-21 00:29:43.498956: Epoch time: 149.28 s
2025-02-21 00:29:43.502382: Yayy! New best EMA pseudo Dice: 0.291
2025-02-21 00:29:50.037912: 
2025-02-21 00:29:50.040400: Epoch 28
2025-02-21 00:29:50.042868: Current learning rate: 0.00744
2025-02-21 00:32:36.308831: train_loss 0.0166
2025-02-21 00:32:36.315923: val_loss -0.0116
2025-02-21 00:32:36.318928: Pseudo dice [0.2416, 0.3842, 0.5996, 0.483]
2025-02-21 00:32:36.321836: Epoch time: 166.27 s
2025-02-21 00:32:36.325313: Yayy! New best EMA pseudo Dice: 0.3046
2025-02-21 00:32:40.820435: 
2025-02-21 00:32:40.850571: Epoch 29
2025-02-21 00:32:40.854660: Current learning rate: 0.00735
2025-02-21 00:35:38.828762: train_loss -0.0088
2025-02-21 00:35:38.837852: val_loss -0.0282
2025-02-21 00:35:38.844239: Pseudo dice [0.0063, 0.3481, 0.6305, 0.522]
2025-02-21 00:35:38.849337: Epoch time: 178.01 s
2025-02-21 00:35:38.852464: Yayy! New best EMA pseudo Dice: 0.3118
2025-02-21 00:35:42.626467: 
2025-02-21 00:35:42.630589: Epoch 30
2025-02-21 00:35:42.633675: Current learning rate: 0.00725
2025-02-21 00:38:17.707002: train_loss 0.0074
2025-02-21 00:38:17.713795: val_loss 0.0699
2025-02-21 00:38:17.716444: Pseudo dice [0.2294, 0.4051, 0.2248, 0.4185]
2025-02-21 00:38:17.718837: Epoch time: 155.08 s
2025-02-21 00:38:17.721065: Yayy! New best EMA pseudo Dice: 0.3126
2025-02-21 00:38:21.843871: 
2025-02-21 00:38:21.847063: Epoch 31
2025-02-21 00:38:21.849799: Current learning rate: 0.00716
2025-02-21 00:40:59.302914: train_loss 0.0042
2025-02-21 00:40:59.308713: val_loss -0.0687
2025-02-21 00:40:59.311606: Pseudo dice [0.1953, 0.3371, 0.6566, 0.5518]
2025-02-21 00:40:59.314191: Epoch time: 157.46 s
2025-02-21 00:40:59.321958: Yayy! New best EMA pseudo Dice: 0.3248
2025-02-21 00:41:03.640765: 
2025-02-21 00:41:03.643595: Epoch 32
2025-02-21 00:41:03.646408: Current learning rate: 0.00707
2025-02-21 00:43:33.161722: train_loss -0.0063
2025-02-21 00:43:33.167987: val_loss -0.0207
2025-02-21 00:43:33.174496: Pseudo dice [0.2723, 0.5382, 0.6366, 0.2608]
2025-02-21 00:43:33.179984: Epoch time: 149.52 s
2025-02-21 00:43:33.184575: Yayy! New best EMA pseudo Dice: 0.335
2025-02-21 00:43:37.005673: 
2025-02-21 00:43:37.008024: Epoch 33
2025-02-21 00:43:37.010405: Current learning rate: 0.00697
2025-02-21 00:46:14.046631: train_loss 0.001
2025-02-21 00:46:14.055346: val_loss 0.0165
2025-02-21 00:46:14.060959: Pseudo dice [0.4635, 0.5194, 0.2615, 0.3678]
2025-02-21 00:46:14.063915: Epoch time: 157.04 s
2025-02-21 00:46:14.066140: Yayy! New best EMA pseudo Dice: 0.3418
2025-02-21 00:46:20.126276: 
2025-02-21 00:46:20.129227: Epoch 34
2025-02-21 00:46:20.131473: Current learning rate: 0.00688
2025-02-21 00:48:56.661400: train_loss 0.0321
2025-02-21 00:48:56.666274: val_loss -0.0274
2025-02-21 00:48:56.669170: Pseudo dice [0.3874, 0.5224, 0.5401, 0.5079]
2025-02-21 00:48:56.672095: Epoch time: 156.54 s
2025-02-21 00:48:56.675599: Yayy! New best EMA pseudo Dice: 0.3566
2025-02-21 00:49:00.718847: 
2025-02-21 00:49:00.721702: Epoch 35
2025-02-21 00:49:00.724333: Current learning rate: 0.00679
2025-02-21 00:51:42.152730: train_loss -0.0426
2025-02-21 00:51:42.345960: val_loss -0.0573
2025-02-21 00:51:42.470733: Pseudo dice [0.3738, 0.4588, 0.6336, 0.4883]
2025-02-21 00:51:42.540447: Epoch time: 161.44 s
2025-02-21 00:51:42.556660: Yayy! New best EMA pseudo Dice: 0.3698
2025-02-21 00:51:46.542957: 
2025-02-21 00:51:46.547623: Epoch 36
2025-02-21 00:51:46.552500: Current learning rate: 0.00669
2025-02-21 00:54:47.222744: train_loss -0.0293
2025-02-21 00:54:47.231395: val_loss 0.0021
2025-02-21 00:54:47.234751: Pseudo dice [0.2444, 0.2179, 0.5194, 0.616]
2025-02-21 00:54:47.237980: Epoch time: 180.68 s
2025-02-21 00:54:47.241389: Yayy! New best EMA pseudo Dice: 0.3728
2025-02-21 00:54:52.103363: 
2025-02-21 00:54:52.107116: Epoch 37
2025-02-21 00:54:52.110459: Current learning rate: 0.0066
2025-02-21 00:57:46.960831: train_loss -0.0324
2025-02-21 00:57:46.964442: val_loss -0.0555
2025-02-21 00:57:46.966301: Pseudo dice [0.132, 0.5355, 0.6506, 0.5192]
2025-02-21 00:57:46.968713: Epoch time: 174.86 s
2025-02-21 00:57:46.970680: Yayy! New best EMA pseudo Dice: 0.3814
2025-02-21 00:57:50.814158: 
2025-02-21 00:57:50.817176: Epoch 38
2025-02-21 00:57:50.819510: Current learning rate: 0.0065
2025-02-21 01:00:46.583098: train_loss -0.0192
2025-02-21 01:00:46.591224: val_loss -0.0183
2025-02-21 01:00:46.596412: Pseudo dice [0.4442, 0.2988, 0.5601, 0.5133]
2025-02-21 01:00:46.602328: Epoch time: 175.77 s
2025-02-21 01:00:46.606701: Yayy! New best EMA pseudo Dice: 0.3887
2025-02-21 01:00:51.503442: 
2025-02-21 01:00:51.507363: Epoch 39
2025-02-21 01:00:51.511708: Current learning rate: 0.00641
2025-02-21 01:03:40.543308: train_loss -0.0414
2025-02-21 01:03:40.547486: val_loss -0.0515
2025-02-21 01:03:40.549879: Pseudo dice [0.322, 0.3158, 0.6297, 0.58]
2025-02-21 01:03:40.552102: Epoch time: 169.04 s
2025-02-21 01:03:40.553984: Yayy! New best EMA pseudo Dice: 0.396
2025-02-21 01:03:44.693086: 
2025-02-21 01:03:44.695002: Epoch 40
2025-02-21 01:03:44.697320: Current learning rate: 0.00631
2025-02-21 01:06:49.144702: train_loss -0.0724
2025-02-21 01:06:49.153382: val_loss -0.0816
2025-02-21 01:06:49.157099: Pseudo dice [0.476, 0.4993, 0.6065, 0.5803]
2025-02-21 01:06:49.159584: Epoch time: 184.45 s
2025-02-21 01:06:49.162636: Yayy! New best EMA pseudo Dice: 0.4105
2025-02-21 01:06:55.676183: 
2025-02-21 01:06:55.679664: Epoch 41
2025-02-21 01:06:55.682626: Current learning rate: 0.00622
2025-02-21 01:09:50.746632: train_loss -0.0867
2025-02-21 01:09:50.752469: val_loss -0.0501
2025-02-21 01:09:50.755382: Pseudo dice [0.3263, 0.3973, 0.6217, 0.6653]
2025-02-21 01:09:50.758146: Epoch time: 175.07 s
2025-02-21 01:09:50.761628: Yayy! New best EMA pseudo Dice: 0.4197
2025-02-21 01:09:54.702097: 
2025-02-21 01:09:54.705846: Epoch 42
2025-02-21 01:09:54.709196: Current learning rate: 0.00612
2025-02-21 01:12:57.237114: train_loss -0.0775
2025-02-21 01:12:57.243498: val_loss -0.082
2025-02-21 01:12:57.245554: Pseudo dice [0.4499, 0.5467, 0.6672, 0.5813]
2025-02-21 01:12:57.247531: Epoch time: 182.54 s
2025-02-21 01:12:57.249456: Yayy! New best EMA pseudo Dice: 0.4338
2025-02-21 01:13:01.439901: 
2025-02-21 01:13:01.442589: Epoch 43
2025-02-21 01:13:01.444443: Current learning rate: 0.00603
2025-02-21 01:16:05.768005: train_loss -0.0861
2025-02-21 01:16:05.775016: val_loss -0.0056
2025-02-21 01:16:05.778319: Pseudo dice [0.3941, 0.5648, 0.4064, 0.4792]
2025-02-21 01:16:05.781733: Epoch time: 184.33 s
2025-02-21 01:16:05.785446: Yayy! New best EMA pseudo Dice: 0.4366
2025-02-21 01:16:09.722605: 
2025-02-21 01:16:09.726051: Epoch 44
2025-02-21 01:16:09.728691: Current learning rate: 0.00593
2025-02-21 01:19:13.556056: train_loss -0.0502
2025-02-21 01:19:13.561743: val_loss -0.1201
2025-02-21 01:19:13.564731: Pseudo dice [0.5971, 0.5781, 0.6999, 0.571]
2025-02-21 01:19:13.567215: Epoch time: 183.84 s
2025-02-21 01:19:13.570371: Yayy! New best EMA pseudo Dice: 0.4541
2025-02-21 01:19:17.484731: 
2025-02-21 01:19:17.487963: Epoch 45
2025-02-21 01:19:17.491026: Current learning rate: 0.00584
2025-02-21 01:22:22.450209: train_loss -0.0656
2025-02-21 01:22:22.458386: val_loss -0.0169
2025-02-21 01:22:22.462248: Pseudo dice [0.3171, 0.4622, 0.464, 0.6737]
2025-02-21 01:22:22.465162: Epoch time: 184.97 s
2025-02-21 01:22:22.467735: Yayy! New best EMA pseudo Dice: 0.4566
2025-02-21 01:22:26.894230: 
2025-02-21 01:22:26.897366: Epoch 46
2025-02-21 01:22:26.899931: Current learning rate: 0.00574
2025-02-21 01:25:35.056813: train_loss -0.0863
2025-02-21 01:25:35.063714: val_loss -0.0356
2025-02-21 01:25:35.066365: Pseudo dice [0.3825, 0.5595, 0.4978, 0.6081]
2025-02-21 01:25:35.069247: Epoch time: 188.16 s
2025-02-21 01:25:35.072980: Yayy! New best EMA pseudo Dice: 0.4621
2025-02-21 01:25:41.654733: 
2025-02-21 01:25:41.657663: Epoch 47
2025-02-21 01:25:41.660724: Current learning rate: 0.00565
2025-02-21 01:28:31.829724: train_loss -0.1011
2025-02-21 01:28:31.835421: val_loss -0.0779
2025-02-21 01:28:31.838370: Pseudo dice [0.3216, 0.5515, 0.6263, 0.6092]
2025-02-21 01:28:31.841095: Epoch time: 170.18 s
2025-02-21 01:28:31.844162: Yayy! New best EMA pseudo Dice: 0.4686
2025-02-21 01:28:36.790609: 
2025-02-21 01:28:36.794020: Epoch 48
2025-02-21 01:28:36.797195: Current learning rate: 0.00555
2025-02-21 01:31:24.390734: train_loss -0.0888
2025-02-21 01:31:24.394442: val_loss -0.0102
2025-02-21 01:31:24.396713: Pseudo dice [0.3656, 0.4566, 0.2199, 0.6133]
2025-02-21 01:31:24.398890: Epoch time: 167.6 s
2025-02-21 01:31:25.922786: 
2025-02-21 01:31:25.925367: Epoch 49
2025-02-21 01:31:25.927839: Current learning rate: 0.00546
2025-02-21 01:34:14.916992: train_loss -0.0973
2025-02-21 01:34:14.927304: val_loss -0.0423
2025-02-21 01:34:14.930972: Pseudo dice [0.2722, 0.3221, 0.6848, 0.6273]
2025-02-21 01:34:14.933609: Epoch time: 169.0 s
2025-02-21 01:34:19.536501: 
2025-02-21 01:34:19.539194: Epoch 50
2025-02-21 01:34:19.541681: Current learning rate: 0.00536
2025-02-21 01:37:03.750159: train_loss -0.0966
2025-02-21 01:37:03.758425: val_loss 0.0139
2025-02-21 01:37:03.761503: Pseudo dice [0.2933, 0.3897, 0.5189, 0.6625]
2025-02-21 01:37:03.764054: Epoch time: 164.22 s
2025-02-21 01:37:05.296382: 
2025-02-21 01:37:05.299238: Epoch 51
2025-02-21 01:37:05.301351: Current learning rate: 0.00526
2025-02-21 01:40:02.683718: train_loss -0.0912
2025-02-21 01:40:02.694279: val_loss -0.0532
2025-02-21 01:40:02.699221: Pseudo dice [0.5748, 0.497, 0.6335, 0.5899]
2025-02-21 01:40:02.704608: Epoch time: 177.39 s
2025-02-21 01:40:02.710928: Yayy! New best EMA pseudo Dice: 0.4756
2025-02-21 01:40:06.605782: 
2025-02-21 01:40:06.608609: Epoch 52
2025-02-21 01:40:06.612973: Current learning rate: 0.00517
2025-02-21 01:42:59.357980: train_loss -0.0861
2025-02-21 01:42:59.361948: val_loss -0.0416
2025-02-21 01:42:59.363677: Pseudo dice [0.2622, 0.2213, 0.589, 0.6292]
2025-02-21 01:42:59.365359: Epoch time: 172.75 s
2025-02-21 01:43:00.907369: 
2025-02-21 01:43:00.909315: Epoch 53
2025-02-21 01:43:00.911441: Current learning rate: 0.00507
2025-02-21 01:46:03.518922: train_loss -0.0917
2025-02-21 01:46:03.529499: val_loss 0.0364
2025-02-21 01:46:03.535126: Pseudo dice [0.4037, 0.5564, 0.3897, 0.4204]
2025-02-21 01:46:03.537743: Epoch time: 182.61 s
2025-02-21 01:46:07.360097: 
2025-02-21 01:46:07.363231: Epoch 54
2025-02-21 01:46:07.365665: Current learning rate: 0.00497
2025-02-21 01:48:58.534795: train_loss -0.0947
2025-02-21 01:48:58.545407: val_loss -0.075
2025-02-21 01:48:58.551653: Pseudo dice [0.5189, 0.6126, 0.663, 0.5219]
2025-02-21 01:48:58.557215: Epoch time: 171.18 s
2025-02-21 01:48:58.563190: Yayy! New best EMA pseudo Dice: 0.4789
2025-02-21 01:49:02.607269: 
2025-02-21 01:49:02.610905: Epoch 55
2025-02-21 01:49:02.613649: Current learning rate: 0.00487
2025-02-21 01:51:57.259387: train_loss -0.148
2025-02-21 01:51:57.267996: val_loss -0.0835
2025-02-21 01:51:57.273738: Pseudo dice [0.527, 0.4599, 0.7569, 0.6079]
2025-02-21 01:51:57.278354: Epoch time: 174.65 s
2025-02-21 01:51:57.284596: Yayy! New best EMA pseudo Dice: 0.4898
2025-02-21 01:52:01.811677: 
2025-02-21 01:52:01.814831: Epoch 56
2025-02-21 01:52:01.817689: Current learning rate: 0.00478
2025-02-21 01:54:56.620600: train_loss -0.1308
2025-02-21 01:54:56.624650: val_loss -0.098
2025-02-21 01:54:56.627103: Pseudo dice [0.4059, 0.5461, 0.7352, 0.625]
2025-02-21 01:54:56.629561: Epoch time: 174.81 s
2025-02-21 01:54:56.631992: Yayy! New best EMA pseudo Dice: 0.4986
2025-02-21 01:55:00.419455: 
2025-02-21 01:55:00.422588: Epoch 57
2025-02-21 01:55:00.425348: Current learning rate: 0.00468
2025-02-21 01:57:41.160468: train_loss -0.1103
2025-02-21 01:57:41.165951: val_loss -0.1018
2025-02-21 01:57:41.168662: Pseudo dice [0.484, 0.5504, 0.6207, 0.6873]
2025-02-21 01:57:41.171130: Epoch time: 160.74 s
2025-02-21 01:57:41.173836: Yayy! New best EMA pseudo Dice: 0.5073
2025-02-21 01:57:44.910763: 
2025-02-21 01:57:44.913222: Epoch 58
2025-02-21 01:57:44.915347: Current learning rate: 0.00458
2025-02-21 02:00:48.326949: train_loss -0.1367
2025-02-21 02:00:48.335649: val_loss -0.1253
2025-02-21 02:00:48.338721: Pseudo dice [0.6972, 0.4718, 0.73, 0.6974]
2025-02-21 02:00:48.341549: Epoch time: 183.42 s
2025-02-21 02:00:48.344380: Yayy! New best EMA pseudo Dice: 0.5215
2025-02-21 02:00:52.256035: 
2025-02-21 02:00:52.260663: Epoch 59
2025-02-21 02:00:52.266819: Current learning rate: 0.00448
2025-02-21 02:03:43.475075: train_loss -0.1547
2025-02-21 02:03:43.482992: val_loss -0.1169
2025-02-21 02:03:43.486717: Pseudo dice [0.4815, 0.5366, 0.6742, 0.6739]
2025-02-21 02:03:43.489615: Epoch time: 171.22 s
2025-02-21 02:03:43.495130: Yayy! New best EMA pseudo Dice: 0.5285
2025-02-21 02:03:47.200056: 
2025-02-21 02:03:47.202698: Epoch 60
2025-02-21 02:03:47.206560: Current learning rate: 0.00438
2025-02-21 02:06:45.853207: train_loss -0.1367
2025-02-21 02:06:45.858075: val_loss -0.0508
2025-02-21 02:06:45.860476: Pseudo dice [0.4155, 0.3938, 0.5317, 0.7543]
2025-02-21 02:06:45.863363: Epoch time: 178.65 s
2025-02-21 02:06:49.699196: 
2025-02-21 02:06:49.704535: Epoch 61
2025-02-21 02:06:49.708249: Current learning rate: 0.00429
2025-02-21 02:09:37.886638: train_loss -0.1414
2025-02-21 02:09:37.891621: val_loss -0.1348
2025-02-21 02:09:37.893885: Pseudo dice [0.5734, 0.5764, 0.7368, 0.7272]
2025-02-21 02:09:37.895910: Epoch time: 168.19 s
2025-02-21 02:09:37.898315: Yayy! New best EMA pseudo Dice: 0.5406
2025-02-21 02:09:41.707798: 
2025-02-21 02:09:41.710675: Epoch 62
2025-02-21 02:09:41.713401: Current learning rate: 0.00419
2025-02-21 02:12:17.490786: train_loss -0.179
2025-02-21 02:12:17.496297: val_loss -0.128
2025-02-21 02:12:17.498949: Pseudo dice [0.6705, 0.6212, 0.7808, 0.6693]
2025-02-21 02:12:17.502705: Epoch time: 155.78 s
2025-02-21 02:12:17.505387: Yayy! New best EMA pseudo Dice: 0.5551
2025-02-21 02:12:21.390624: 
2025-02-21 02:12:21.393960: Epoch 63
2025-02-21 02:12:21.397701: Current learning rate: 0.00409
2025-02-21 02:15:11.721877: train_loss -0.1531
2025-02-21 02:15:11.727532: val_loss -0.1359
2025-02-21 02:15:11.729614: Pseudo dice [0.5634, 0.5258, 0.6898, 0.7261]
2025-02-21 02:15:11.731735: Epoch time: 170.33 s
2025-02-21 02:15:11.733861: Yayy! New best EMA pseudo Dice: 0.5622
2025-02-21 02:15:15.821680: 
2025-02-21 02:15:15.824594: Epoch 64
2025-02-21 02:15:15.826657: Current learning rate: 0.00399
2025-02-21 02:18:06.043056: train_loss -0.147
2025-02-21 02:18:06.053007: val_loss -0.1007
2025-02-21 02:18:06.057513: Pseudo dice [0.5601, 0.5992, 0.6638, 0.7438]
2025-02-21 02:18:06.061821: Epoch time: 170.22 s
2025-02-21 02:18:06.065825: Yayy! New best EMA pseudo Dice: 0.5701
2025-02-21 02:18:09.869400: 
2025-02-21 02:18:09.872273: Epoch 65
2025-02-21 02:18:09.874954: Current learning rate: 0.00389
2025-02-21 02:20:52.341739: train_loss -0.1455
2025-02-21 02:20:52.346510: val_loss -0.0343
2025-02-21 02:20:52.348448: Pseudo dice [0.5161, 0.575, 0.6622, 0.5626]
2025-02-21 02:20:52.350864: Epoch time: 162.47 s
2025-02-21 02:20:52.353440: Yayy! New best EMA pseudo Dice: 0.571
2025-02-21 02:20:56.221246: 
2025-02-21 02:20:56.224596: Epoch 66
2025-02-21 02:20:56.227165: Current learning rate: 0.00379
2025-02-21 02:23:40.800022: train_loss -0.1685
2025-02-21 02:23:40.807874: val_loss -0.1296
2025-02-21 02:23:40.810893: Pseudo dice [0.5879, 0.5042, 0.6403, 0.6845]
2025-02-21 02:23:40.813544: Epoch time: 164.58 s
2025-02-21 02:23:40.816235: Yayy! New best EMA pseudo Dice: 0.5743
2025-02-21 02:23:45.083428: 
2025-02-21 02:23:45.085978: Epoch 67
2025-02-21 02:23:45.088252: Current learning rate: 0.00369
2025-02-21 02:26:38.010660: train_loss -0.1389
2025-02-21 02:26:38.017723: val_loss -0.1773
2025-02-21 02:26:38.021215: Pseudo dice [0.6837, 0.7094, 0.7889, 0.7494]
2025-02-21 02:26:38.024342: Epoch time: 172.93 s
2025-02-21 02:26:38.026952: Yayy! New best EMA pseudo Dice: 0.5902
2025-02-21 02:26:41.838464: 
2025-02-21 02:26:41.841915: Epoch 68
2025-02-21 02:26:41.844505: Current learning rate: 0.00359
2025-02-21 02:29:32.297622: train_loss -0.1703
2025-02-21 02:29:32.309441: val_loss -0.1095
2025-02-21 02:29:32.318885: Pseudo dice [0.617, 0.4413, 0.7314, 0.6327]
2025-02-21 02:29:32.323295: Epoch time: 170.46 s
2025-02-21 02:29:32.327437: Yayy! New best EMA pseudo Dice: 0.5917
2025-02-21 02:29:36.152047: 
2025-02-21 02:29:36.154456: Epoch 69
2025-02-21 02:29:36.157132: Current learning rate: 0.00349
2025-02-21 02:32:24.463326: train_loss -0.1607
2025-02-21 02:32:24.476797: val_loss -0.1049
2025-02-21 02:32:24.482833: Pseudo dice [0.4726, 0.5025, 0.6696, 0.6499]
2025-02-21 02:32:24.488932: Epoch time: 168.31 s
2025-02-21 02:32:26.162721: 
2025-02-21 02:32:26.165757: Epoch 70
2025-02-21 02:32:26.167913: Current learning rate: 0.00338
2025-02-21 02:35:20.410604: train_loss -0.1891
2025-02-21 02:35:20.421142: val_loss -0.1593
2025-02-21 02:35:20.425006: Pseudo dice [0.7656, 0.5963, 0.8111, 0.6803]
2025-02-21 02:35:20.428264: Epoch time: 174.25 s
2025-02-21 02:35:20.433208: Yayy! New best EMA pseudo Dice: 0.6023
2025-02-21 02:35:24.402923: 
2025-02-21 02:35:24.410103: Epoch 71
2025-02-21 02:35:24.415962: Current learning rate: 0.00328
2025-02-21 02:38:13.680156: train_loss -0.1973
2025-02-21 02:38:13.688452: val_loss -0.1646
2025-02-21 02:38:13.693214: Pseudo dice [0.579, 0.7333, 0.7808, 0.6817]
2025-02-21 02:38:13.696890: Epoch time: 169.28 s
2025-02-21 02:38:13.700810: Yayy! New best EMA pseudo Dice: 0.6114
2025-02-21 02:38:17.640353: 
2025-02-21 02:38:17.643235: Epoch 72
2025-02-21 02:38:17.645577: Current learning rate: 0.00318
2025-02-21 02:41:17.194407: train_loss -0.1979
2025-02-21 02:41:17.202556: val_loss -0.1852
2025-02-21 02:41:17.206167: Pseudo dice [0.722, 0.6842, 0.7266, 0.7339]
2025-02-21 02:41:17.210249: Epoch time: 179.56 s
2025-02-21 02:41:17.214988: Yayy! New best EMA pseudo Dice: 0.6219
2025-02-21 02:41:21.639462: 
2025-02-21 02:41:21.642516: Epoch 73
2025-02-21 02:41:21.644897: Current learning rate: 0.00308
2025-02-21 02:44:24.317670: train_loss -0.1822
2025-02-21 02:44:24.320201: val_loss -0.1488
2025-02-21 02:44:24.321554: Pseudo dice [0.4681, 0.5595, 0.7555, 0.7624]
2025-02-21 02:44:24.322993: Epoch time: 182.68 s
2025-02-21 02:44:24.324209: Yayy! New best EMA pseudo Dice: 0.6234
2025-02-21 02:44:28.170751: 
2025-02-21 02:44:28.174050: Epoch 74
2025-02-21 02:44:28.176746: Current learning rate: 0.00297
2025-02-21 02:47:15.530962: train_loss -0.1988
2025-02-21 02:47:15.534851: val_loss -0.1377
2025-02-21 02:47:15.536605: Pseudo dice [0.5903, 0.6372, 0.6879, 0.7084]
2025-02-21 02:47:15.539691: Epoch time: 167.36 s
2025-02-21 02:47:15.542454: Yayy! New best EMA pseudo Dice: 0.6266
2025-02-21 02:47:19.340471: 
2025-02-21 02:47:19.344397: Epoch 75
2025-02-21 02:47:19.347434: Current learning rate: 0.00287
2025-02-21 02:50:09.665814: train_loss -0.2285
2025-02-21 02:50:09.680762: val_loss -0.1226
2025-02-21 02:50:09.686478: Pseudo dice [0.5822, 0.6331, 0.7144, 0.692]
2025-02-21 02:50:09.692068: Epoch time: 170.33 s
2025-02-21 02:50:09.697855: Yayy! New best EMA pseudo Dice: 0.6295
2025-02-21 02:50:13.712109: 
2025-02-21 02:50:13.715369: Epoch 76
2025-02-21 02:50:13.717747: Current learning rate: 0.00277
2025-02-21 02:53:11.024608: train_loss -0.1994
2025-02-21 02:53:11.030448: val_loss -0.1108
2025-02-21 02:53:11.033313: Pseudo dice [0.5785, 0.6871, 0.571, 0.6748]
2025-02-21 02:53:11.035690: Epoch time: 177.32 s
2025-02-21 02:53:12.681162: 
2025-02-21 02:53:12.683576: Epoch 77
2025-02-21 02:53:12.686011: Current learning rate: 0.00266
2025-02-21 02:56:02.980348: train_loss -0.2079
2025-02-21 02:56:02.991492: val_loss -0.1423
2025-02-21 02:56:02.999569: Pseudo dice [0.6891, 0.5905, 0.6635, 0.7292]
2025-02-21 02:56:03.006056: Epoch time: 170.3 s
2025-02-21 02:56:03.012346: Yayy! New best EMA pseudo Dice: 0.6332
2025-02-21 02:56:06.921337: 
2025-02-21 02:56:06.924260: Epoch 78
2025-02-21 02:56:06.926661: Current learning rate: 0.00256
2025-02-21 02:58:48.484158: train_loss -0.2116
2025-02-21 02:58:48.489158: val_loss -0.2069
2025-02-21 02:58:48.491193: Pseudo dice [0.5032, 0.6732, 0.8235, 0.7456]
2025-02-21 02:58:48.493338: Epoch time: 161.56 s
2025-02-21 02:58:48.495467: Yayy! New best EMA pseudo Dice: 0.6385
2025-02-21 02:58:52.423039: 
2025-02-21 02:58:52.426298: Epoch 79
2025-02-21 02:58:52.428624: Current learning rate: 0.00245
2025-02-21 03:01:31.900914: train_loss -0.2051
2025-02-21 03:01:31.909952: val_loss -0.215
2025-02-21 03:01:31.914524: Pseudo dice [0.4948, 0.726, 0.7461, 0.7849]
2025-02-21 03:01:31.919068: Epoch time: 159.48 s
2025-02-21 03:01:31.923828: Yayy! New best EMA pseudo Dice: 0.6435
2025-02-21 03:01:38.075633: 
2025-02-21 03:01:38.078547: Epoch 80
2025-02-21 03:01:38.081201: Current learning rate: 0.00235
2025-02-21 03:04:27.126251: train_loss -0.2257
2025-02-21 03:04:27.134254: val_loss -0.1512
2025-02-21 03:04:27.138892: Pseudo dice [0.6577, 0.5886, 0.726, 0.6716]
2025-02-21 03:04:27.143402: Epoch time: 169.05 s
2025-02-21 03:04:27.145692: Yayy! New best EMA pseudo Dice: 0.6452
2025-02-21 03:04:32.580633: 
2025-02-21 03:04:32.583616: Epoch 81
2025-02-21 03:04:32.586225: Current learning rate: 0.00224
2025-02-21 03:07:21.048020: train_loss -0.2018
2025-02-21 03:07:21.055336: val_loss -0.1511
2025-02-21 03:07:21.059518: Pseudo dice [0.54, 0.673, 0.6676, 0.7838]
2025-02-21 03:07:21.064054: Epoch time: 168.47 s
2025-02-21 03:07:21.068538: Yayy! New best EMA pseudo Dice: 0.6473
2025-02-21 03:07:25.109026: 
2025-02-21 03:07:25.112822: Epoch 82
2025-02-21 03:07:25.116334: Current learning rate: 0.00214
2025-02-21 03:10:01.105180: train_loss -0.2135
2025-02-21 03:10:01.111798: val_loss -0.2018
2025-02-21 03:10:01.114304: Pseudo dice [0.5817, 0.6014, 0.7977, 0.7776]
2025-02-21 03:10:01.116750: Epoch time: 156.0 s
2025-02-21 03:10:01.119824: Yayy! New best EMA pseudo Dice: 0.6515
2025-02-21 03:10:04.927830: 
2025-02-21 03:10:04.931807: Epoch 83
2025-02-21 03:10:04.934593: Current learning rate: 0.00203
2025-02-21 03:12:48.411444: train_loss -0.2233
2025-02-21 03:12:48.416024: val_loss -0.2241
2025-02-21 03:12:48.418576: Pseudo dice [0.7092, 0.7463, 0.8167, 0.7855]
2025-02-21 03:12:48.420837: Epoch time: 163.49 s
2025-02-21 03:12:48.423531: Yayy! New best EMA pseudo Dice: 0.6628
2025-02-21 03:12:52.324368: 
2025-02-21 03:12:52.327296: Epoch 84
2025-02-21 03:12:52.329529: Current learning rate: 0.00192
2025-02-21 03:15:32.377811: train_loss -0.2198
2025-02-21 03:15:32.382961: val_loss -0.1265
2025-02-21 03:15:32.385484: Pseudo dice [0.3212, 0.6437, 0.6778, 0.7438]
2025-02-21 03:15:32.387617: Epoch time: 160.06 s
2025-02-21 03:15:33.967592: 
2025-02-21 03:15:33.971350: Epoch 85
2025-02-21 03:15:33.974501: Current learning rate: 0.00181
2025-02-21 03:18:21.931616: train_loss -0.2259
2025-02-21 03:18:21.939166: val_loss -0.1934
2025-02-21 03:18:21.943907: Pseudo dice [0.682, 0.6321, 0.6809, 0.7611]
2025-02-21 03:18:21.947184: Epoch time: 167.97 s
2025-02-21 03:18:25.840441: 
2025-02-21 03:18:25.843753: Epoch 86
2025-02-21 03:18:25.846662: Current learning rate: 0.0017
2025-02-21 03:21:14.621897: train_loss -0.2138
2025-02-21 03:21:14.629598: val_loss -0.1912
2025-02-21 03:21:14.634171: Pseudo dice [0.4295, 0.7113, 0.7303, 0.7753]
2025-02-21 03:21:14.639470: Epoch time: 168.78 s
2025-02-21 03:21:16.127011: 
2025-02-21 03:21:16.130638: Epoch 87
2025-02-21 03:21:16.135368: Current learning rate: 0.00159
2025-02-21 03:24:15.478827: train_loss -0.2289
2025-02-21 03:24:15.487527: val_loss -0.1516
2025-02-21 03:24:15.492068: Pseudo dice [0.5998, 0.7141, 0.6743, 0.7628]
2025-02-21 03:24:15.495078: Epoch time: 179.35 s
2025-02-21 03:24:17.032686: 
2025-02-21 03:24:17.035411: Epoch 88
2025-02-21 03:24:17.039406: Current learning rate: 0.00148
2025-02-21 03:27:04.486186: train_loss -0.2403
2025-02-21 03:27:04.494350: val_loss -0.1936
2025-02-21 03:27:04.497928: Pseudo dice [0.7873, 0.61, 0.8283, 0.7966]
2025-02-21 03:27:04.501221: Epoch time: 167.45 s
2025-02-21 03:27:04.504058: Yayy! New best EMA pseudo Dice: 0.6718
2025-02-21 03:27:08.328130: 
2025-02-21 03:27:08.334232: Epoch 89
2025-02-21 03:27:08.339291: Current learning rate: 0.00137
2025-02-21 03:29:58.382019: train_loss -0.2691
2025-02-21 03:29:58.394123: val_loss -0.1893
2025-02-21 03:29:58.400096: Pseudo dice [0.5789, 0.6857, 0.6701, 0.7618]
2025-02-21 03:29:58.404993: Epoch time: 170.06 s
2025-02-21 03:29:58.409937: Yayy! New best EMA pseudo Dice: 0.672
2025-02-21 03:30:02.451708: 
2025-02-21 03:30:02.454341: Epoch 90
2025-02-21 03:30:02.456643: Current learning rate: 0.00126
2025-02-21 03:33:02.068399: train_loss -0.2475
2025-02-21 03:33:02.074785: val_loss -0.1744
2025-02-21 03:33:02.077802: Pseudo dice [0.5563, 0.6291, 0.6924, 0.747]
2025-02-21 03:33:02.080755: Epoch time: 179.62 s
2025-02-21 03:33:03.615795: 
2025-02-21 03:33:03.618594: Epoch 91
2025-02-21 03:33:03.620819: Current learning rate: 0.00115
2025-02-21 03:36:00.907943: train_loss -0.2129
2025-02-21 03:36:00.915252: val_loss -0.2002
2025-02-21 03:36:00.918828: Pseudo dice [0.7527, 0.6538, 0.7145, 0.7789]
2025-02-21 03:36:00.922234: Epoch time: 177.29 s
2025-02-21 03:36:00.925971: Yayy! New best EMA pseudo Dice: 0.6759
2025-02-21 03:36:04.691616: 
2025-02-21 03:36:04.696273: Epoch 92
2025-02-21 03:36:04.700789: Current learning rate: 0.00103
2025-02-21 03:38:56.979091: train_loss -0.2597
2025-02-21 03:38:56.985223: val_loss -0.1524
2025-02-21 03:38:56.987710: Pseudo dice [0.5969, 0.7808, 0.6401, 0.8119]
2025-02-21 03:38:56.993112: Epoch time: 172.29 s
2025-02-21 03:38:56.995409: Yayy! New best EMA pseudo Dice: 0.6791
2025-02-21 03:39:03.207188: 
2025-02-21 03:39:03.209457: Epoch 93
2025-02-21 03:39:03.211529: Current learning rate: 0.00091
2025-02-21 03:41:58.087287: train_loss -0.2675
2025-02-21 03:41:58.092947: val_loss -0.1877
2025-02-21 03:41:58.095231: Pseudo dice [0.457, 0.6629, 0.7195, 0.7761]
2025-02-21 03:41:58.097668: Epoch time: 174.88 s
2025-02-21 03:41:59.640095: 
2025-02-21 03:41:59.644665: Epoch 94
2025-02-21 03:41:59.650930: Current learning rate: 0.00079
2025-02-21 03:44:50.697657: train_loss -0.2689
2025-02-21 03:44:50.705779: val_loss -0.1914
2025-02-21 03:44:50.711272: Pseudo dice [0.6966, 0.5781, 0.7464, 0.7269]
2025-02-21 03:44:50.716925: Epoch time: 171.06 s
2025-02-21 03:44:52.247161: 
2025-02-21 03:44:52.250444: Epoch 95
2025-02-21 03:44:52.254337: Current learning rate: 0.00067
2025-02-21 03:47:40.223966: train_loss -0.2494
2025-02-21 03:47:40.235409: val_loss -0.2475
2025-02-21 03:47:40.240433: Pseudo dice [0.8831, 0.7118, 0.8492, 0.7553]
2025-02-21 03:47:40.245615: Epoch time: 167.98 s
2025-02-21 03:47:40.250195: Yayy! New best EMA pseudo Dice: 0.6898
2025-02-21 03:47:44.224054: 
2025-02-21 03:47:44.227957: Epoch 96
2025-02-21 03:47:44.231971: Current learning rate: 0.00055
2025-02-21 03:50:47.218347: train_loss -0.2599
2025-02-21 03:50:47.226995: val_loss -0.1813
2025-02-21 03:50:47.231174: Pseudo dice [0.7298, 0.6773, 0.7887, 0.754]
2025-02-21 03:50:47.235422: Epoch time: 183.0 s
2025-02-21 03:50:47.239470: Yayy! New best EMA pseudo Dice: 0.6946
2025-02-21 03:50:51.176377: 
2025-02-21 03:50:51.179024: Epoch 97
2025-02-21 03:50:51.181330: Current learning rate: 0.00043
2025-02-21 03:53:36.904695: train_loss -0.2732
2025-02-21 03:53:36.912934: val_loss -0.2254
2025-02-21 03:53:36.917325: Pseudo dice [0.6359, 0.7974, 0.7757, 0.7873]
2025-02-21 03:53:36.921945: Epoch time: 165.73 s
2025-02-21 03:53:36.926754: Yayy! New best EMA pseudo Dice: 0.7
2025-02-21 03:53:40.855451: 
2025-02-21 03:53:40.860041: Epoch 98
2025-02-21 03:53:40.863307: Current learning rate: 0.0003
2025-02-21 03:56:41.543038: train_loss -0.2663
2025-02-21 03:56:41.549811: val_loss -0.1588
2025-02-21 03:56:41.552927: Pseudo dice [0.5108, 0.6808, 0.6885, 0.7729]
2025-02-21 03:56:41.555086: Epoch time: 180.69 s
2025-02-21 03:56:43.142697: 
2025-02-21 03:56:43.145477: Epoch 99
2025-02-21 03:56:43.148014: Current learning rate: 0.00016
2025-02-21 03:59:35.797110: train_loss -0.289
2025-02-21 03:59:35.806078: val_loss -0.1822
2025-02-21 03:59:35.807818: Pseudo dice [0.6561, 0.7181, 0.7561, 0.7693]
2025-02-21 03:59:35.809904: Epoch time: 172.66 s
2025-02-21 03:59:41.048754: Training done.
2025-02-21 03:59:41.080714: Using splits from existing split file: /home3/hghr96/parm/work/AD_project/segmentation/nnUNet/data/nnUNet_preprocess/Dataset501_AD/splits_final.json
2025-02-21 03:59:41.085082: The split file contains 5 splits.
2025-02-21 03:59:41.086981: Desired fold for training: 3
2025-02-21 03:59:41.089121: This split has 71 training and 17 validation cases.
2025-02-21 03:59:41.091321: predicting ad_004
2025-02-21 03:59:41.097729: ad_004, shape torch.Size([1, 405, 653, 405]), rank 0
2025-02-21 04:01:03.428953: predicting ad_006
2025-02-21 04:01:03.458222: ad_006, shape torch.Size([1, 512, 1417, 512]), rank 0
2025-02-21 04:06:22.575194: predicting ad_016
2025-02-21 04:06:22.651130: ad_016, shape torch.Size([1, 290, 702, 290]), rank 0
2025-02-21 04:07:11.370558: predicting ad_018
2025-02-21 04:07:11.397252: ad_018, shape torch.Size([1, 512, 733, 512]), rank 0
2025-02-21 04:15:46.548944: predicting ad_032
2025-02-21 04:15:46.591292: ad_032, shape torch.Size([1, 541, 925, 541]), rank 0
2025-02-21 04:20:33.003959: predicting ad_054
2025-02-21 04:20:33.154458: ad_054, shape torch.Size([1, 578, 834, 578]), rank 0
2025-02-21 04:24:42.320475: predicting ad_058
2025-02-21 04:24:42.391209: ad_058, shape torch.Size([1, 510, 946, 510]), rank 0
2025-02-21 04:30:43.296702: predicting ad_062
2025-02-21 04:30:43.360499: ad_062, shape torch.Size([1, 543, 965, 543]), rank 0
2025-02-21 04:36:33.082447: predicting ad_071
2025-02-21 04:36:33.155279: ad_071, shape torch.Size([1, 360, 798, 360]), rank 0
2025-02-21 04:42:20.475572: predicting ad_072
2025-02-21 04:42:20.532125: ad_072, shape torch.Size([1, 480, 858, 480]), rank 0
2025-02-21 04:54:10.206609: predicting ad_075
2025-02-21 04:54:10.263482: ad_075, shape torch.Size([1, 481, 834, 481]), rank 0
2025-02-21 04:59:40.666323: predicting ad_077
2025-02-21 04:59:40.721732: ad_077, shape torch.Size([1, 577, 687, 577]), rank 0
2025-02-21 05:10:04.728058: predicting ad_082
2025-02-21 05:10:04.790405: ad_082, shape torch.Size([1, 340, 757, 340]), rank 0
2025-02-21 05:14:11.288528: predicting ad_090
2025-02-21 05:14:11.325283: ad_090, shape torch.Size([1, 629, 870, 629]), rank 0
2025-02-21 05:19:14.356332: predicting ad_091
2025-02-21 05:19:14.452905: ad_091, shape torch.Size([1, 535, 639, 535]), rank 0
2025-02-21 05:24:19.035695: predicting ad_092
2025-02-21 05:24:19.203602: ad_092, shape torch.Size([1, 624, 757, 624]), rank 0
2025-02-21 05:30:27.554070: predicting ad_103
2025-02-21 05:30:27.632698: ad_103, shape torch.Size([1, 299, 665, 299]), rank 0
2025-02-21 05:45:30.274175: Validation complete
2025-02-21 05:45:30.277740: Mean Validation Dice:  0.486178296850316
Finished at Fri 21 Feb 2025 05:45:33 AM GMT
Total Execution Time: 23249 seconds
