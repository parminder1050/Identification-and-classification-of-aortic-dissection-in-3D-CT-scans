Starting at Wed 26 Feb 2025 09:40:37 PM GMT

############################
INFO: You are using the old nnU-Net default plans. We have updated our recommendations. Please consider using those instead! Read more here: https://github.com/MIC-DKFZ/nnUNet/blob/master/documentation/resenc_presets.md
############################

Using device: cuda:0

#######################################################################
Please cite the following paper when using nnU-Net:
Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.
#######################################################################

2025-02-26 21:40:47.350463: do_dummy_2d_data_aug: False
2025-02-26 21:40:47.359271: Using splits from existing split file: /home3/hghr96/parm/work/AD_project/segmentation/nnUNet/data/nnUNet_preprocessed/Dataset501_AD/splits_final.json
2025-02-26 21:40:47.361830: The split file contains 5 splits.
2025-02-26 21:40:47.363411: Desired fold for training: 2
2025-02-26 21:40:47.364888: This split has 70 training and 18 validation cases.
using pin_memory on device 0
/home3/hghr96/miniconda3/envs/nnUnet/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
using pin_memory on device 0
2025-02-26 21:40:53.016737: Using torch.compile...

This is the configuration used by this training:
Configuration name: 3d_lowres
 {'data_identifier': 'nnUNetPlans_3d_lowres', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 2, 'patch_size': [112, 192, 112], 'median_image_size_in_voxels': [177, 288, 177], 'spacing': [2.275601343470847, 2.028794967802552, 2.275601343470847], 'normalization_schemes': ['CTNormalization'], 'use_mask_for_norm': [False], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.PlainConvUNet', 'arch_kwargs': {'n_stages': 6, 'features_per_stage': [32, 64, 128, 256, 320, 320], 'conv_op': 'torch.nn.modules.conv.Conv3d', 'kernel_sizes': [[3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]], 'strides': [[1, 1, 1], [2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2], [1, 2, 1]], 'n_conv_per_stage': [2, 2, 2, 2, 2, 2], 'n_conv_per_stage_decoder': [2, 2, 2, 2, 2], 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm3d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}}, '_kw_requires_import': ['conv_op', 'norm_op', 'dropout_op', 'nonlin']}, 'batch_dice': False, 'next_stage': '3d_cascade_fullres'} 

These are the global plan.json settings:
 {'dataset_name': 'Dataset501_AD', 'plans_name': 'nnUNetPlans', 'original_median_spacing_after_transp': [0.78515625, 0.7000000476837158, 0.78515625], 'original_median_shape_after_transp': [512, 800, 512], 'image_reader_writer': 'SimpleITKIO', 'transpose_forward': [1, 0, 2], 'transpose_backward': [1, 0, 2], 'experiment_planner_used': 'ExperimentPlanner', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 3071.0, 'mean': 161.64767456054688, 'median': 182.0, 'min': -1103.0, 'percentile_00_5': -840.0, 'percentile_99_5': 778.0, 'std': 241.90689086914062}}} 

2025-02-26 21:40:55.435014: unpacking dataset...
2025-02-26 21:41:09.740966: unpacking done...
2025-02-26 21:41:09.771702: Unable to plot network architecture: nnUNet_compile is enabled!
2025-02-26 21:41:09.849148: 
2025-02-26 21:41:09.852518: Epoch 0
2025-02-26 21:41:09.859876: Current learning rate: 0.01
2025-02-26 21:44:58.151154: train_loss 0.1525
2025-02-26 21:44:58.155489: val_loss 0.0586
2025-02-26 21:44:58.157332: Pseudo dice [0.0, 0.0, 0.0, 0.0]
2025-02-26 21:44:58.159178: Epoch time: 228.3 s
2025-02-26 21:44:58.160898: Yayy! New best EMA pseudo Dice: 0.0
2025-02-26 21:45:01.862839: 
2025-02-26 21:45:01.865555: Epoch 1
2025-02-26 21:45:01.867339: Current learning rate: 0.00991
2025-02-26 21:47:12.070763: train_loss 0.0156
2025-02-26 21:47:12.075552: val_loss -0.0482
2025-02-26 21:47:12.077953: Pseudo dice [0.0, 0.3318, 0.0, 0.2302]
2025-02-26 21:47:12.080373: Epoch time: 130.21 s
2025-02-26 21:47:12.082231: Yayy! New best EMA pseudo Dice: 0.0141
2025-02-26 21:47:15.821377: 
2025-02-26 21:47:15.823891: Epoch 2
2025-02-26 21:47:15.825836: Current learning rate: 0.00982
2025-02-26 21:49:30.403246: train_loss -0.0641
2025-02-26 21:49:30.408468: val_loss -0.0952
2025-02-26 21:49:30.410701: Pseudo dice [0.0, 0.3872, 0.0, 0.0186]
2025-02-26 21:49:30.412691: Epoch time: 134.58 s
2025-02-26 21:49:30.414882: Yayy! New best EMA pseudo Dice: 0.0228
2025-02-26 21:49:35.180376: 
2025-02-26 21:49:35.182849: Epoch 3
2025-02-26 21:49:35.185006: Current learning rate: 0.00973
2025-02-26 21:51:46.465575: train_loss -0.1129
2025-02-26 21:51:46.468431: val_loss -0.1398
2025-02-26 21:51:46.469954: Pseudo dice [0.0, 0.2319, 0.3809, 0.4256]
2025-02-26 21:51:46.471048: Epoch time: 131.29 s
2025-02-26 21:51:46.472116: Yayy! New best EMA pseudo Dice: 0.0465
2025-02-26 21:51:50.221834: 
2025-02-26 21:51:50.223490: Epoch 4
2025-02-26 21:51:50.225066: Current learning rate: 0.00964
2025-02-26 21:54:16.639100: train_loss -0.1834
2025-02-26 21:54:16.643067: val_loss -0.1833
2025-02-26 21:54:16.645220: Pseudo dice [0.3193, 0.4417, 0.5064, 0.4484]
2025-02-26 21:54:16.647330: Epoch time: 146.42 s
2025-02-26 21:54:16.649400: Yayy! New best EMA pseudo Dice: 0.0847
2025-02-26 21:54:20.578087: 
2025-02-26 21:54:20.580435: Epoch 5
2025-02-26 21:54:20.582262: Current learning rate: 0.00955
2025-02-26 21:56:40.767976: train_loss -0.2116
2025-02-26 21:56:40.772484: val_loss -0.2272
2025-02-26 21:56:40.774767: Pseudo dice [0.3468, 0.435, 0.5441, 0.5613]
2025-02-26 21:56:40.776903: Epoch time: 140.19 s
2025-02-26 21:56:40.779057: Yayy! New best EMA pseudo Dice: 0.1234
2025-02-26 21:56:45.233839: 
2025-02-26 21:56:45.236492: Epoch 6
2025-02-26 21:56:45.238547: Current learning rate: 0.00946
2025-02-26 21:59:00.301739: train_loss -0.2214
2025-02-26 21:59:00.306159: val_loss -0.2149
2025-02-26 21:59:00.308404: Pseudo dice [0.4642, 0.4801, 0.613, 0.2347]
2025-02-26 21:59:00.310535: Epoch time: 135.07 s
2025-02-26 21:59:00.312587: Yayy! New best EMA pseudo Dice: 0.1559
2025-02-26 21:59:04.848914: 
2025-02-26 21:59:04.885593: Epoch 7
2025-02-26 21:59:04.899164: Current learning rate: 0.00937
2025-02-26 22:01:24.217424: train_loss -0.2411
2025-02-26 22:01:24.221359: val_loss -0.2623
2025-02-26 22:01:24.223509: Pseudo dice [0.6363, 0.4182, 0.6453, 0.5846]
2025-02-26 22:01:24.225513: Epoch time: 139.37 s
2025-02-26 22:01:24.227645: Yayy! New best EMA pseudo Dice: 0.1974
2025-02-26 22:01:28.033237: 
2025-02-26 22:01:28.035535: Epoch 8
2025-02-26 22:01:28.037534: Current learning rate: 0.00928
2025-02-26 22:03:42.940784: train_loss -0.2735
2025-02-26 22:03:42.944511: val_loss -0.2494
2025-02-26 22:03:42.946446: Pseudo dice [0.6234, 0.4498, 0.5616, 0.5982]
2025-02-26 22:03:42.948410: Epoch time: 134.91 s
2025-02-26 22:03:42.950213: Yayy! New best EMA pseudo Dice: 0.2335
2025-02-26 22:03:47.374963: 
2025-02-26 22:03:47.377637: Epoch 9
2025-02-26 22:03:47.379771: Current learning rate: 0.00919
2025-02-26 22:26:28.674586: train_loss -0.2716
2025-02-26 22:26:28.679199: val_loss -0.2836
2025-02-26 22:26:28.681345: Pseudo dice [0.5742, 0.5494, 0.6632, 0.6277]
2025-02-26 22:26:28.683530: Epoch time: 1361.3 s
2025-02-26 22:26:28.685344: Yayy! New best EMA pseudo Dice: 0.2705
2025-02-26 22:26:32.394519: 
2025-02-26 22:26:32.397168: Epoch 10
2025-02-26 22:26:32.398959: Current learning rate: 0.0091
2025-02-26 22:28:50.954125: train_loss -0.2644
2025-02-26 22:28:50.958915: val_loss -0.2683
2025-02-26 22:28:50.961668: Pseudo dice [0.5938, 0.6296, 0.6249, 0.4332]
2025-02-26 22:28:50.964165: Epoch time: 138.56 s
2025-02-26 22:28:50.966608: Yayy! New best EMA pseudo Dice: 0.3005
2025-02-26 22:28:55.426663: 
2025-02-26 22:28:55.429684: Epoch 11
2025-02-26 22:28:55.431718: Current learning rate: 0.009
2025-02-26 22:31:16.627935: train_loss -0.2767
2025-02-26 22:31:16.632726: val_loss -0.2861
2025-02-26 22:31:16.634842: Pseudo dice [0.603, 0.6116, 0.6937, 0.5763]
2025-02-26 22:31:16.637219: Epoch time: 141.2 s
2025-02-26 22:31:16.639297: Yayy! New best EMA pseudo Dice: 0.3326
2025-02-26 22:31:20.341680: 
2025-02-26 22:31:20.344607: Epoch 12
2025-02-26 22:31:20.346811: Current learning rate: 0.00891
2025-02-26 22:33:44.395310: train_loss -0.2891
2025-02-26 22:33:44.399194: val_loss -0.2763
2025-02-26 22:33:44.401039: Pseudo dice [0.5943, 0.6078, 0.7406, 0.491]
2025-02-26 22:33:44.402894: Epoch time: 144.05 s
2025-02-26 22:33:44.404912: Yayy! New best EMA pseudo Dice: 0.3601
2025-02-26 22:33:48.112466: 
2025-02-26 22:33:48.114776: Epoch 13
2025-02-26 22:33:48.116982: Current learning rate: 0.00882
2025-02-26 22:36:20.144747: train_loss -0.3072
2025-02-26 22:36:20.149425: val_loss -0.3262
2025-02-26 22:36:20.151776: Pseudo dice [0.6969, 0.6247, 0.7256, 0.6319]
2025-02-26 22:36:20.154095: Epoch time: 152.03 s
2025-02-26 22:36:20.156495: Yayy! New best EMA pseudo Dice: 0.3911
2025-02-26 22:36:24.314802: 
2025-02-26 22:36:24.317419: Epoch 14
2025-02-26 22:36:24.319227: Current learning rate: 0.00873
2025-02-26 22:38:42.875691: train_loss -0.323
2025-02-26 22:38:42.880599: val_loss -0.3034
2025-02-26 22:38:42.882931: Pseudo dice [0.6579, 0.6154, 0.7311, 0.5853]
2025-02-26 22:38:42.885349: Epoch time: 138.56 s
2025-02-26 22:38:42.887376: Yayy! New best EMA pseudo Dice: 0.4167
2025-02-26 22:38:46.964482: 
2025-02-26 22:38:46.967280: Epoch 15
2025-02-26 22:38:46.969414: Current learning rate: 0.00864
2025-02-26 22:41:00.877267: train_loss -0.3415
2025-02-26 22:41:00.882047: val_loss -0.3144
2025-02-26 22:41:00.884692: Pseudo dice [0.6732, 0.6603, 0.7058, 0.6227]
2025-02-26 22:41:00.887132: Epoch time: 133.91 s
2025-02-26 22:41:00.889463: Yayy! New best EMA pseudo Dice: 0.4416
2025-02-26 22:41:04.732591: 
2025-02-26 22:41:04.734613: Epoch 16
2025-02-26 22:41:04.736415: Current learning rate: 0.00855
2025-02-26 22:43:16.070576: train_loss -0.326
2025-02-26 22:43:16.074892: val_loss -0.3157
2025-02-26 22:43:16.077150: Pseudo dice [0.6957, 0.6481, 0.7256, 0.6368]
2025-02-26 22:43:16.079271: Epoch time: 131.34 s
2025-02-26 22:43:16.081113: Yayy! New best EMA pseudo Dice: 0.4651
2025-02-26 22:43:20.731015: 
2025-02-26 22:43:20.733596: Epoch 17
2025-02-26 22:43:20.735819: Current learning rate: 0.00846
2025-02-26 22:45:29.418972: train_loss -0.3295
2025-02-26 22:45:29.423839: val_loss -0.3326
2025-02-26 22:45:29.426000: Pseudo dice [0.7559, 0.6624, 0.7602, 0.6648]
2025-02-26 22:45:29.428575: Epoch time: 128.69 s
2025-02-26 22:45:29.430947: Yayy! New best EMA pseudo Dice: 0.4897
2025-02-26 22:45:33.405924: 
2025-02-26 22:45:33.408950: Epoch 18
2025-02-26 22:45:33.411311: Current learning rate: 0.00836
2025-02-26 22:47:48.855641: train_loss -0.3481
2025-02-26 22:47:48.859767: val_loss -0.3499
2025-02-26 22:47:48.861607: Pseudo dice [0.7692, 0.7283, 0.7665, 0.6407]
2025-02-26 22:47:48.863537: Epoch time: 135.45 s
2025-02-26 22:47:48.865283: Yayy! New best EMA pseudo Dice: 0.5133
2025-02-26 22:47:52.638866: 
2025-02-26 22:47:52.641266: Epoch 19
2025-02-26 22:47:52.643450: Current learning rate: 0.00827
2025-02-26 22:50:02.420795: train_loss -0.3614
2025-02-26 22:50:02.425601: val_loss -0.3098
2025-02-26 22:50:02.428450: Pseudo dice [0.6053, 0.6483, 0.7539, 0.6054]
2025-02-26 22:50:02.431243: Epoch time: 129.78 s
2025-02-26 22:50:02.433328: Yayy! New best EMA pseudo Dice: 0.5273
2025-02-26 22:50:06.468290: 
2025-02-26 22:50:06.471049: Epoch 20
2025-02-26 22:50:06.473189: Current learning rate: 0.00818
2025-02-26 22:52:17.993790: train_loss -0.3664
2025-02-26 22:52:17.998173: val_loss -0.3661
2025-02-26 22:52:18.000461: Pseudo dice [0.7614, 0.751, 0.7603, 0.7105]
2025-02-26 22:52:18.002759: Epoch time: 131.53 s
2025-02-26 22:52:18.004780: Yayy! New best EMA pseudo Dice: 0.5492
2025-02-26 22:52:21.793456: 
2025-02-26 22:52:21.796558: Epoch 21
2025-02-26 22:52:21.799043: Current learning rate: 0.00809
2025-02-26 22:54:31.656343: train_loss -0.3608
2025-02-26 22:54:31.661023: val_loss -0.3316
2025-02-26 22:54:31.663726: Pseudo dice [0.6654, 0.7053, 0.7857, 0.6999]
2025-02-26 22:54:31.666399: Epoch time: 129.86 s
2025-02-26 22:54:31.668537: Yayy! New best EMA pseudo Dice: 0.5657
2025-02-26 22:54:36.118294: 
2025-02-26 22:54:36.121014: Epoch 22
2025-02-26 22:54:36.123092: Current learning rate: 0.008
2025-02-26 22:56:40.288512: train_loss -0.3611
2025-02-26 22:56:40.293236: val_loss -0.3218
2025-02-26 22:56:40.296129: Pseudo dice [0.7687, 0.6517, 0.7524, 0.5219]
2025-02-26 22:56:40.298573: Epoch time: 124.17 s
2025-02-26 22:56:40.300708: Yayy! New best EMA pseudo Dice: 0.5765
2025-02-26 22:56:44.555033: 
2025-02-26 22:56:44.557326: Epoch 23
2025-02-26 22:56:44.559717: Current learning rate: 0.0079
2025-02-26 22:58:51.354459: train_loss -0.3723
2025-02-26 22:58:51.359457: val_loss -0.3524
2025-02-26 22:58:51.361610: Pseudo dice [0.7718, 0.7754, 0.7319, 0.7159]
2025-02-26 22:58:51.364443: Epoch time: 126.8 s
2025-02-26 22:58:51.366958: Yayy! New best EMA pseudo Dice: 0.5937
2025-02-26 22:58:55.179655: 
2025-02-26 22:58:55.181778: Epoch 24
2025-02-26 22:58:55.183642: Current learning rate: 0.00781
2025-02-26 23:01:12.713913: train_loss -0.3682
2025-02-26 23:01:12.718331: val_loss -0.3576
2025-02-26 23:01:12.720515: Pseudo dice [0.7451, 0.7177, 0.7892, 0.7002]
2025-02-26 23:01:12.722902: Epoch time: 137.54 s
2025-02-26 23:01:12.725072: Yayy! New best EMA pseudo Dice: 0.6081
2025-02-26 23:01:16.353687: 
2025-02-26 23:01:16.355865: Epoch 25
2025-02-26 23:01:16.357688: Current learning rate: 0.00772
2025-02-26 23:03:30.793276: train_loss -0.3843
2025-02-26 23:03:30.798232: val_loss -0.3371
2025-02-26 23:03:30.800534: Pseudo dice [0.7618, 0.7068, 0.718, 0.624]
2025-02-26 23:03:30.802796: Epoch time: 134.44 s
2025-02-26 23:03:30.804837: Yayy! New best EMA pseudo Dice: 0.6176
2025-02-26 23:03:35.426963: 
2025-02-26 23:03:35.429425: Epoch 26
2025-02-26 23:03:35.431956: Current learning rate: 0.00763
2025-02-26 23:05:47.493812: train_loss -0.3825
2025-02-26 23:05:47.498230: val_loss -0.363
2025-02-26 23:05:47.500036: Pseudo dice [0.7999, 0.7594, 0.7551, 0.7123]
2025-02-26 23:05:47.501698: Epoch time: 132.07 s
2025-02-26 23:05:47.503260: Yayy! New best EMA pseudo Dice: 0.6315
2025-02-26 23:05:51.899842: 
2025-02-26 23:05:51.902840: Epoch 27
2025-02-26 23:05:51.904931: Current learning rate: 0.00753
2025-02-26 23:08:02.646421: train_loss -0.3908
2025-02-26 23:08:02.651079: val_loss -0.3861
2025-02-26 23:08:02.653096: Pseudo dice [0.8407, 0.7895, 0.8361, 0.7007]
2025-02-26 23:08:02.655203: Epoch time: 130.75 s
2025-02-26 23:08:02.656998: Yayy! New best EMA pseudo Dice: 0.6475
2025-02-26 23:08:06.356875: 
2025-02-26 23:08:06.359323: Epoch 28
2025-02-26 23:08:06.361467: Current learning rate: 0.00744
2025-02-26 23:10:06.089159: train_loss -0.3977
2025-02-26 23:10:06.094350: val_loss -0.3617
2025-02-26 23:10:06.097254: Pseudo dice [0.7587, 0.7928, 0.7837, 0.6716]
2025-02-26 23:10:06.100247: Epoch time: 119.73 s
2025-02-26 23:10:06.102957: Yayy! New best EMA pseudo Dice: 0.6579
2025-02-26 23:10:10.151470: 
2025-02-26 23:10:10.153288: Epoch 29
2025-02-26 23:10:10.154790: Current learning rate: 0.00735
2025-02-26 23:12:17.717866: train_loss -0.3863
2025-02-26 23:12:17.722502: val_loss -0.3545
2025-02-26 23:12:17.725243: Pseudo dice [0.7845, 0.7555, 0.7758, 0.6495]
2025-02-26 23:12:17.727697: Epoch time: 127.57 s
2025-02-26 23:12:17.729846: Yayy! New best EMA pseudo Dice: 0.6663
2025-02-26 23:12:21.484123: 
2025-02-26 23:12:21.486979: Epoch 30
2025-02-26 23:12:21.489418: Current learning rate: 0.00725
2025-02-26 23:14:42.980309: train_loss -0.3971
2025-02-26 23:14:42.984928: val_loss -0.3759
2025-02-26 23:14:42.987427: Pseudo dice [0.8485, 0.7417, 0.7929, 0.6941]
2025-02-26 23:14:42.989810: Epoch time: 141.5 s
2025-02-26 23:14:42.992231: Yayy! New best EMA pseudo Dice: 0.6766
2025-02-26 23:14:47.521414: 
2025-02-26 23:14:47.524512: Epoch 31
2025-02-26 23:14:47.526970: Current learning rate: 0.00716
2025-02-26 23:17:07.654723: train_loss -0.3915
2025-02-26 23:17:07.658525: val_loss -0.3584
2025-02-26 23:17:07.660608: Pseudo dice [0.7559, 0.7583, 0.7203, 0.7222]
2025-02-26 23:17:07.662518: Epoch time: 140.14 s
2025-02-26 23:17:07.664554: Yayy! New best EMA pseudo Dice: 0.6828
2025-02-26 23:17:11.412684: 
2025-02-26 23:17:11.415278: Epoch 32
2025-02-26 23:17:11.417268: Current learning rate: 0.00707
2025-02-26 23:19:24.992593: train_loss -0.3627
2025-02-26 23:19:24.997609: val_loss -0.3612
2025-02-26 23:19:25.000330: Pseudo dice [0.7953, 0.7522, 0.8196, 0.6928]
2025-02-26 23:19:25.003025: Epoch time: 133.58 s
2025-02-26 23:19:25.005504: Yayy! New best EMA pseudo Dice: 0.691
2025-02-26 23:19:29.301455: 
2025-02-26 23:19:29.303881: Epoch 33
2025-02-26 23:19:29.306002: Current learning rate: 0.00697
2025-02-26 23:21:49.256858: train_loss -0.3901
2025-02-26 23:21:49.261379: val_loss -0.386
2025-02-26 23:21:49.264101: Pseudo dice [0.8182, 0.7666, 0.7669, 0.7082]
2025-02-26 23:21:49.266642: Epoch time: 139.96 s
2025-02-26 23:21:49.269446: Yayy! New best EMA pseudo Dice: 0.6984
2025-02-26 23:21:53.234105: 
2025-02-26 23:21:53.237049: Epoch 34
2025-02-26 23:21:53.239143: Current learning rate: 0.00688
2025-02-26 23:24:05.745423: train_loss -0.4072
2025-02-26 23:24:05.750367: val_loss -0.3958
2025-02-26 23:24:05.753206: Pseudo dice [0.8336, 0.7794, 0.8154, 0.6785]
2025-02-26 23:24:05.755944: Epoch time: 132.51 s
2025-02-26 23:24:05.758538: Yayy! New best EMA pseudo Dice: 0.7063
2025-02-26 23:24:10.129341: 
2025-02-26 23:24:10.133384: Epoch 35
2025-02-26 23:24:10.135808: Current learning rate: 0.00679
2025-02-26 23:26:29.841444: train_loss -0.3994
2025-02-26 23:26:29.846106: val_loss -0.3829
2025-02-26 23:26:29.848828: Pseudo dice [0.801, 0.807, 0.8104, 0.748]
2025-02-26 23:26:29.850705: Epoch time: 139.71 s
2025-02-26 23:26:29.853144: Yayy! New best EMA pseudo Dice: 0.7148
2025-02-26 23:26:34.457510: 
2025-02-26 23:26:34.460105: Epoch 36
2025-02-26 23:26:34.462036: Current learning rate: 0.00669
2025-02-26 23:28:56.486138: train_loss -0.4155
2025-02-26 23:28:56.491126: val_loss -0.3878
2025-02-26 23:28:56.494091: Pseudo dice [0.8555, 0.8262, 0.8333, 0.7467]
2025-02-26 23:28:56.496911: Epoch time: 142.03 s
2025-02-26 23:28:56.499076: Yayy! New best EMA pseudo Dice: 0.7249
2025-02-26 23:29:00.536032: 
2025-02-26 23:29:00.538632: Epoch 37
2025-02-26 23:29:00.541127: Current learning rate: 0.0066
2025-02-26 23:31:09.424805: train_loss -0.411
2025-02-26 23:31:09.429417: val_loss -0.4004
2025-02-26 23:31:09.431847: Pseudo dice [0.8274, 0.8047, 0.8187, 0.7653]
2025-02-26 23:31:09.434484: Epoch time: 128.89 s
2025-02-26 23:31:09.436931: Yayy! New best EMA pseudo Dice: 0.7328
2025-02-26 23:31:13.922275: 
2025-02-26 23:31:13.925070: Epoch 38
2025-02-26 23:31:13.926800: Current learning rate: 0.0065
2025-02-26 23:33:35.742863: train_loss -0.4196
2025-02-26 23:33:35.747559: val_loss -0.3709
2025-02-26 23:33:35.749918: Pseudo dice [0.7976, 0.7643, 0.7912, 0.6927]
2025-02-26 23:33:35.752106: Epoch time: 141.82 s
2025-02-26 23:33:35.754293: Yayy! New best EMA pseudo Dice: 0.7356
2025-02-26 23:33:40.430203: 
2025-02-26 23:33:40.432938: Epoch 39
2025-02-26 23:33:40.434961: Current learning rate: 0.00641
2025-02-26 23:35:58.002174: train_loss -0.4267
2025-02-26 23:35:58.006942: val_loss -0.3797
2025-02-26 23:35:58.009725: Pseudo dice [0.8175, 0.7996, 0.794, 0.7783]
2025-02-26 23:35:58.012192: Epoch time: 137.57 s
2025-02-26 23:35:58.014415: Yayy! New best EMA pseudo Dice: 0.7418
2025-02-26 23:36:02.791866: 
2025-02-26 23:36:02.793919: Epoch 40
2025-02-26 23:36:02.795956: Current learning rate: 0.00631
2025-02-26 23:38:06.412246: train_loss -0.4335
2025-02-26 23:38:06.417276: val_loss -0.4043
2025-02-26 23:38:06.419547: Pseudo dice [0.8038, 0.8531, 0.808, 0.7804]
2025-02-26 23:38:06.422240: Epoch time: 123.62 s
2025-02-26 23:38:06.424805: Yayy! New best EMA pseudo Dice: 0.7488
2025-02-26 23:38:10.224419: 
2025-02-26 23:38:10.226774: Epoch 41
2025-02-26 23:38:10.228796: Current learning rate: 0.00622
2025-02-26 23:40:23.618401: train_loss -0.4354
2025-02-26 23:40:23.622834: val_loss -0.35
2025-02-26 23:40:23.625272: Pseudo dice [0.8372, 0.7883, 0.7471, 0.7472]
2025-02-26 23:40:23.627119: Epoch time: 133.39 s
2025-02-26 23:40:23.629522: Yayy! New best EMA pseudo Dice: 0.7519
2025-02-26 23:40:27.317322: 
2025-02-26 23:40:27.319960: Epoch 42
2025-02-26 23:40:27.322052: Current learning rate: 0.00612
2025-02-26 23:42:47.004667: train_loss -0.4423
2025-02-26 23:42:47.009409: val_loss -0.3817
2025-02-26 23:42:47.012201: Pseudo dice [0.8238, 0.7941, 0.8263, 0.7547]
2025-02-26 23:42:47.014510: Epoch time: 139.69 s
2025-02-26 23:42:47.016993: Yayy! New best EMA pseudo Dice: 0.7567
2025-02-26 23:42:51.293597: 
2025-02-26 23:42:51.295588: Epoch 43
2025-02-26 23:42:51.297208: Current learning rate: 0.00603
2025-02-26 23:45:03.470752: train_loss -0.4296
2025-02-26 23:45:03.475306: val_loss -0.4048
2025-02-26 23:45:03.478029: Pseudo dice [0.8541, 0.7667, 0.8426, 0.7526]
2025-02-26 23:45:03.480504: Epoch time: 132.18 s
2025-02-26 23:45:03.482698: Yayy! New best EMA pseudo Dice: 0.7614
2025-02-26 23:45:07.811547: 
2025-02-26 23:45:07.814502: Epoch 44
2025-02-26 23:45:07.816843: Current learning rate: 0.00593
2025-02-26 23:47:27.926482: train_loss -0.4245
2025-02-26 23:47:27.930998: val_loss -0.3926
2025-02-26 23:47:27.933356: Pseudo dice [0.7929, 0.8282, 0.7892, 0.7526]
2025-02-26 23:47:27.935302: Epoch time: 140.12 s
2025-02-26 23:47:27.937597: Yayy! New best EMA pseudo Dice: 0.7643
2025-02-26 23:47:31.587165: 
2025-02-26 23:47:31.589411: Epoch 45
2025-02-26 23:47:31.591082: Current learning rate: 0.00584
2025-02-26 23:49:57.017698: train_loss -0.437
2025-02-26 23:49:57.022218: val_loss -0.4242
2025-02-26 23:49:57.024890: Pseudo dice [0.8647, 0.8317, 0.8355, 0.7508]
2025-02-26 23:49:57.027022: Epoch time: 145.43 s
2025-02-26 23:49:57.029646: Yayy! New best EMA pseudo Dice: 0.77
2025-02-26 23:50:00.761081: 
2025-02-26 23:50:00.763689: Epoch 46
2025-02-26 23:50:00.766016: Current learning rate: 0.00574
2025-02-26 23:52:39.671511: train_loss -0.4367
2025-02-26 23:52:39.675342: val_loss -0.3898
2025-02-26 23:52:39.677204: Pseudo dice [0.8373, 0.8609, 0.7816, 0.726]
2025-02-26 23:52:39.678891: Epoch time: 158.91 s
2025-02-26 23:52:39.680664: Yayy! New best EMA pseudo Dice: 0.7731
2025-02-26 23:52:43.328221: 
2025-02-26 23:52:43.330942: Epoch 47
2025-02-26 23:52:43.333198: Current learning rate: 0.00565
2025-02-26 23:55:17.464345: train_loss -0.4445
2025-02-26 23:55:17.469390: val_loss -0.3446
2025-02-26 23:55:17.471914: Pseudo dice [0.8329, 0.7107, 0.8177, 0.7336]
2025-02-26 23:55:17.474412: Epoch time: 154.14 s
2025-02-26 23:55:17.477051: Yayy! New best EMA pseudo Dice: 0.7732
2025-02-26 23:55:21.125692: 
2025-02-26 23:55:21.128413: Epoch 48
2025-02-26 23:55:21.130758: Current learning rate: 0.00555
2025-02-26 23:58:04.505408: train_loss -0.4361
2025-02-26 23:58:04.509915: val_loss -0.4126
2025-02-26 23:58:04.512735: Pseudo dice [0.8363, 0.8307, 0.7773, 0.7808]
2025-02-26 23:58:04.514866: Epoch time: 163.38 s
2025-02-26 23:58:04.517112: Yayy! New best EMA pseudo Dice: 0.7765
2025-02-26 23:58:08.199840: 
2025-02-26 23:58:08.202563: Epoch 49
2025-02-26 23:58:08.204996: Current learning rate: 0.00546
2025-02-27 00:00:49.142788: train_loss -0.4299
2025-02-27 00:00:49.147546: val_loss -0.3748
2025-02-27 00:00:49.149873: Pseudo dice [0.8316, 0.7654, 0.8115, 0.7099]
2025-02-27 00:00:49.152407: Epoch time: 160.94 s
2025-02-27 00:00:51.389513: Yayy! New best EMA pseudo Dice: 0.7768
2025-02-27 00:00:55.114417: 
2025-02-27 00:00:55.117166: Epoch 50
2025-02-27 00:00:55.119034: Current learning rate: 0.00536
2025-02-27 00:03:45.343570: train_loss -0.4493
2025-02-27 00:03:45.348281: val_loss -0.3911
2025-02-27 00:03:45.350302: Pseudo dice [0.8504, 0.8045, 0.802, 0.7488]
2025-02-27 00:03:45.353207: Epoch time: 170.23 s
2025-02-27 00:03:45.355807: Yayy! New best EMA pseudo Dice: 0.7793
2025-02-27 00:03:48.995468: 
2025-02-27 00:03:48.998054: Epoch 51
2025-02-27 00:03:49.000228: Current learning rate: 0.00526
2025-02-27 00:06:41.161330: train_loss -0.443
2025-02-27 00:06:41.166036: val_loss -0.3939
2025-02-27 00:06:41.168519: Pseudo dice [0.8513, 0.775, 0.8063, 0.7243]
2025-02-27 00:06:41.170668: Epoch time: 172.17 s
2025-02-27 00:06:41.173002: Yayy! New best EMA pseudo Dice: 0.7803
2025-02-27 00:06:44.865914: 
2025-02-27 00:06:44.868166: Epoch 52
2025-02-27 00:06:44.869921: Current learning rate: 0.00517
2025-02-27 00:09:33.549029: train_loss -0.4367
2025-02-27 00:09:33.553450: val_loss -0.3693
2025-02-27 00:09:33.556056: Pseudo dice [0.8441, 0.741, 0.8103, 0.7219]
2025-02-27 00:09:33.558258: Epoch time: 168.68 s
2025-02-27 00:09:34.969736: 
2025-02-27 00:09:34.972630: Epoch 53
2025-02-27 00:09:34.974957: Current learning rate: 0.00507
2025-02-27 00:12:25.734782: train_loss -0.449
2025-02-27 00:12:25.739722: val_loss -0.4098
2025-02-27 00:12:25.741973: Pseudo dice [0.8178, 0.8275, 0.806, 0.7662]
2025-02-27 00:12:25.744638: Epoch time: 170.77 s
2025-02-27 00:12:25.746921: Yayy! New best EMA pseudo Dice: 0.7826
2025-02-27 00:12:29.418855: 
2025-02-27 00:12:29.421178: Epoch 54
2025-02-27 00:12:29.423191: Current learning rate: 0.00497
2025-02-27 00:15:12.792795: train_loss -0.4511
2025-02-27 00:15:12.797229: val_loss -0.4041
2025-02-27 00:15:12.799588: Pseudo dice [0.8239, 0.8328, 0.7695, 0.7688]
2025-02-27 00:15:12.801647: Epoch time: 163.37 s
2025-02-27 00:15:12.803997: Yayy! New best EMA pseudo Dice: 0.7842
2025-02-27 00:15:16.461648: 
2025-02-27 00:15:16.464551: Epoch 55
2025-02-27 00:15:16.466863: Current learning rate: 0.00487
2025-02-27 00:17:59.449971: train_loss -0.4425
2025-02-27 00:17:59.454695: val_loss -0.4075
2025-02-27 00:17:59.457108: Pseudo dice [0.8527, 0.8001, 0.8111, 0.7464]
2025-02-27 00:17:59.459296: Epoch time: 162.99 s
2025-02-27 00:17:59.461530: Yayy! New best EMA pseudo Dice: 0.786
2025-02-27 00:18:03.113249: 
2025-02-27 00:18:03.116156: Epoch 56
2025-02-27 00:18:03.118499: Current learning rate: 0.00478
2025-02-27 00:20:45.093755: train_loss -0.4473
2025-02-27 00:20:45.098646: val_loss -0.4232
2025-02-27 00:20:45.101331: Pseudo dice [0.8516, 0.8472, 0.8398, 0.7892]
2025-02-27 00:20:45.103745: Epoch time: 161.98 s
2025-02-27 00:20:45.106125: Yayy! New best EMA pseudo Dice: 0.7906
2025-02-27 00:20:48.713644: 
2025-02-27 00:20:48.716127: Epoch 57
2025-02-27 00:20:48.717855: Current learning rate: 0.00468
2025-02-27 00:23:23.389186: train_loss -0.4505
2025-02-27 00:23:23.393395: val_loss -0.3943
2025-02-27 00:23:23.395522: Pseudo dice [0.8576, 0.8138, 0.847, 0.7821]
2025-02-27 00:23:23.397638: Epoch time: 154.68 s
2025-02-27 00:23:23.399621: Yayy! New best EMA pseudo Dice: 0.7941
2025-02-27 00:23:27.062224: 
2025-02-27 00:23:27.064581: Epoch 58
2025-02-27 00:23:27.066508: Current learning rate: 0.00458
2025-02-27 00:26:08.964098: train_loss -0.4552
2025-02-27 00:26:08.968915: val_loss -0.398
2025-02-27 00:26:08.971126: Pseudo dice [0.8402, 0.8104, 0.8374, 0.792]
2025-02-27 00:26:08.973446: Epoch time: 161.9 s
2025-02-27 00:26:08.975692: Yayy! New best EMA pseudo Dice: 0.7967
2025-02-27 00:26:12.549775: 
2025-02-27 00:26:12.552599: Epoch 59
2025-02-27 00:26:12.555161: Current learning rate: 0.00448
2025-02-27 00:28:52.018058: train_loss -0.4624
2025-02-27 00:28:52.022402: val_loss -0.4152
2025-02-27 00:28:52.024907: Pseudo dice [0.8796, 0.857, 0.8143, 0.8143]
2025-02-27 00:28:52.026901: Epoch time: 159.47 s
2025-02-27 00:28:52.029203: Yayy! New best EMA pseudo Dice: 0.8011
2025-02-27 00:28:55.679101: 
2025-02-27 00:28:55.681599: Epoch 60
2025-02-27 00:28:55.683631: Current learning rate: 0.00438
2025-02-27 00:31:39.830257: train_loss -0.4656
2025-02-27 00:31:39.834716: val_loss -0.4091
2025-02-27 00:31:39.837759: Pseudo dice [0.8542, 0.8295, 0.8098, 0.772]
2025-02-27 00:31:39.840260: Epoch time: 164.15 s
2025-02-27 00:31:39.842323: Yayy! New best EMA pseudo Dice: 0.8027
2025-02-27 00:31:43.623005: 
2025-02-27 00:31:43.625709: Epoch 61
2025-02-27 00:31:43.627918: Current learning rate: 0.00429
2025-02-27 00:34:25.445713: train_loss -0.4607
2025-02-27 00:34:25.450454: val_loss -0.4421
2025-02-27 00:34:25.452963: Pseudo dice [0.842, 0.8785, 0.8138, 0.7914]
2025-02-27 00:34:25.455207: Epoch time: 161.82 s
2025-02-27 00:34:25.457463: Yayy! New best EMA pseudo Dice: 0.8055
2025-02-27 00:34:29.177989: 
2025-02-27 00:34:29.180419: Epoch 62
2025-02-27 00:34:29.182357: Current learning rate: 0.00419
2025-02-27 00:37:20.349501: train_loss -0.4715
2025-02-27 00:37:20.354361: val_loss -0.391
2025-02-27 00:37:20.357042: Pseudo dice [0.8357, 0.8372, 0.8186, 0.7889]
2025-02-27 00:37:20.359432: Epoch time: 171.17 s
2025-02-27 00:37:20.361619: Yayy! New best EMA pseudo Dice: 0.807
2025-02-27 00:37:24.812101: 
2025-02-27 00:37:24.814235: Epoch 63
2025-02-27 00:37:24.815955: Current learning rate: 0.00409
2025-02-27 00:40:14.922475: train_loss -0.4576
2025-02-27 00:40:14.927363: val_loss -0.4163
2025-02-27 00:40:14.929856: Pseudo dice [0.8563, 0.8637, 0.837, 0.768]
2025-02-27 00:40:14.932485: Epoch time: 170.11 s
2025-02-27 00:40:14.934921: Yayy! New best EMA pseudo Dice: 0.8094
2025-02-27 00:40:18.677289: 
2025-02-27 00:40:18.679794: Epoch 64
2025-02-27 00:40:18.681448: Current learning rate: 0.00399
2025-02-27 00:43:04.337359: train_loss -0.4728
2025-02-27 00:43:04.342093: val_loss -0.431
2025-02-27 00:43:04.344634: Pseudo dice [0.8657, 0.8095, 0.8158, 0.7978]
2025-02-27 00:43:04.346572: Epoch time: 165.66 s
2025-02-27 00:43:04.349255: Yayy! New best EMA pseudo Dice: 0.8107
2025-02-27 00:43:08.033339: 
2025-02-27 00:43:08.036267: Epoch 65
2025-02-27 00:43:08.038155: Current learning rate: 0.00389
2025-02-27 00:45:52.905506: train_loss -0.4632
2025-02-27 00:45:52.910184: val_loss -0.4065
2025-02-27 00:45:52.913242: Pseudo dice [0.826, 0.8406, 0.8064, 0.8039]
2025-02-27 00:45:52.915738: Epoch time: 164.87 s
2025-02-27 00:45:52.918103: Yayy! New best EMA pseudo Dice: 0.8115
2025-02-27 00:45:56.685358: 
2025-02-27 00:45:56.687986: Epoch 66
2025-02-27 00:45:56.689827: Current learning rate: 0.00379
2025-02-27 00:48:35.870311: train_loss -0.4804
2025-02-27 00:48:35.874994: val_loss -0.3752
2025-02-27 00:48:35.877416: Pseudo dice [0.8078, 0.8423, 0.8212, 0.7791]
2025-02-27 00:48:35.879843: Epoch time: 159.19 s
2025-02-27 00:48:35.881903: Yayy! New best EMA pseudo Dice: 0.8117
2025-02-27 00:48:39.571412: 
2025-02-27 00:48:39.574123: Epoch 67
2025-02-27 00:48:39.576717: Current learning rate: 0.00369
2025-02-27 00:51:19.669179: train_loss -0.4734
2025-02-27 00:51:19.673409: val_loss -0.441
2025-02-27 00:51:19.675552: Pseudo dice [0.8518, 0.8626, 0.8294, 0.7725]
2025-02-27 00:51:19.677443: Epoch time: 160.1 s
2025-02-27 00:51:19.679329: Yayy! New best EMA pseudo Dice: 0.8134
2025-02-27 00:51:23.438716: 
2025-02-27 00:51:23.441213: Epoch 68
2025-02-27 00:51:23.442952: Current learning rate: 0.00359
2025-02-27 00:53:59.716261: train_loss -0.4769
2025-02-27 00:53:59.721185: val_loss -0.4077
2025-02-27 00:53:59.723285: Pseudo dice [0.8712, 0.8328, 0.8274, 0.7309]
2025-02-27 00:53:59.725358: Epoch time: 156.28 s
2025-02-27 00:53:59.727244: Yayy! New best EMA pseudo Dice: 0.8136
2025-02-27 00:54:03.392505: 
2025-02-27 00:54:03.395321: Epoch 69
2025-02-27 00:54:03.397827: Current learning rate: 0.00349
2025-02-27 00:56:43.443446: train_loss -0.4782
2025-02-27 00:56:43.448313: val_loss -0.4061
2025-02-27 00:56:43.450581: Pseudo dice [0.8405, 0.8353, 0.8127, 0.7897]
2025-02-27 00:56:43.452952: Epoch time: 160.05 s
2025-02-27 00:56:43.455007: Yayy! New best EMA pseudo Dice: 0.8142
2025-02-27 00:56:47.133405: 
2025-02-27 00:56:47.136049: Epoch 70
2025-02-27 00:56:47.137972: Current learning rate: 0.00338
2025-02-27 00:59:15.600752: train_loss -0.4741
2025-02-27 00:59:15.605256: val_loss -0.4055
2025-02-27 00:59:15.607225: Pseudo dice [0.854, 0.8302, 0.831, 0.7703]
2025-02-27 00:59:15.609671: Epoch time: 148.47 s
2025-02-27 00:59:15.612000: Yayy! New best EMA pseudo Dice: 0.8149
2025-02-27 00:59:19.323383: 
2025-02-27 00:59:19.326022: Epoch 71
2025-02-27 00:59:19.328074: Current learning rate: 0.00328
2025-02-27 01:01:49.938589: train_loss -0.4639
2025-02-27 01:01:49.992506: val_loss -0.4026
2025-02-27 01:01:49.994507: Pseudo dice [0.8663, 0.8494, 0.8374, 0.7685]
2025-02-27 01:01:49.996411: Epoch time: 150.62 s
2025-02-27 01:01:49.997995: Yayy! New best EMA pseudo Dice: 0.8165
2025-02-27 01:01:53.773268: 
2025-02-27 01:01:53.775446: Epoch 72
2025-02-27 01:01:53.777399: Current learning rate: 0.00318
2025-02-27 01:04:30.627103: train_loss -0.4952
2025-02-27 01:04:30.631788: val_loss -0.4135
2025-02-27 01:04:30.634280: Pseudo dice [0.8671, 0.8743, 0.8078, 0.8062]
2025-02-27 01:04:30.636914: Epoch time: 156.85 s
2025-02-27 01:04:30.638956: Yayy! New best EMA pseudo Dice: 0.8187
2025-02-27 01:04:34.355751: 
2025-02-27 01:04:34.357640: Epoch 73
2025-02-27 01:04:34.359274: Current learning rate: 0.00308
2025-02-27 01:07:07.417368: train_loss -0.4735
2025-02-27 01:07:07.422058: val_loss -0.4078
2025-02-27 01:07:07.424258: Pseudo dice [0.873, 0.8419, 0.8304, 0.7678]
2025-02-27 01:07:07.426255: Epoch time: 153.06 s
2025-02-27 01:07:07.428423: Yayy! New best EMA pseudo Dice: 0.8197
2025-02-27 01:07:11.126998: 
2025-02-27 01:07:11.129792: Epoch 74
2025-02-27 01:07:11.132006: Current learning rate: 0.00297
2025-02-27 01:09:56.804017: train_loss -0.4793
2025-02-27 01:09:56.809089: val_loss -0.4145
2025-02-27 01:09:56.811400: Pseudo dice [0.8667, 0.846, 0.8429, 0.7972]
2025-02-27 01:09:56.813946: Epoch time: 165.68 s
2025-02-27 01:09:56.816195: Yayy! New best EMA pseudo Dice: 0.8215
2025-02-27 01:10:00.545136: 
2025-02-27 01:10:00.547376: Epoch 75
2025-02-27 01:10:00.549286: Current learning rate: 0.00287
2025-02-27 01:12:42.580436: train_loss -0.4812
2025-02-27 01:12:42.585322: val_loss -0.4175
2025-02-27 01:12:42.587829: Pseudo dice [0.8128, 0.8406, 0.7894, 0.7677]
2025-02-27 01:12:42.590375: Epoch time: 162.04 s
2025-02-27 01:12:44.286616: 
2025-02-27 01:12:44.289464: Epoch 76
2025-02-27 01:12:44.291420: Current learning rate: 0.00277
2025-02-27 01:15:34.081278: train_loss -0.4892
2025-02-27 01:15:34.086093: val_loss -0.4376
2025-02-27 01:15:34.088629: Pseudo dice [0.8759, 0.866, 0.8599, 0.823]
2025-02-27 01:15:34.091070: Epoch time: 169.8 s
2025-02-27 01:15:34.093650: Yayy! New best EMA pseudo Dice: 0.8233
2025-02-27 01:15:37.782349: 
2025-02-27 01:15:37.784710: Epoch 77
2025-02-27 01:15:37.786241: Current learning rate: 0.00266
2025-02-27 01:18:30.815522: train_loss -0.468
2025-02-27 01:18:30.820372: val_loss -0.4249
2025-02-27 01:18:30.822659: Pseudo dice [0.8166, 0.8656, 0.8259, 0.7984]
2025-02-27 01:18:30.824835: Epoch time: 173.03 s
2025-02-27 01:18:30.826888: Yayy! New best EMA pseudo Dice: 0.8236
2025-02-27 01:18:34.544942: 
2025-02-27 01:18:34.547283: Epoch 78
2025-02-27 01:18:34.549680: Current learning rate: 0.00256
2025-02-27 01:21:20.409382: train_loss -0.4721
2025-02-27 01:21:20.414320: val_loss -0.4149
2025-02-27 01:21:20.416873: Pseudo dice [0.8666, 0.8357, 0.8505, 0.8073]
2025-02-27 01:21:20.419329: Epoch time: 165.87 s
2025-02-27 01:21:20.421973: Yayy! New best EMA pseudo Dice: 0.8253
2025-02-27 01:21:24.159043: 
2025-02-27 01:21:24.161899: Epoch 79
2025-02-27 01:21:24.164449: Current learning rate: 0.00245
2025-02-27 01:24:11.977640: train_loss -0.4902
2025-02-27 01:24:11.982404: val_loss -0.4025
2025-02-27 01:24:11.984842: Pseudo dice [0.8783, 0.8505, 0.8143, 0.7576]
2025-02-27 01:24:11.986871: Epoch time: 167.82 s
2025-02-27 01:24:14.125561: 
2025-02-27 01:24:14.128414: Epoch 80
2025-02-27 01:24:14.130677: Current learning rate: 0.00235
2025-02-27 01:26:57.379191: train_loss -0.4853
2025-02-27 01:26:57.384533: val_loss -0.422
2025-02-27 01:26:57.386977: Pseudo dice [0.861, 0.8703, 0.8204, 0.771]
2025-02-27 01:26:57.389473: Epoch time: 163.25 s
2025-02-27 01:26:57.391672: Yayy! New best EMA pseudo Dice: 0.8258
2025-02-27 01:27:01.204809: 
2025-02-27 01:27:01.207254: Epoch 81
2025-02-27 01:27:01.209575: Current learning rate: 0.00224
2025-02-27 01:29:41.117043: train_loss -0.4893
2025-02-27 01:29:41.122190: val_loss -0.4595
2025-02-27 01:29:41.124658: Pseudo dice [0.8838, 0.8704, 0.8582, 0.8226]
2025-02-27 01:29:41.127198: Epoch time: 159.91 s
2025-02-27 01:29:41.129710: Yayy! New best EMA pseudo Dice: 0.8291
2025-02-27 01:29:44.989634: 
2025-02-27 01:29:44.992219: Epoch 82
2025-02-27 01:29:44.994244: Current learning rate: 0.00214
2025-02-27 01:32:22.940598: train_loss -0.4903
2025-02-27 01:32:22.945946: val_loss -0.4362
2025-02-27 01:32:22.948735: Pseudo dice [0.8528, 0.8607, 0.8207, 0.7942]
2025-02-27 01:32:22.951319: Epoch time: 157.95 s
2025-02-27 01:32:22.954043: Yayy! New best EMA pseudo Dice: 0.8294
2025-02-27 01:32:26.735898: 
2025-02-27 01:32:26.738253: Epoch 83
2025-02-27 01:32:26.740301: Current learning rate: 0.00203
2025-02-27 01:34:59.618001: train_loss -0.4911
2025-02-27 01:34:59.623051: val_loss -0.4271
2025-02-27 01:34:59.625803: Pseudo dice [0.8774, 0.8843, 0.8404, 0.7721]
2025-02-27 01:34:59.628064: Epoch time: 152.88 s
2025-02-27 01:34:59.630250: Yayy! New best EMA pseudo Dice: 0.8308
2025-02-27 01:35:03.293024: 
2025-02-27 01:35:03.295635: Epoch 84
2025-02-27 01:35:03.297930: Current learning rate: 0.00192
2025-02-27 01:37:33.106247: train_loss -0.4899
2025-02-27 01:37:33.111053: val_loss -0.425
2025-02-27 01:37:33.113838: Pseudo dice [0.8657, 0.8921, 0.8461, 0.8016]
2025-02-27 01:37:33.115955: Epoch time: 149.81 s
2025-02-27 01:37:33.118225: Yayy! New best EMA pseudo Dice: 0.8329
2025-02-27 01:37:36.718853: 
2025-02-27 01:37:36.721358: Epoch 85
2025-02-27 01:37:36.723184: Current learning rate: 0.00181
2025-02-27 01:40:16.375534: train_loss -0.489
2025-02-27 01:40:16.380511: val_loss -0.4361
2025-02-27 01:40:16.382799: Pseudo dice [0.8925, 0.8811, 0.8479, 0.8139]
2025-02-27 01:40:16.385106: Epoch time: 159.66 s
2025-02-27 01:40:16.387083: Yayy! New best EMA pseudo Dice: 0.8355
2025-02-27 01:40:20.033790: 
2025-02-27 01:40:20.036276: Epoch 86
2025-02-27 01:40:20.038105: Current learning rate: 0.0017
2025-02-27 01:42:52.794992: train_loss -0.4767
2025-02-27 01:42:52.800226: val_loss -0.4408
2025-02-27 01:42:52.802639: Pseudo dice [0.8759, 0.8968, 0.8594, 0.8131]
2025-02-27 01:42:52.805070: Epoch time: 152.76 s
2025-02-27 01:42:52.807307: Yayy! New best EMA pseudo Dice: 0.838
2025-02-27 01:42:56.454216: 
2025-02-27 01:42:56.456962: Epoch 87
2025-02-27 01:42:56.459168: Current learning rate: 0.00159
2025-02-27 01:45:36.426006: train_loss -0.4847
2025-02-27 01:45:36.430992: val_loss -0.4295
2025-02-27 01:45:36.433916: Pseudo dice [0.8581, 0.8861, 0.8436, 0.8087]
2025-02-27 01:45:36.436496: Epoch time: 159.97 s
2025-02-27 01:45:36.439064: Yayy! New best EMA pseudo Dice: 0.8392
2025-02-27 01:45:40.089231: 
2025-02-27 01:45:40.091819: Epoch 88
2025-02-27 01:45:40.094259: Current learning rate: 0.00148
2025-02-27 01:48:15.022385: train_loss -0.4934
2025-02-27 01:48:15.027262: val_loss -0.4315
2025-02-27 01:48:15.030131: Pseudo dice [0.8804, 0.867, 0.8436, 0.7854]
2025-02-27 01:48:15.032883: Epoch time: 154.93 s
2025-02-27 01:48:15.035134: Yayy! New best EMA pseudo Dice: 0.8397
2025-02-27 01:48:18.584877: 
2025-02-27 01:48:18.587766: Epoch 89
2025-02-27 01:48:18.590584: Current learning rate: 0.00137
2025-02-27 01:50:52.815590: train_loss -0.4947
2025-02-27 01:50:52.820910: val_loss -0.3968
2025-02-27 01:50:52.823448: Pseudo dice [0.8611, 0.85, 0.8188, 0.7571]
2025-02-27 01:50:52.825969: Epoch time: 154.23 s
2025-02-27 01:50:54.104964: 
2025-02-27 01:50:54.106766: Epoch 90
2025-02-27 01:50:54.108425: Current learning rate: 0.00126
2025-02-27 01:53:28.656553: train_loss -0.4864
2025-02-27 01:53:28.661185: val_loss -0.4308
2025-02-27 01:53:28.663376: Pseudo dice [0.8872, 0.8721, 0.8424, 0.8226]
2025-02-27 01:53:28.665654: Epoch time: 154.55 s
2025-02-27 01:53:28.667501: Yayy! New best EMA pseudo Dice: 0.8397
2025-02-27 01:53:32.304707: 
2025-02-27 01:53:32.307194: Epoch 91
2025-02-27 01:53:32.309408: Current learning rate: 0.00115
2025-02-27 01:56:06.105542: train_loss -0.4965
2025-02-27 01:56:06.110456: val_loss -0.4359
2025-02-27 01:56:06.112636: Pseudo dice [0.8761, 0.8599, 0.8467, 0.8199]
2025-02-27 01:56:06.115258: Epoch time: 153.8 s
2025-02-27 01:56:06.117781: Yayy! New best EMA pseudo Dice: 0.8408
2025-02-27 01:56:09.687952: 
2025-02-27 01:56:09.690132: Epoch 92
2025-02-27 01:56:09.692120: Current learning rate: 0.00103
2025-02-27 01:58:34.437103: train_loss -0.4938
2025-02-27 01:58:34.442165: val_loss -0.4329
2025-02-27 01:58:34.444669: Pseudo dice [0.8728, 0.8673, 0.8379, 0.8009]
2025-02-27 01:58:34.447117: Epoch time: 144.75 s
2025-02-27 01:58:34.449710: Yayy! New best EMA pseudo Dice: 0.8412
2025-02-27 01:58:38.069949: 
2025-02-27 01:58:38.072549: Epoch 93
2025-02-27 01:58:38.074566: Current learning rate: 0.00091
2025-02-27 02:01:03.917783: train_loss -0.498
2025-02-27 02:01:03.921804: val_loss -0.4229
2025-02-27 02:01:03.923332: Pseudo dice [0.8928, 0.8611, 0.8483, 0.7954]
2025-02-27 02:01:03.925532: Epoch time: 145.85 s
2025-02-27 02:01:03.927139: Yayy! New best EMA pseudo Dice: 0.842
2025-02-27 02:01:07.615054: 
2025-02-27 02:01:07.617929: Epoch 94
2025-02-27 02:01:07.620051: Current learning rate: 0.00079
2025-02-27 02:03:30.840901: train_loss -0.5012
2025-02-27 02:03:30.846150: val_loss -0.4301
2025-02-27 02:03:30.848693: Pseudo dice [0.8791, 0.866, 0.8577, 0.7896]
2025-02-27 02:03:30.851167: Epoch time: 143.23 s
2025-02-27 02:03:30.853410: Yayy! New best EMA pseudo Dice: 0.8426
2025-02-27 02:03:34.447537: 
2025-02-27 02:03:34.449950: Epoch 95
2025-02-27 02:03:34.452090: Current learning rate: 0.00067
2025-02-27 02:05:56.319545: train_loss -0.4992
2025-02-27 02:05:56.324757: val_loss -0.4182
2025-02-27 02:05:56.326488: Pseudo dice [0.8803, 0.8795, 0.8424, 0.7872]
2025-02-27 02:05:56.329035: Epoch time: 141.87 s
2025-02-27 02:05:56.331271: Yayy! New best EMA pseudo Dice: 0.8431
2025-02-27 02:06:00.012261: 
2025-02-27 02:06:00.014809: Epoch 96
2025-02-27 02:06:00.017152: Current learning rate: 0.00055
2025-02-27 02:08:29.417328: train_loss -0.4954
2025-02-27 02:08:29.421962: val_loss -0.454
2025-02-27 02:08:29.423772: Pseudo dice [0.8733, 0.8769, 0.8413, 0.7846]
2025-02-27 02:08:29.425795: Epoch time: 149.41 s
2025-02-27 02:08:29.427372: Yayy! New best EMA pseudo Dice: 0.8432
2025-02-27 02:08:33.154032: 
2025-02-27 02:08:33.156923: Epoch 97
2025-02-27 02:08:33.159157: Current learning rate: 0.00043
2025-02-27 02:10:51.991609: train_loss -0.5006
2025-02-27 02:10:51.997027: val_loss -0.4579
2025-02-27 02:10:51.999335: Pseudo dice [0.8971, 0.8818, 0.8607, 0.8267]
2025-02-27 02:10:52.001993: Epoch time: 138.84 s
2025-02-27 02:10:52.004731: Yayy! New best EMA pseudo Dice: 0.8455
2025-02-27 02:10:56.351768: 
2025-02-27 02:10:56.354304: Epoch 98
2025-02-27 02:10:56.355855: Current learning rate: 0.0003
2025-02-27 02:13:16.525682: train_loss -0.5014
2025-02-27 02:13:16.531025: val_loss -0.4359
2025-02-27 02:13:16.534221: Pseudo dice [0.8968, 0.8637, 0.8534, 0.8036]
2025-02-27 02:13:16.536916: Epoch time: 140.18 s
2025-02-27 02:13:16.539345: Yayy! New best EMA pseudo Dice: 0.8464
2025-02-27 02:13:20.150069: 
2025-02-27 02:13:20.152710: Epoch 99
2025-02-27 02:13:20.154805: Current learning rate: 0.00016
2025-02-27 02:15:48.057332: train_loss -0.4923
2025-02-27 02:15:48.061457: val_loss -0.4286
2025-02-27 02:15:48.063524: Pseudo dice [0.8746, 0.8833, 0.8276, 0.7896]
2025-02-27 02:15:48.065252: Epoch time: 147.91 s
2025-02-27 02:15:51.723956: Training done.
2025-02-27 02:15:51.758395: Using splits from existing split file: /home3/hghr96/parm/work/AD_project/segmentation/nnUNet/data/nnUNet_preprocessed/Dataset501_AD/splits_final.json
2025-02-27 02:15:51.762489: The split file contains 5 splits.
2025-02-27 02:15:51.764144: Desired fold for training: 2
2025-02-27 02:15:51.765787: This split has 70 training and 18 validation cases.
2025-02-27 02:15:51.768704: predicting ad_009
2025-02-27 02:15:51.773684: ad_009, shape torch.Size([1, 172, 359, 172]), rank 0
2025-02-27 02:16:21.924795: predicting ad_013
2025-02-27 02:16:21.936067: ad_013, shape torch.Size([1, 163, 299, 163]), rank 0
2025-02-27 02:21:33.438635: predicting ad_017
2025-02-27 02:21:33.452028: ad_017, shape torch.Size([1, 119, 155, 119]), rank 0
2025-02-27 02:26:47.080628: predicting ad_020
2025-02-27 02:26:47.094074: ad_020, shape torch.Size([1, 177, 290, 177]), rank 0
2025-02-27 02:29:22.818940: predicting ad_025
2025-02-27 02:29:22.830014: ad_025, shape torch.Size([1, 106, 318, 106]), rank 0
2025-02-27 02:34:31.593464: predicting ad_028
2025-02-27 02:34:31.606923: ad_028, shape torch.Size([1, 177, 296, 177]), rank 0
2025-02-27 02:39:56.513694: predicting ad_033
2025-02-27 02:39:56.526646: ad_033, shape torch.Size([1, 206, 339, 206]), rank 0
2025-02-27 02:45:14.590969: predicting ad_045
2025-02-27 02:45:14.604896: ad_045, shape torch.Size([1, 163, 288, 163]), rank 0
2025-02-27 02:53:07.976799: predicting ad_047
2025-02-27 02:53:07.989546: ad_047, shape torch.Size([1, 177, 321, 177]), rank 0
2025-02-27 02:59:16.682190: predicting ad_050
2025-02-27 02:59:16.698949: ad_050, shape torch.Size([1, 172, 229, 172]), rank 0
2025-02-27 03:06:18.160567: predicting ad_055
2025-02-27 03:06:18.175359: ad_055, shape torch.Size([1, 122, 267, 122]), rank 0
2025-02-27 03:10:41.367971: predicting ad_056
2025-02-27 03:10:41.381526: ad_056, shape torch.Size([1, 195, 355, 195]), rank 0
2025-02-27 03:15:16.788390: predicting ad_063
2025-02-27 03:15:16.803038: ad_063, shape torch.Size([1, 181, 328, 181]), rank 0
2025-02-27 03:22:24.846697: predicting ad_080
2025-02-27 03:22:24.862077: ad_080, shape torch.Size([1, 141, 197, 141]), rank 0
2025-02-27 03:32:33.554074: predicting ad_083
2025-02-27 03:32:33.568071: ad_083, shape torch.Size([1, 198, 252, 198]), rank 0
2025-02-27 03:35:09.834338: predicting ad_088
2025-02-27 03:35:09.848666: ad_088, shape torch.Size([1, 148, 254, 148]), rank 0
2025-02-27 03:40:01.035396: predicting ad_089
2025-02-27 03:40:01.049867: ad_089, shape torch.Size([1, 132, 252, 132]), rank 0
2025-02-27 03:43:25.750356: predicting ad_096
2025-02-27 03:43:25.763259: ad_096, shape torch.Size([1, 207, 303, 207]), rank 0
2025-02-27 03:57:53.178877: Validation complete
2025-02-27 03:57:53.181340: Mean Validation Dice:  0.572008796347609
Finished at Thu 27 Feb 2025 03:57:56 AM GMT
Total Execution Time: 22639 seconds
