Starting at Sat 22 Feb 2025 02:22:47 PM GMT

############################
INFO: You are using the old nnU-Net default plans. We have updated our recommendations. Please consider using those instead! Read more here: https://github.com/MIC-DKFZ/nnUNet/blob/master/documentation/resenc_presets.md
############################

Using device: cuda:0

#######################################################################
Please cite the following paper when using nnU-Net:
Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.
#######################################################################

2025-02-22 14:23:02.745445: do_dummy_2d_data_aug: False
2025-02-22 14:23:02.756701: Using splits from existing split file: /home3/hghr96/parm/work/AD_project/segmentation/nnUNet/data/nnUNet_preprocess/Dataset501_AD/splits_final.json
2025-02-22 14:23:02.761284: The split file contains 5 splits.
2025-02-22 14:23:02.763145: Desired fold for training: 4
2025-02-22 14:23:02.764993: This split has 71 training and 17 validation cases.
using pin_memory on device 0
/home3/hghr96/miniconda3/envs/nnUnet/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
using pin_memory on device 0

This is the configuration used by this training:
Configuration name: 3d_fullres
 {'data_identifier': 'nnUNetPlans_3d_fullres', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 2, 'patch_size': [112, 192, 112], 'median_image_size_in_voxels': [512.0, 834.0, 512.0], 'spacing': [0.78515625, 0.7000000476837158, 0.78515625], 'normalization_schemes': ['CTNormalization'], 'use_mask_for_norm': [False], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.PlainConvUNet', 'arch_kwargs': {'n_stages': 6, 'features_per_stage': [32, 64, 128, 256, 320, 320], 'conv_op': 'torch.nn.modules.conv.Conv3d', 'kernel_sizes': [[3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]], 'strides': [[1, 1, 1], [2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2], [1, 2, 1]], 'n_conv_per_stage': [2, 2, 2, 2, 2, 2], 'n_conv_per_stage_decoder': [2, 2, 2, 2, 2], 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm3d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}}, '_kw_requires_import': ['conv_op', 'norm_op', 'dropout_op', 'nonlin']}, 'batch_dice': True} 

These are the global plan.json settings:
 {'dataset_name': 'Dataset501_AD', 'plans_name': 'nnUNetPlans', 'original_median_spacing_after_transp': [0.78515625, 0.7000000476837158, 0.78515625], 'original_median_shape_after_transp': [512, 800, 512], 'image_reader_writer': 'SimpleITKIO', 'transpose_forward': [1, 0, 2], 'transpose_backward': [1, 0, 2], 'experiment_planner_used': 'ExperimentPlanner', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 3071.0, 'mean': 161.64767456054688, 'median': 182.0, 'min': -1103.0, 'percentile_00_5': -840.0, 'percentile_99_5': 778.0, 'std': 241.90689086914062}}} 

2025-02-22 14:23:18.619095: unpacking dataset...
2025-02-22 14:23:43.690804: unpacking done...
2025-02-22 14:23:43.762740: Unable to plot network architecture:
2025-02-22 14:23:43.777022: No module named 'hiddenlayer'
2025-02-22 14:23:43.971842: 
2025-02-22 14:23:43.988063: Epoch 0
2025-02-22 14:23:44.001565: Current learning rate: 0.01
2025-02-22 14:33:30.367821: train_loss 0.5578
2025-02-22 14:33:30.377611: val_loss 0.4671
2025-02-22 14:33:30.381726: Pseudo dice [0.0, 0.0, 0.0, 0.0]
2025-02-22 14:33:30.386573: Epoch time: 586.4 s
2025-02-22 14:33:30.391168: Yayy! New best EMA pseudo Dice: 0.0
2025-02-22 14:33:34.033778: 
2025-02-22 14:33:34.038835: Epoch 1
2025-02-22 14:33:34.043446: Current learning rate: 0.00991
2025-02-22 14:38:29.917909: train_loss 0.4099
2025-02-22 14:38:29.922428: val_loss 0.4036
2025-02-22 14:38:29.925077: Pseudo dice [0.0, 0.0, 0.0, 0.0]
2025-02-22 14:38:29.927589: Epoch time: 295.89 s
2025-02-22 14:38:31.677420: 
2025-02-22 14:38:31.682545: Epoch 2
2025-02-22 14:38:31.684901: Current learning rate: 0.00982
2025-02-22 14:42:49.631345: train_loss 0.3759
2025-02-22 14:42:49.637564: val_loss 0.3548
2025-02-22 14:42:49.641809: Pseudo dice [0.0, 0.0, 0.0, 0.0]
2025-02-22 14:42:49.645874: Epoch time: 257.95 s
2025-02-22 14:42:51.208016: 
2025-02-22 14:42:51.211846: Epoch 3
2025-02-22 14:42:51.214024: Current learning rate: 0.00973
2025-02-22 14:47:32.441540: train_loss 0.3142
2025-02-22 14:47:32.450541: val_loss 0.3011
2025-02-22 14:47:32.455490: Pseudo dice [0.0, 0.0, 0.0, 0.0]
2025-02-22 14:47:32.460814: Epoch time: 281.23 s
2025-02-22 14:47:33.945259: 
2025-02-22 14:47:33.949970: Epoch 4
2025-02-22 14:47:33.957556: Current learning rate: 0.00964
2025-02-22 14:52:26.734247: train_loss 0.2812
2025-02-22 14:52:26.745257: val_loss 0.2822
2025-02-22 14:52:26.750355: Pseudo dice [0.0, 0.0, 0.0001, 0.0012]
2025-02-22 14:52:26.754160: Epoch time: 292.79 s
2025-02-22 14:52:26.760877: Yayy! New best EMA pseudo Dice: 0.0
2025-02-22 14:52:30.579018: 
2025-02-22 14:52:30.581462: Epoch 5
2025-02-22 14:52:30.583904: Current learning rate: 0.00955
2025-02-22 14:57:25.898995: train_loss 0.2692
2025-02-22 14:57:25.910984: val_loss 0.2216
2025-02-22 14:57:25.917033: Pseudo dice [0.0, 0.0, 0.0458, 0.2786]
2025-02-22 14:57:25.922825: Epoch time: 295.32 s
2025-02-22 14:57:25.928874: Yayy! New best EMA pseudo Dice: 0.0081
2025-02-22 14:57:29.773410: 
2025-02-22 14:57:29.777339: Epoch 6
2025-02-22 14:57:29.781167: Current learning rate: 0.00946
2025-02-22 15:01:58.623091: train_loss 0.2156
2025-02-22 15:01:58.635127: val_loss 0.202
2025-02-22 15:01:58.640228: Pseudo dice [0.0, 0.0, 0.0187, 0.2749]
2025-02-22 15:01:58.645619: Epoch time: 268.85 s
2025-02-22 15:01:58.649337: Yayy! New best EMA pseudo Dice: 0.0147
2025-02-22 15:02:02.528235: 
2025-02-22 15:02:02.537100: Epoch 7
2025-02-22 15:02:02.541652: Current learning rate: 0.00937
2025-02-22 15:06:18.795305: train_loss 0.219
2025-02-22 15:06:18.804779: val_loss 0.1358
2025-02-22 15:06:18.809565: Pseudo dice [0.0, 0.1083, 0.0077, 0.4229]
2025-02-22 15:06:18.814769: Epoch time: 256.27 s
2025-02-22 15:06:18.819661: Yayy! New best EMA pseudo Dice: 0.0267
2025-02-22 15:06:22.611865: 
2025-02-22 15:06:22.617065: Epoch 8
2025-02-22 15:06:22.621587: Current learning rate: 0.00928
2025-02-22 15:11:32.023102: train_loss 0.2107
2025-02-22 15:11:32.054161: val_loss 0.1539
2025-02-22 15:11:32.093865: Pseudo dice [0.0, 0.2939, 0.3368, 0.0575]
2025-02-22 15:11:32.096654: Epoch time: 309.41 s
2025-02-22 15:11:32.099413: Yayy! New best EMA pseudo Dice: 0.0412
2025-02-22 15:11:37.662452: 
2025-02-22 15:11:37.669315: Epoch 9
2025-02-22 15:11:37.673095: Current learning rate: 0.00919
2025-02-22 15:16:41.435242: train_loss 0.1734
2025-02-22 15:16:41.444188: val_loss 0.1623
2025-02-22 15:16:41.449848: Pseudo dice [0.0, 0.0729, 0.3609, 0.4112]
2025-02-22 15:16:41.455706: Epoch time: 303.77 s
2025-02-22 15:16:41.461434: Yayy! New best EMA pseudo Dice: 0.0582
2025-02-22 15:16:45.070989: 
2025-02-22 15:16:45.073706: Epoch 10
2025-02-22 15:16:45.075969: Current learning rate: 0.0091
2025-02-22 15:21:33.200502: train_loss 0.1746
2025-02-22 15:21:33.212415: val_loss 0.1784
2025-02-22 15:21:33.217644: Pseudo dice [0.0, 0.002, 0.4162, 0.4504]
2025-02-22 15:21:33.221340: Epoch time: 288.13 s
2025-02-22 15:21:33.227570: Yayy! New best EMA pseudo Dice: 0.0741
2025-02-22 15:21:36.990526: 
2025-02-22 15:21:36.993864: Epoch 11
2025-02-22 15:21:36.997255: Current learning rate: 0.009
2025-02-22 15:26:20.096159: train_loss 0.1595
2025-02-22 15:26:20.101400: val_loss 0.1635
2025-02-22 15:26:20.103358: Pseudo dice [0.0, 0.0, 0.3883, 0.4057]
2025-02-22 15:26:20.105393: Epoch time: 283.11 s
2025-02-22 15:26:20.107442: Yayy! New best EMA pseudo Dice: 0.0865
2025-02-22 15:26:23.826192: 
2025-02-22 15:26:23.830876: Epoch 12
2025-02-22 15:26:23.837113: Current learning rate: 0.00891
2025-02-22 15:31:20.084379: train_loss 0.1727
2025-02-22 15:31:20.091077: val_loss 0.1858
2025-02-22 15:31:20.093354: Pseudo dice [0.0, 0.2156, 0.2451, 0.372]
2025-02-22 15:31:20.097686: Epoch time: 296.26 s
2025-02-22 15:31:20.104123: Yayy! New best EMA pseudo Dice: 0.0987
2025-02-22 15:31:23.890836: 
2025-02-22 15:31:23.897249: Epoch 13
2025-02-22 15:31:23.902354: Current learning rate: 0.00882
2025-02-22 15:36:04.842052: train_loss 0.1453
2025-02-22 15:36:04.854180: val_loss 0.159
2025-02-22 15:36:04.860427: Pseudo dice [0.0351, 0.13, 0.2466, 0.4132]
2025-02-22 15:36:04.865595: Epoch time: 280.95 s
2025-02-22 15:36:04.869185: Yayy! New best EMA pseudo Dice: 0.1095
2025-02-22 15:36:08.633256: 
2025-02-22 15:36:08.638019: Epoch 14
2025-02-22 15:36:08.644112: Current learning rate: 0.00873
2025-02-22 15:40:48.212050: train_loss 0.1304
2025-02-22 15:40:48.224287: val_loss 0.126
2025-02-22 15:40:48.231493: Pseudo dice [0.0001, 0.1296, 0.4869, 0.371]
2025-02-22 15:40:48.235051: Epoch time: 279.58 s
2025-02-22 15:40:48.243682: Yayy! New best EMA pseudo Dice: 0.1232
2025-02-22 15:40:53.688469: 
2025-02-22 15:40:53.692320: Epoch 15
2025-02-22 15:40:53.698287: Current learning rate: 0.00864
2025-02-22 15:45:22.114572: train_loss 0.1015
2025-02-22 15:45:22.121690: val_loss 0.1379
2025-02-22 15:45:22.125036: Pseudo dice [0.0, 0.0036, 0.4822, 0.4976]
2025-02-22 15:45:22.129663: Epoch time: 268.43 s
2025-02-22 15:45:22.133822: Yayy! New best EMA pseudo Dice: 0.1355
2025-02-22 15:45:25.935967: 
2025-02-22 15:45:25.941705: Epoch 16
2025-02-22 15:45:25.947518: Current learning rate: 0.00855
2025-02-22 15:49:57.687186: train_loss 0.086
2025-02-22 15:49:57.691346: val_loss 0.0999
2025-02-22 15:49:57.693757: Pseudo dice [0.0, 0.3698, 0.4273, 0.3815]
2025-02-22 15:49:57.696229: Epoch time: 271.75 s
2025-02-22 15:49:57.698098: Yayy! New best EMA pseudo Dice: 0.1514
2025-02-22 15:50:01.617255: 
2025-02-22 15:50:01.619747: Epoch 17
2025-02-22 15:50:01.624561: Current learning rate: 0.00846
2025-02-22 15:54:23.908388: train_loss 0.1026
2025-02-22 15:54:23.915559: val_loss 0.0867
2025-02-22 15:54:23.920488: Pseudo dice [0.0, 0.0392, 0.5444, 0.4326]
2025-02-22 15:54:23.923978: Epoch time: 262.29 s
2025-02-22 15:54:23.927094: Yayy! New best EMA pseudo Dice: 0.1617
2025-02-22 15:54:27.820705: 
2025-02-22 15:54:27.825497: Epoch 18
2025-02-22 15:54:27.831623: Current learning rate: 0.00836
2025-02-22 15:59:05.828548: train_loss 0.1019
2025-02-22 15:59:05.833714: val_loss 0.0782
2025-02-22 15:59:05.837541: Pseudo dice [0.0, 0.168, 0.519, 0.4568]
2025-02-22 15:59:05.839932: Epoch time: 278.01 s
2025-02-22 15:59:05.844540: Yayy! New best EMA pseudo Dice: 0.1741
2025-02-22 15:59:09.731193: 
2025-02-22 15:59:09.735146: Epoch 19
2025-02-22 15:59:09.736784: Current learning rate: 0.00827
2025-02-22 16:03:41.927553: train_loss 0.0752
2025-02-22 16:03:41.937959: val_loss 0.1135
2025-02-22 16:03:41.944070: Pseudo dice [0.0081, 0.0165, 0.5447, 0.3392]
2025-02-22 16:03:41.950150: Epoch time: 272.2 s
2025-02-22 16:03:41.956228: Yayy! New best EMA pseudo Dice: 0.1794
2025-02-22 16:03:45.825022: 
2025-02-22 16:03:45.827707: Epoch 20
2025-02-22 16:03:45.830424: Current learning rate: 0.00818
2025-02-22 16:08:23.415078: train_loss 0.062
2025-02-22 16:08:23.422162: val_loss 0.0123
2025-02-22 16:08:23.426030: Pseudo dice [0.0639, 0.4986, 0.4837, 0.5273]
2025-02-22 16:08:23.431810: Epoch time: 277.59 s
2025-02-22 16:08:23.434173: Yayy! New best EMA pseudo Dice: 0.2008
2025-02-22 16:08:27.334533: 
2025-02-22 16:08:27.340956: Epoch 21
2025-02-22 16:08:27.345293: Current learning rate: 0.00809
2025-02-22 16:12:56.155792: train_loss 0.0398
2025-02-22 16:12:56.172679: val_loss 0.0358
2025-02-22 16:12:56.181666: Pseudo dice [0.5602, 0.3324, 0.4238, 0.4743]
2025-02-22 16:12:56.189293: Epoch time: 268.82 s
2025-02-22 16:12:56.194443: Yayy! New best EMA pseudo Dice: 0.2255
2025-02-22 16:13:01.711749: 
2025-02-22 16:13:01.716985: Epoch 22
2025-02-22 16:13:01.723186: Current learning rate: 0.008
2025-02-22 16:17:44.855206: train_loss 0.0579
2025-02-22 16:17:44.866487: val_loss 0.0309
2025-02-22 16:17:44.869658: Pseudo dice [0.253, 0.4329, 0.4981, 0.3391]
2025-02-22 16:17:44.873640: Epoch time: 283.14 s
2025-02-22 16:17:44.877401: Yayy! New best EMA pseudo Dice: 0.241
2025-02-22 16:17:48.645278: 
2025-02-22 16:17:48.649904: Epoch 23
2025-02-22 16:17:48.655775: Current learning rate: 0.0079
2025-02-22 16:22:25.541195: train_loss 0.037
2025-02-22 16:22:25.552061: val_loss 0.0283
2025-02-22 16:22:25.556442: Pseudo dice [0.1126, 0.3991, 0.6133, 0.5076]
2025-02-22 16:22:25.559746: Epoch time: 276.9 s
2025-02-22 16:22:25.565634: Yayy! New best EMA pseudo Dice: 0.2577
2025-02-22 16:22:29.289106: 
2025-02-22 16:22:29.296416: Epoch 24
2025-02-22 16:22:29.300497: Current learning rate: 0.00781
2025-02-22 16:27:03.098582: train_loss 0.0123
2025-02-22 16:27:03.109355: val_loss 0.0425
2025-02-22 16:27:03.115217: Pseudo dice [0.0, 0.2954, 0.4118, 0.4686]
2025-02-22 16:27:03.119002: Epoch time: 273.81 s
2025-02-22 16:27:03.123305: Yayy! New best EMA pseudo Dice: 0.2613
2025-02-22 16:27:06.792031: 
2025-02-22 16:27:06.795583: Epoch 25
2025-02-22 16:27:06.798711: Current learning rate: 0.00772
2025-02-22 16:31:42.811213: train_loss 0.0402
2025-02-22 16:31:42.822448: val_loss 0.0502
2025-02-22 16:31:42.828421: Pseudo dice [0.0185, 0.4164, 0.4803, 0.3663]
2025-02-22 16:31:42.833444: Epoch time: 276.02 s
2025-02-22 16:31:42.837642: Yayy! New best EMA pseudo Dice: 0.2672
2025-02-22 16:31:46.627499: 
2025-02-22 16:31:46.633265: Epoch 26
2025-02-22 16:31:46.637245: Current learning rate: 0.00763
2025-02-22 16:36:31.124148: train_loss 0.0235
2025-02-22 16:36:31.134291: val_loss -0.0053
2025-02-22 16:36:31.139229: Pseudo dice [0.0083, 0.5192, 0.4557, 0.4613]
2025-02-22 16:36:31.144115: Epoch time: 284.5 s
2025-02-22 16:36:31.149022: Yayy! New best EMA pseudo Dice: 0.2766
2025-02-22 16:36:34.844910: 
2025-02-22 16:36:34.847105: Epoch 27
2025-02-22 16:36:34.849062: Current learning rate: 0.00753
2025-02-22 16:41:23.393228: train_loss 0.059
2025-02-22 16:41:23.403188: val_loss -0.0005
2025-02-22 16:41:23.409333: Pseudo dice [0.2671, 0.4042, 0.5707, 0.4534]
2025-02-22 16:41:23.415908: Epoch time: 288.55 s
2025-02-22 16:41:23.420890: Yayy! New best EMA pseudo Dice: 0.2914
2025-02-22 16:41:28.577958: 
2025-02-22 16:41:28.584134: Epoch 28
2025-02-22 16:41:28.587761: Current learning rate: 0.00744
2025-02-22 16:45:56.811211: train_loss 0.0331
2025-02-22 16:45:56.822010: val_loss 0.0045
2025-02-22 16:45:56.826713: Pseudo dice [0.3505, 0.4688, 0.5927, 0.5]
2025-02-22 16:45:56.832389: Epoch time: 268.23 s
2025-02-22 16:45:56.836968: Yayy! New best EMA pseudo Dice: 0.31
2025-02-22 16:46:00.515432: 
2025-02-22 16:46:00.520896: Epoch 29
2025-02-22 16:46:00.525077: Current learning rate: 0.00735
2025-02-22 16:50:37.674762: train_loss 0.0164
2025-02-22 16:50:37.687232: val_loss -0.0291
2025-02-22 16:50:37.692239: Pseudo dice [0.1038, 0.4228, 0.5568, 0.5388]
2025-02-22 16:50:37.698560: Epoch time: 277.16 s
2025-02-22 16:50:37.705053: Yayy! New best EMA pseudo Dice: 0.3196
2025-02-22 16:50:41.432162: 
2025-02-22 16:50:41.434259: Epoch 30
2025-02-22 16:50:41.436225: Current learning rate: 0.00725
2025-02-22 16:55:15.234214: train_loss -0.0023
2025-02-22 16:55:15.242656: val_loss 0.0687
2025-02-22 16:55:15.246198: Pseudo dice [0.1847, 0.5315, 0.4788, 0.2342]
2025-02-22 16:55:15.249426: Epoch time: 273.8 s
2025-02-22 16:55:15.253295: Yayy! New best EMA pseudo Dice: 0.3233
2025-02-22 16:55:19.046528: 
2025-02-22 16:55:19.050423: Epoch 31
2025-02-22 16:55:19.052463: Current learning rate: 0.00716
2025-02-22 17:00:02.467496: train_loss 0.0023
2025-02-22 17:00:02.478589: val_loss -0.0265
2025-02-22 17:00:02.488111: Pseudo dice [0.5742, 0.5039, 0.5439, 0.4841]
2025-02-22 17:00:02.492586: Epoch time: 283.42 s
2025-02-22 17:00:02.501298: Yayy! New best EMA pseudo Dice: 0.3437
2025-02-22 17:00:06.259001: 
2025-02-22 17:00:06.269551: Epoch 32
2025-02-22 17:00:06.277492: Current learning rate: 0.00707
2025-02-22 17:04:58.808817: train_loss -0.0184
2025-02-22 17:04:58.814419: val_loss 0.0187
2025-02-22 17:04:58.819205: Pseudo dice [0.4498, 0.4077, 0.5798, 0.3582]
2025-02-22 17:04:58.823265: Epoch time: 292.55 s
2025-02-22 17:04:58.829573: Yayy! New best EMA pseudo Dice: 0.3542
2025-02-22 17:05:02.546599: 
2025-02-22 17:05:02.551658: Epoch 33
2025-02-22 17:05:02.557302: Current learning rate: 0.00697
2025-02-22 17:09:33.055583: train_loss -0.0201
2025-02-22 17:09:33.060150: val_loss -0.0098
2025-02-22 17:09:33.062350: Pseudo dice [0.4784, 0.4722, 0.6197, 0.3455]
2025-02-22 17:09:33.065216: Epoch time: 270.51 s
2025-02-22 17:09:33.068109: Yayy! New best EMA pseudo Dice: 0.3667
2025-02-22 17:09:36.884805: 
2025-02-22 17:09:36.889602: Epoch 34
2025-02-22 17:09:36.894360: Current learning rate: 0.00688
2025-02-22 17:14:18.373925: train_loss -0.005
2025-02-22 17:14:18.386172: val_loss -0.0138
2025-02-22 17:14:18.392429: Pseudo dice [0.2875, 0.3897, 0.6372, 0.4643]
2025-02-22 17:14:18.398670: Epoch time: 281.49 s
2025-02-22 17:14:18.404770: Yayy! New best EMA pseudo Dice: 0.3745
2025-02-22 17:14:23.484984: 
2025-02-22 17:14:23.489766: Epoch 35
2025-02-22 17:14:23.492824: Current learning rate: 0.00679
2025-02-22 17:18:53.932323: train_loss -0.0125
2025-02-22 17:18:53.936785: val_loss -0.0767
2025-02-22 17:18:53.938856: Pseudo dice [0.5055, 0.5402, 0.6225, 0.4432]
2025-02-22 17:18:53.940925: Epoch time: 270.45 s
2025-02-22 17:18:53.942881: Yayy! New best EMA pseudo Dice: 0.3898
2025-02-22 17:18:57.801732: 
2025-02-22 17:18:57.805081: Epoch 36
2025-02-22 17:18:57.808874: Current learning rate: 0.00669
2025-02-22 17:23:55.648807: train_loss -0.0284
2025-02-22 17:23:55.661476: val_loss 0.0066
2025-02-22 17:23:55.667678: Pseudo dice [0.5079, 0.4805, 0.5466, 0.4563]
2025-02-22 17:23:55.672757: Epoch time: 297.85 s
2025-02-22 17:23:55.676585: Yayy! New best EMA pseudo Dice: 0.4006
2025-02-22 17:23:59.496996: 
2025-02-22 17:23:59.499392: Epoch 37
2025-02-22 17:23:59.502784: Current learning rate: 0.0066
2025-02-22 17:28:34.367454: train_loss -0.0268
2025-02-22 17:28:34.379299: val_loss 0.0072
2025-02-22 17:28:34.385623: Pseudo dice [0.1777, 0.4369, 0.65, 0.4524]
2025-02-22 17:28:34.389333: Epoch time: 274.87 s
2025-02-22 17:28:34.396612: Yayy! New best EMA pseudo Dice: 0.4035
2025-02-22 17:28:38.253740: 
2025-02-22 17:28:38.259526: Epoch 38
2025-02-22 17:28:38.263722: Current learning rate: 0.0065
2025-02-22 17:33:12.911467: train_loss -0.0202
2025-02-22 17:33:12.916069: val_loss -0.0336
2025-02-22 17:33:12.917544: Pseudo dice [0.3687, 0.4594, 0.6138, 0.5305]
2025-02-22 17:33:12.919947: Epoch time: 274.66 s
2025-02-22 17:33:12.922451: Yayy! New best EMA pseudo Dice: 0.4124
2025-02-22 17:33:16.826334: 
2025-02-22 17:33:16.832485: Epoch 39
2025-02-22 17:33:16.837570: Current learning rate: 0.00641
2025-02-22 17:37:50.659648: train_loss -0.0327
2025-02-22 17:37:50.667776: val_loss -0.0352
2025-02-22 17:37:50.670080: Pseudo dice [0.2495, 0.6072, 0.702, 0.4378]
2025-02-22 17:37:50.672287: Epoch time: 273.83 s
2025-02-22 17:37:50.675908: Yayy! New best EMA pseudo Dice: 0.4211
2025-02-22 17:37:54.554575: 
2025-02-22 17:37:54.557871: Epoch 40
2025-02-22 17:37:54.563771: Current learning rate: 0.00631
2025-02-22 17:42:27.317342: train_loss -0.0454
2025-02-22 17:42:27.323854: val_loss 0.0025
2025-02-22 17:42:27.327363: Pseudo dice [0.5777, 0.3683, 0.5691, 0.537]
2025-02-22 17:42:27.330091: Epoch time: 272.76 s
2025-02-22 17:42:27.332492: Yayy! New best EMA pseudo Dice: 0.4303
2025-02-22 17:42:31.135999: 
2025-02-22 17:42:31.138980: Epoch 41
2025-02-22 17:42:31.142307: Current learning rate: 0.00622
2025-02-22 17:47:01.689341: train_loss -0.0552
2025-02-22 17:47:01.697179: val_loss -0.1001
2025-02-22 17:47:01.700542: Pseudo dice [0.4608, 0.6853, 0.6849, 0.506]
2025-02-22 17:47:01.703840: Epoch time: 270.55 s
2025-02-22 17:47:01.706514: Yayy! New best EMA pseudo Dice: 0.4457
2025-02-22 17:47:06.092176: 
2025-02-22 17:47:06.096227: Epoch 42
2025-02-22 17:47:06.102155: Current learning rate: 0.00612
2025-02-22 17:51:33.945109: train_loss -0.0434
2025-02-22 17:51:33.954531: val_loss -0.0928
2025-02-22 17:51:33.959557: Pseudo dice [0.6447, 0.5502, 0.569, 0.558]
2025-02-22 17:51:33.962424: Epoch time: 267.85 s
2025-02-22 17:51:33.964871: Yayy! New best EMA pseudo Dice: 0.4592
2025-02-22 17:51:37.710373: 
2025-02-22 17:51:37.715526: Epoch 43
2025-02-22 17:51:37.719918: Current learning rate: 0.00603
2025-02-22 17:56:28.333926: train_loss -0.0718
2025-02-22 17:56:28.340424: val_loss -0.0868
2025-02-22 17:56:28.343554: Pseudo dice [0.5689, 0.6538, 0.674, 0.6216]
2025-02-22 17:56:28.347130: Epoch time: 290.62 s
2025-02-22 17:56:28.351062: Yayy! New best EMA pseudo Dice: 0.4762
2025-02-22 17:56:32.070912: 
2025-02-22 17:56:32.073212: Epoch 44
2025-02-22 17:56:32.075397: Current learning rate: 0.00593
2025-02-22 18:01:17.182510: train_loss -0.0631
2025-02-22 18:01:17.193516: val_loss -0.0576
2025-02-22 18:01:17.198662: Pseudo dice [0.5558, 0.66, 0.5228, 0.46]
2025-02-22 18:01:17.204802: Epoch time: 285.11 s
2025-02-22 18:01:17.208024: Yayy! New best EMA pseudo Dice: 0.4835
2025-02-22 18:01:21.033279: 
2025-02-22 18:01:21.038461: Epoch 45
2025-02-22 18:01:21.042114: Current learning rate: 0.00584
2025-02-22 18:05:50.842090: train_loss -0.0828
2025-02-22 18:05:50.849983: val_loss -0.0314
2025-02-22 18:05:50.854657: Pseudo dice [0.5507, 0.4226, 0.6554, 0.5504]
2025-02-22 18:05:50.859787: Epoch time: 269.81 s
2025-02-22 18:05:50.864656: Yayy! New best EMA pseudo Dice: 0.4897
2025-02-22 18:05:54.522007: 
2025-02-22 18:05:54.526684: Epoch 46
2025-02-22 18:05:54.529436: Current learning rate: 0.00574
2025-02-22 18:10:40.753764: train_loss -0.0748
2025-02-22 18:10:40.761730: val_loss -0.0565
2025-02-22 18:10:40.765803: Pseudo dice [0.5032, 0.5725, 0.6674, 0.5049]
2025-02-22 18:10:40.770303: Epoch time: 286.23 s
2025-02-22 18:10:40.776234: Yayy! New best EMA pseudo Dice: 0.4969
2025-02-22 18:10:44.482014: 
2025-02-22 18:10:44.485044: Epoch 47
2025-02-22 18:10:44.488158: Current learning rate: 0.00565
2025-02-22 18:15:14.800347: train_loss -0.0793
2025-02-22 18:15:14.811080: val_loss -0.0354
2025-02-22 18:15:14.815903: Pseudo dice [0.4992, 0.6255, 0.7233, 0.5604]
2025-02-22 18:15:14.820799: Epoch time: 270.32 s
2025-02-22 18:15:14.827341: Yayy! New best EMA pseudo Dice: 0.5074
2025-02-22 18:15:19.616211: 
2025-02-22 18:15:19.619451: Epoch 48
2025-02-22 18:15:19.625507: Current learning rate: 0.00555
2025-02-22 18:19:43.571984: train_loss -0.0671
2025-02-22 18:19:43.583180: val_loss -0.1011
2025-02-22 18:19:43.588104: Pseudo dice [0.4754, 0.605, 0.7241, 0.5494]
2025-02-22 18:19:43.593083: Epoch time: 263.96 s
2025-02-22 18:19:43.597613: Yayy! New best EMA pseudo Dice: 0.5155
2025-02-22 18:19:47.306020: 
2025-02-22 18:19:47.308887: Epoch 49
2025-02-22 18:19:47.310982: Current learning rate: 0.00546
2025-02-22 18:24:34.281583: train_loss -0.0995
2025-02-22 18:24:34.290701: val_loss -0.0848
2025-02-22 18:24:34.295119: Pseudo dice [0.7299, 0.5141, 0.7421, 0.4694]
2025-02-22 18:24:34.300107: Epoch time: 286.98 s
2025-02-22 18:24:36.627054: Yayy! New best EMA pseudo Dice: 0.5254
2025-02-22 18:24:40.609637: 
2025-02-22 18:24:40.611885: Epoch 50
2025-02-22 18:24:40.613700: Current learning rate: 0.00536
2025-02-22 18:29:34.782183: train_loss -0.1203
2025-02-22 18:29:34.792795: val_loss -0.1385
2025-02-22 18:29:34.796525: Pseudo dice [0.7071, 0.6611, 0.724, 0.5489]
2025-02-22 18:29:34.799886: Epoch time: 294.17 s
2025-02-22 18:29:34.803826: Yayy! New best EMA pseudo Dice: 0.5389
2025-02-22 18:29:38.695857: 
2025-02-22 18:29:38.699520: Epoch 51
2025-02-22 18:29:38.707706: Current learning rate: 0.00526
2025-02-22 18:34:23.649378: train_loss -0.0744
2025-02-22 18:34:23.659511: val_loss -0.098
2025-02-22 18:34:23.664102: Pseudo dice [0.6747, 0.5562, 0.7578, 0.5307]
2025-02-22 18:34:23.668270: Epoch time: 284.95 s
2025-02-22 18:34:23.673128: Yayy! New best EMA pseudo Dice: 0.548
2025-02-22 18:34:27.453324: 
2025-02-22 18:34:27.457818: Epoch 52
2025-02-22 18:34:27.461176: Current learning rate: 0.00517
2025-02-22 18:39:18.508747: train_loss -0.049
2025-02-22 18:39:18.517568: val_loss -0.0879
2025-02-22 18:39:18.521164: Pseudo dice [0.4941, 0.6214, 0.7219, 0.6381]
2025-02-22 18:39:18.525400: Epoch time: 291.06 s
2025-02-22 18:39:18.527661: Yayy! New best EMA pseudo Dice: 0.555
2025-02-22 18:39:22.368251: 
2025-02-22 18:39:22.370963: Epoch 53
2025-02-22 18:39:22.374153: Current learning rate: 0.00507
2025-02-22 18:43:44.002638: train_loss -0.0925
2025-02-22 18:43:44.014118: val_loss -0.1195
2025-02-22 18:43:44.019405: Pseudo dice [0.7161, 0.5897, 0.7954, 0.5308]
2025-02-22 18:43:44.025512: Epoch time: 261.64 s
2025-02-22 18:43:44.031657: Yayy! New best EMA pseudo Dice: 0.5653
2025-02-22 18:43:47.750991: 
2025-02-22 18:43:47.754525: Epoch 54
2025-02-22 18:43:47.758768: Current learning rate: 0.00497
2025-02-22 18:48:25.459750: train_loss -0.1259
2025-02-22 18:48:25.505019: val_loss -0.1248
2025-02-22 18:48:25.508897: Pseudo dice [0.716, 0.6227, 0.7926, 0.4959]
2025-02-22 18:48:25.516511: Epoch time: 277.71 s
2025-02-22 18:48:25.522663: Yayy! New best EMA pseudo Dice: 0.5745
2025-02-22 18:48:31.680805: 
2025-02-22 18:48:31.683076: Epoch 55
2025-02-22 18:48:31.685556: Current learning rate: 0.00487
2025-02-22 18:53:09.761567: train_loss -0.0698
2025-02-22 18:53:09.775073: val_loss 0.0339
2025-02-22 18:53:09.780190: Pseudo dice [0.4192, 0.4138, 0.5496, 0.4445]
2025-02-22 18:53:09.787583: Epoch time: 278.08 s
2025-02-22 18:53:11.215957: 
2025-02-22 18:53:11.218795: Epoch 56
2025-02-22 18:53:11.222013: Current learning rate: 0.00478
2025-02-22 18:57:52.423299: train_loss -0.1029
2025-02-22 18:57:52.433451: val_loss -0.1437
2025-02-22 18:57:52.439706: Pseudo dice [0.6919, 0.6337, 0.7909, 0.4961]
2025-02-22 18:57:52.446039: Epoch time: 281.21 s
2025-02-22 18:57:53.989979: 
2025-02-22 18:57:53.995052: Epoch 57
2025-02-22 18:57:54.000267: Current learning rate: 0.00468
2025-02-22 19:02:40.299531: train_loss -0.1355
2025-02-22 19:02:40.309795: val_loss -0.0669
2025-02-22 19:02:40.314674: Pseudo dice [0.6587, 0.6199, 0.6671, 0.5897]
2025-02-22 19:02:40.317230: Epoch time: 286.31 s
2025-02-22 19:02:40.320943: Yayy! New best EMA pseudo Dice: 0.578
2025-02-22 19:02:44.135067: 
2025-02-22 19:02:44.140208: Epoch 58
2025-02-22 19:02:44.145331: Current learning rate: 0.00458
2025-02-22 19:07:07.274489: train_loss -0.1459
2025-02-22 19:07:07.284716: val_loss -0.1268
2025-02-22 19:07:07.290497: Pseudo dice [0.6473, 0.6216, 0.8106, 0.5425]
2025-02-22 19:07:07.296576: Epoch time: 263.14 s
2025-02-22 19:07:07.302961: Yayy! New best EMA pseudo Dice: 0.5857
2025-02-22 19:07:11.113665: 
2025-02-22 19:07:11.120578: Epoch 59
2025-02-22 19:07:11.123154: Current learning rate: 0.00448
2025-02-22 19:11:56.694455: train_loss -0.1654
2025-02-22 19:11:56.702896: val_loss -0.1405
2025-02-22 19:11:56.709034: Pseudo dice [0.7591, 0.6426, 0.7541, 0.5774]
2025-02-22 19:11:56.713016: Epoch time: 285.58 s
2025-02-22 19:11:56.721483: Yayy! New best EMA pseudo Dice: 0.5955
2025-02-22 19:12:00.555345: 
2025-02-22 19:12:00.557753: Epoch 60
2025-02-22 19:12:00.560172: Current learning rate: 0.00438
2025-02-22 19:16:43.112886: train_loss -0.1708
2025-02-22 19:16:43.120218: val_loss -0.0942
2025-02-22 19:16:43.122910: Pseudo dice [0.6022, 0.6374, 0.7541, 0.5785]
2025-02-22 19:16:43.125675: Epoch time: 282.56 s
2025-02-22 19:16:43.128331: Yayy! New best EMA pseudo Dice: 0.6002
2025-02-22 19:16:46.940145: 
2025-02-22 19:16:46.942603: Epoch 61
2025-02-22 19:16:46.945837: Current learning rate: 0.00429
2025-02-22 19:21:25.982813: train_loss -0.1171
2025-02-22 19:21:25.994469: val_loss -0.0758
2025-02-22 19:21:26.002875: Pseudo dice [0.6222, 0.604, 0.6179, 0.4946]
2025-02-22 19:21:26.007816: Epoch time: 279.04 s
2025-02-22 19:21:29.240338: 
2025-02-22 19:21:29.243823: Epoch 62
2025-02-22 19:21:29.247161: Current learning rate: 0.00419
2025-02-22 19:25:44.640437: train_loss -0.1674
2025-02-22 19:25:44.648692: val_loss -0.1537
2025-02-22 19:25:44.653668: Pseudo dice [0.7639, 0.7207, 0.7766, 0.6006]
2025-02-22 19:25:44.655655: Epoch time: 255.4 s
2025-02-22 19:25:44.658461: Yayy! New best EMA pseudo Dice: 0.6104
2025-02-22 19:25:48.372086: 
2025-02-22 19:25:48.376460: Epoch 63
2025-02-22 19:25:48.380866: Current learning rate: 0.00409
2025-02-22 19:30:30.860126: train_loss -0.1623
2025-02-22 19:30:30.874780: val_loss -0.1598
2025-02-22 19:30:30.876802: Pseudo dice [0.7914, 0.6744, 0.7969, 0.5212]
2025-02-22 19:30:30.878933: Epoch time: 282.49 s
2025-02-22 19:30:30.881275: Yayy! New best EMA pseudo Dice: 0.6189
2025-02-22 19:30:34.786966: 
2025-02-22 19:30:34.791120: Epoch 64
2025-02-22 19:30:34.795777: Current learning rate: 0.00399
2025-02-22 19:35:12.504253: train_loss -0.1687
2025-02-22 19:35:12.510061: val_loss -0.1971
2025-02-22 19:35:12.514423: Pseudo dice [0.7473, 0.8062, 0.8151, 0.6323]
2025-02-22 19:35:12.517594: Epoch time: 277.72 s
2025-02-22 19:35:12.521066: Yayy! New best EMA pseudo Dice: 0.632
2025-02-22 19:35:16.345310: 
2025-02-22 19:35:16.350144: Epoch 65
2025-02-22 19:35:16.353914: Current learning rate: 0.00389
2025-02-22 19:39:57.824037: train_loss -0.1487
2025-02-22 19:39:57.833008: val_loss -0.1267
2025-02-22 19:39:57.836287: Pseudo dice [0.6622, 0.6721, 0.7674, 0.6144]
2025-02-22 19:39:57.839226: Epoch time: 281.48 s
2025-02-22 19:39:57.842303: Yayy! New best EMA pseudo Dice: 0.6367
2025-02-22 19:40:01.568515: 
2025-02-22 19:40:01.572557: Epoch 66
2025-02-22 19:40:01.577924: Current learning rate: 0.00379
2025-02-22 19:44:46.153581: train_loss -0.1165
2025-02-22 19:44:46.160582: val_loss -0.1458
2025-02-22 19:44:46.162626: Pseudo dice [0.7729, 0.7025, 0.812, 0.6485]
2025-02-22 19:44:46.164778: Epoch time: 284.59 s
2025-02-22 19:44:46.167280: Yayy! New best EMA pseudo Dice: 0.6465
2025-02-22 19:44:49.926248: 
2025-02-22 19:44:49.930343: Epoch 67
2025-02-22 19:44:49.937428: Current learning rate: 0.00369
2025-02-22 19:49:33.144988: train_loss -0.1492
2025-02-22 19:49:33.149781: val_loss -0.1943
2025-02-22 19:49:33.152209: Pseudo dice [0.787, 0.6416, 0.8173, 0.6862]
2025-02-22 19:49:33.154348: Epoch time: 283.22 s
2025-02-22 19:49:33.156386: Yayy! New best EMA pseudo Dice: 0.6551
2025-02-22 19:49:38.423705: 
2025-02-22 19:49:38.425692: Epoch 68
2025-02-22 19:49:38.428615: Current learning rate: 0.00359
2025-02-22 19:53:52.931005: train_loss -0.1665
2025-02-22 19:53:52.940089: val_loss -0.1239
2025-02-22 19:53:52.946219: Pseudo dice [0.5571, 0.6705, 0.7674, 0.6115]
2025-02-22 19:53:52.951252: Epoch time: 254.51 s
2025-02-22 19:53:54.514215: 
2025-02-22 19:53:54.516595: Epoch 69
2025-02-22 19:53:54.520123: Current learning rate: 0.00349
2025-02-22 19:58:33.270983: train_loss -0.1636
2025-02-22 19:58:33.298255: val_loss -0.2071
2025-02-22 19:58:33.304176: Pseudo dice [0.6729, 0.7755, 0.7589, 0.6885]
2025-02-22 19:58:33.309661: Epoch time: 278.76 s
2025-02-22 19:58:33.313078: Yayy! New best EMA pseudo Dice: 0.6617
2025-02-22 19:58:37.203104: 
2025-02-22 19:58:37.207172: Epoch 70
2025-02-22 19:58:37.211668: Current learning rate: 0.00338
2025-02-22 20:03:09.594408: train_loss -0.1844
2025-02-22 20:03:09.600533: val_loss -0.1522
2025-02-22 20:03:09.603168: Pseudo dice [0.6551, 0.7, 0.7722, 0.5862]
2025-02-22 20:03:09.605917: Epoch time: 272.39 s
2025-02-22 20:03:09.608375: Yayy! New best EMA pseudo Dice: 0.6634
2025-02-22 20:03:13.595963: 
2025-02-22 20:03:13.599070: Epoch 71
2025-02-22 20:03:13.602078: Current learning rate: 0.00328
2025-02-22 20:07:48.064411: train_loss -0.1859
2025-02-22 20:07:48.070100: val_loss -0.1997
2025-02-22 20:07:48.072476: Pseudo dice [0.6127, 0.7148, 0.8386, 0.6416]
2025-02-22 20:07:48.076119: Epoch time: 274.47 s
2025-02-22 20:07:48.078119: Yayy! New best EMA pseudo Dice: 0.6672
2025-02-22 20:07:51.928187: 
2025-02-22 20:07:51.934111: Epoch 72
2025-02-22 20:07:51.937550: Current learning rate: 0.00318
2025-02-22 20:12:07.073634: train_loss -0.1906
2025-02-22 20:12:07.085111: val_loss -0.1995
2025-02-22 20:12:07.091268: Pseudo dice [0.8552, 0.7035, 0.8773, 0.6296]
2025-02-22 20:12:07.097359: Epoch time: 255.15 s
2025-02-22 20:12:07.103183: Yayy! New best EMA pseudo Dice: 0.6771
2025-02-22 20:12:11.005363: 
2025-02-22 20:12:11.011873: Epoch 73
2025-02-22 20:12:11.014894: Current learning rate: 0.00308
2025-02-22 20:16:32.015111: train_loss -0.1927
2025-02-22 20:16:32.027134: val_loss -0.2236
2025-02-22 20:16:32.033302: Pseudo dice [0.7773, 0.7937, 0.8182, 0.6636]
2025-02-22 20:16:32.039667: Epoch time: 261.01 s
2025-02-22 20:16:32.045965: Yayy! New best EMA pseudo Dice: 0.6857
2025-02-22 20:16:36.734509: 
2025-02-22 20:16:36.739057: Epoch 74
2025-02-22 20:16:36.743372: Current learning rate: 0.00297
2025-02-22 20:21:05.213215: train_loss -0.2128
2025-02-22 20:21:05.226352: val_loss -0.1713
2025-02-22 20:21:05.230059: Pseudo dice [0.8092, 0.6972, 0.8016, 0.5007]
2025-02-22 20:21:05.236212: Epoch time: 268.48 s
2025-02-22 20:21:05.241156: Yayy! New best EMA pseudo Dice: 0.6874
2025-02-22 20:21:09.136501: 
2025-02-22 20:21:09.141507: Epoch 75
2025-02-22 20:21:09.147296: Current learning rate: 0.00287
2025-02-22 20:25:50.218844: train_loss -0.1908
2025-02-22 20:25:50.227880: val_loss -0.2184
2025-02-22 20:25:50.231442: Pseudo dice [0.7455, 0.7437, 0.8455, 0.7684]
2025-02-22 20:25:50.235174: Epoch time: 281.08 s
2025-02-22 20:25:50.238735: Yayy! New best EMA pseudo Dice: 0.6962
2025-02-22 20:25:54.131001: 
2025-02-22 20:25:54.136171: Epoch 76
2025-02-22 20:25:54.139193: Current learning rate: 0.00277
2025-02-22 20:30:16.220511: train_loss -0.2149
2025-02-22 20:30:16.226185: val_loss -0.1603
2025-02-22 20:30:16.230389: Pseudo dice [0.7251, 0.6795, 0.7131, 0.6025]
2025-02-22 20:30:16.234658: Epoch time: 262.09 s
2025-02-22 20:30:17.823178: 
2025-02-22 20:30:17.828243: Epoch 77
2025-02-22 20:30:17.834279: Current learning rate: 0.00266
2025-02-22 20:34:51.476571: train_loss -0.2094
2025-02-22 20:34:51.485658: val_loss -0.2
2025-02-22 20:34:51.490458: Pseudo dice [0.6747, 0.775, 0.8154, 0.7406]
2025-02-22 20:34:51.494577: Epoch time: 273.65 s
2025-02-22 20:34:51.502532: Yayy! New best EMA pseudo Dice: 0.7003
2025-02-22 20:34:55.412126: 
2025-02-22 20:34:55.418299: Epoch 78
2025-02-22 20:34:55.423610: Current learning rate: 0.00256
2025-02-22 20:39:20.256767: train_loss -0.2082
2025-02-22 20:39:20.264022: val_loss -0.2075
2025-02-22 20:39:20.269189: Pseudo dice [0.8427, 0.7788, 0.8069, 0.674]
2025-02-22 20:39:20.272851: Epoch time: 264.85 s
2025-02-22 20:39:20.277825: Yayy! New best EMA pseudo Dice: 0.7078
2025-02-22 20:39:24.171305: 
2025-02-22 20:39:24.174955: Epoch 79
2025-02-22 20:39:24.178037: Current learning rate: 0.00245
2025-02-22 20:43:58.199189: train_loss -0.2293
2025-02-22 20:43:58.208474: val_loss -0.244
2025-02-22 20:43:58.212956: Pseudo dice [0.8292, 0.7652, 0.8623, 0.7018]
2025-02-22 20:43:58.217421: Epoch time: 274.03 s
2025-02-22 20:43:58.221917: Yayy! New best EMA pseudo Dice: 0.716
2025-02-22 20:44:02.146951: 
2025-02-22 20:44:02.149468: Epoch 80
2025-02-22 20:44:02.151771: Current learning rate: 0.00235
2025-02-22 20:48:41.380555: train_loss -0.2052
2025-02-22 20:48:41.391886: val_loss -0.2026
2025-02-22 20:48:41.398149: Pseudo dice [0.7637, 0.7422, 0.8464, 0.6838]
2025-02-22 20:48:41.404364: Epoch time: 279.23 s
2025-02-22 20:48:41.410433: Yayy! New best EMA pseudo Dice: 0.7203
2025-02-22 20:48:46.747357: 
2025-02-22 20:48:46.753332: Epoch 81
2025-02-22 20:48:46.757491: Current learning rate: 0.00224
2025-02-22 20:53:27.107619: train_loss -0.211
2025-02-22 20:53:27.114626: val_loss -0.1716
2025-02-22 20:53:27.118022: Pseudo dice [0.7901, 0.7011, 0.8035, 0.7291]
2025-02-22 20:53:27.120283: Epoch time: 280.36 s
2025-02-22 20:53:27.122568: Yayy! New best EMA pseudo Dice: 0.7239
2025-02-22 20:53:30.910882: 
2025-02-22 20:53:30.914447: Epoch 82
2025-02-22 20:53:30.917326: Current learning rate: 0.00214
2025-02-22 20:57:57.770168: train_loss -0.2158
2025-02-22 20:57:57.778437: val_loss -0.23
2025-02-22 20:57:57.782633: Pseudo dice [0.8042, 0.784, 0.8455, 0.6658]
2025-02-22 20:57:57.788048: Epoch time: 266.86 s
2025-02-22 20:57:57.790287: Yayy! New best EMA pseudo Dice: 0.729
2025-02-22 20:58:01.599277: 
2025-02-22 20:58:01.605720: Epoch 83
2025-02-22 20:58:01.613423: Current learning rate: 0.00203
2025-02-22 21:02:32.975139: train_loss -0.235
2025-02-22 21:02:32.993866: val_loss -0.2205
2025-02-22 21:02:33.002947: Pseudo dice [0.7384, 0.7453, 0.8245, 0.6396]
2025-02-22 21:02:33.011899: Epoch time: 271.38 s
2025-02-22 21:02:33.020800: Yayy! New best EMA pseudo Dice: 0.7298
2025-02-22 21:02:36.740716: 
2025-02-22 21:02:36.747530: Epoch 84
2025-02-22 21:02:36.752147: Current learning rate: 0.00192
2025-02-22 21:07:05.380976: train_loss -0.2115
2025-02-22 21:07:05.388726: val_loss -0.2232
2025-02-22 21:07:05.394727: Pseudo dice [0.7773, 0.8066, 0.8387, 0.6597]
2025-02-22 21:07:05.398545: Epoch time: 268.64 s
2025-02-22 21:07:05.400679: Yayy! New best EMA pseudo Dice: 0.7338
2025-02-22 21:07:09.197045: 
2025-02-22 21:07:09.202281: Epoch 85
2025-02-22 21:07:09.207794: Current learning rate: 0.00181
2025-02-22 21:11:34.501874: train_loss -0.2305
2025-02-22 21:11:34.510278: val_loss -0.2042
2025-02-22 21:11:34.516496: Pseudo dice [0.8639, 0.7336, 0.8533, 0.7109]
2025-02-22 21:11:34.521965: Epoch time: 265.31 s
2025-02-22 21:11:34.526390: Yayy! New best EMA pseudo Dice: 0.7395
2025-02-22 21:11:38.344129: 
2025-02-22 21:11:38.348915: Epoch 86
2025-02-22 21:11:38.353174: Current learning rate: 0.0017
2025-02-22 21:15:57.964422: train_loss -0.2363
2025-02-22 21:15:57.971851: val_loss -0.2097
2025-02-22 21:15:57.976700: Pseudo dice [0.828, 0.7375, 0.8675, 0.7277]
2025-02-22 21:15:57.979496: Epoch time: 259.62 s
2025-02-22 21:15:57.981845: Yayy! New best EMA pseudo Dice: 0.7446
2025-02-22 21:16:02.910806: 
2025-02-22 21:16:02.917833: Epoch 87
2025-02-22 21:16:02.923005: Current learning rate: 0.00159
2025-02-22 21:20:31.124050: train_loss -0.216
2025-02-22 21:20:31.130314: val_loss -0.2263
2025-02-22 21:20:31.133981: Pseudo dice [0.7795, 0.8093, 0.8112, 0.7465]
2025-02-22 21:20:31.137824: Epoch time: 268.21 s
2025-02-22 21:20:31.141474: Yayy! New best EMA pseudo Dice: 0.7488
2025-02-22 21:20:34.900127: 
2025-02-22 21:20:34.903984: Epoch 88
2025-02-22 21:20:34.908407: Current learning rate: 0.00148
2025-02-22 21:25:11.098550: train_loss -0.2205
2025-02-22 21:25:11.102936: val_loss -0.2173
2025-02-22 21:25:11.105021: Pseudo dice [0.8287, 0.7975, 0.8055, 0.6735]
2025-02-22 21:25:11.107139: Epoch time: 276.2 s
2025-02-22 21:25:11.109170: Yayy! New best EMA pseudo Dice: 0.7515
2025-02-22 21:25:14.894205: 
2025-02-22 21:25:14.899653: Epoch 89
2025-02-22 21:25:14.901845: Current learning rate: 0.00137
2025-02-22 21:29:57.400503: train_loss -0.2283
2025-02-22 21:29:57.411039: val_loss -0.1951
2025-02-22 21:29:57.413926: Pseudo dice [0.8269, 0.7285, 0.8203, 0.7329]
2025-02-22 21:29:57.418337: Epoch time: 282.51 s
2025-02-22 21:29:57.423940: Yayy! New best EMA pseudo Dice: 0.7541
2025-02-22 21:30:01.113218: 
2025-02-22 21:30:01.115695: Epoch 90
2025-02-22 21:30:01.118131: Current learning rate: 0.00126
2025-02-22 21:34:27.993607: train_loss -0.244
2025-02-22 21:34:28.001665: val_loss -0.2198
2025-02-22 21:34:28.007864: Pseudo dice [0.8368, 0.8167, 0.8402, 0.7519]
2025-02-22 21:34:28.013735: Epoch time: 266.88 s
2025-02-22 21:34:28.019243: Yayy! New best EMA pseudo Dice: 0.7598
2025-02-22 21:34:31.749955: 
2025-02-22 21:34:31.754043: Epoch 91
2025-02-22 21:34:31.757984: Current learning rate: 0.00115
2025-02-22 21:38:58.281879: train_loss -0.2626
2025-02-22 21:38:58.286475: val_loss -0.2354
2025-02-22 21:38:58.289858: Pseudo dice [0.7898, 0.8032, 0.8215, 0.6843]
2025-02-22 21:38:58.292650: Epoch time: 266.53 s
2025-02-22 21:38:58.296206: Yayy! New best EMA pseudo Dice: 0.7613
2025-02-22 21:39:01.992455: 
2025-02-22 21:39:02.001444: Epoch 92
2025-02-22 21:39:02.008527: Current learning rate: 0.00103
2025-02-22 21:43:29.974566: train_loss -0.2606
2025-02-22 21:43:29.985232: val_loss -0.2224
2025-02-22 21:43:29.992251: Pseudo dice [0.8169, 0.7474, 0.8523, 0.6963]
2025-02-22 21:43:29.999008: Epoch time: 267.98 s
2025-02-22 21:43:30.003953: Yayy! New best EMA pseudo Dice: 0.763
2025-02-22 21:43:33.717272: 
2025-02-22 21:43:33.719222: Epoch 93
2025-02-22 21:43:33.722041: Current learning rate: 0.00091
2025-02-22 21:48:06.407993: train_loss -0.2652
2025-02-22 21:48:06.412816: val_loss -0.2207
2025-02-22 21:48:06.414613: Pseudo dice [0.8269, 0.7617, 0.8225, 0.6389]
2025-02-22 21:48:06.416719: Epoch time: 272.69 s
2025-02-22 21:48:09.651733: 
2025-02-22 21:48:09.655609: Epoch 94
2025-02-22 21:48:09.658711: Current learning rate: 0.00079
2025-02-22 21:52:48.970398: train_loss -0.2626
2025-02-22 21:52:48.982245: val_loss -0.2001
2025-02-22 21:52:48.986811: Pseudo dice [0.7816, 0.7368, 0.7582, 0.7345]
2025-02-22 21:52:48.992544: Epoch time: 279.32 s
2025-02-22 21:52:50.325035: 
2025-02-22 21:52:50.330581: Epoch 95
2025-02-22 21:52:50.336272: Current learning rate: 0.00067
2025-02-22 21:57:29.557141: train_loss -0.2692
2025-02-22 21:57:29.563308: val_loss -0.2121
2025-02-22 21:57:29.565925: Pseudo dice [0.8356, 0.7499, 0.8513, 0.6878]
2025-02-22 21:57:29.568594: Epoch time: 279.23 s
2025-02-22 21:57:29.571158: Yayy! New best EMA pseudo Dice: 0.7638
2025-02-22 21:57:33.326851: 
2025-02-22 21:57:33.331463: Epoch 96
2025-02-22 21:57:33.335454: Current learning rate: 0.00055
2025-02-22 22:02:05.591781: train_loss -0.2474
2025-02-22 22:02:05.599540: val_loss -0.2479
2025-02-22 22:02:05.602587: Pseudo dice [0.8357, 0.7473, 0.8187, 0.7139]
2025-02-22 22:02:05.604700: Epoch time: 272.27 s
2025-02-22 22:02:05.608139: Yayy! New best EMA pseudo Dice: 0.7654
2025-02-22 22:02:09.301106: 
2025-02-22 22:02:09.304124: Epoch 97
2025-02-22 22:02:09.307534: Current learning rate: 0.00043
2025-02-22 22:06:29.343230: train_loss -0.2589
2025-02-22 22:06:29.352563: val_loss -0.2668
2025-02-22 22:06:29.356825: Pseudo dice [0.7878, 0.7847, 0.7957, 0.6993]
2025-02-22 22:06:29.360481: Epoch time: 260.04 s
2025-02-22 22:06:29.363490: Yayy! New best EMA pseudo Dice: 0.7655
2025-02-22 22:06:33.064845: 
2025-02-22 22:06:33.067484: Epoch 98
2025-02-22 22:06:33.069892: Current learning rate: 0.0003
2025-02-22 22:11:08.355741: train_loss -0.2472
2025-02-22 22:11:08.365716: val_loss -0.2385
2025-02-22 22:11:08.369677: Pseudo dice [0.8284, 0.7538, 0.8613, 0.7241]
2025-02-22 22:11:08.374851: Epoch time: 275.29 s
2025-02-22 22:11:08.381054: Yayy! New best EMA pseudo Dice: 0.7681
2025-02-22 22:11:12.137777: 
2025-02-22 22:11:12.142416: Epoch 99
2025-02-22 22:11:12.149140: Current learning rate: 0.00016
2025-02-22 22:16:02.155298: train_loss -0.2836
2025-02-22 22:16:02.159803: val_loss -0.2625
2025-02-22 22:16:02.161536: Pseudo dice [0.8042, 0.8592, 0.8117, 0.7388]
2025-02-22 22:16:02.163136: Epoch time: 290.02 s
2025-02-22 22:16:02.165356: Yayy! New best EMA pseudo Dice: 0.7717
2025-02-22 22:16:08.306794: Training done.
2025-02-22 22:16:08.356162: Using splits from existing split file: /home3/hghr96/parm/work/AD_project/segmentation/nnUNet/data/nnUNet_preprocess/Dataset501_AD/splits_final.json
2025-02-22 22:16:08.360759: The split file contains 5 splits.
2025-02-22 22:16:08.362729: Desired fold for training: 4
2025-02-22 22:16:08.364745: This split has 71 training and 17 validation cases.
2025-02-22 22:16:08.367300: predicting ad_002
2025-02-22 22:16:08.379693: ad_002, shape torch.Size([1, 460, 595, 460]), rank 0
2025-02-22 22:18:37.612715: predicting ad_008
2025-02-22 22:18:37.645381: ad_008, shape torch.Size([1, 492, 771, 492]), rank 0
2025-02-22 22:21:58.763322: predicting ad_011
2025-02-22 22:21:58.803579: ad_011, shape torch.Size([1, 459, 674, 459]), rank 0
2025-02-22 22:24:53.894668: predicting ad_012
2025-02-22 22:24:53.923654: ad_012, shape torch.Size([1, 523, 623, 523]), rank 0
2025-02-22 22:28:03.213488: predicting ad_015
2025-02-22 22:28:03.265185: ad_015, shape torch.Size([1, 410, 826, 410]), rank 0
2025-02-22 22:31:03.421909: predicting ad_024
2025-02-22 22:31:03.466595: ad_024, shape torch.Size([1, 442, 671, 442]), rank 0
2025-02-22 22:34:11.058474: predicting ad_030
2025-02-22 22:34:11.111598: ad_030, shape torch.Size([1, 489, 794, 489]), rank 0
2025-02-22 22:40:04.656318: predicting ad_035
2025-02-22 22:40:04.696282: ad_035, shape torch.Size([1, 512, 811, 512]), rank 0
2025-02-22 22:44:47.804268: predicting ad_037
2025-02-22 22:44:47.876746: ad_037, shape torch.Size([1, 636, 877, 636]), rank 0
2025-02-22 22:51:52.608096: predicting ad_039
2025-02-22 22:51:52.692766: ad_039, shape torch.Size([1, 542, 969, 542]), rank 0
2025-02-22 22:57:12.362981: predicting ad_042
2025-02-22 22:57:12.425832: ad_042, shape torch.Size([1, 637, 813, 637]), rank 0
2025-02-22 23:11:29.101939: predicting ad_044
2025-02-22 23:11:29.170883: ad_044, shape torch.Size([1, 469, 871, 469]), rank 0
2025-02-22 23:17:36.640595: predicting ad_070
2025-02-22 23:17:36.720100: ad_070, shape torch.Size([1, 387, 769, 387]), rank 0
2025-02-22 23:23:26.335821: predicting ad_086
2025-02-22 23:23:26.378583: ad_086, shape torch.Size([1, 469, 634, 469]), rank 0
2025-02-22 23:30:32.868500: predicting ad_095
2025-02-22 23:30:32.936002: ad_095, shape torch.Size([1, 573, 997, 573]), rank 0
2025-02-22 23:38:02.942483: predicting ad_104
2025-02-22 23:38:03.090803: ad_104, shape torch.Size([1, 541, 923, 541]), rank 0
2025-02-22 23:42:47.532440: predicting ad_105
2025-02-22 23:42:47.624775: ad_105, shape torch.Size([1, 490, 814, 490]), rank 0
2025-02-22 23:58:39.241500: Validation complete
2025-02-22 23:58:39.243531: Mean Validation Dice:  0.5190619708384299
Finished at Sat 22 Feb 2025 11:58:44 PM GMT
Total Execution Time: 34557 seconds
