Starting at Wed 26 Feb 2025 09:40:14 PM GMT

############################
INFO: You are using the old nnU-Net default plans. We have updated our recommendations. Please consider using those instead! Read more here: https://github.com/MIC-DKFZ/nnUNet/blob/master/documentation/resenc_presets.md
############################

Using device: cuda:0

#######################################################################
Please cite the following paper when using nnU-Net:
Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.
#######################################################################

2025-02-26 21:40:30.694640: do_dummy_2d_data_aug: False
2025-02-26 21:40:30.706401: Using splits from existing split file: /home3/hghr96/parm/work/AD_project/segmentation/nnUNet/data/nnUNet_preprocessed/Dataset501_AD/splits_final.json
2025-02-26 21:40:30.722097: The split file contains 5 splits.
2025-02-26 21:40:30.724450: Desired fold for training: 3
2025-02-26 21:40:30.726398: This split has 71 training and 17 validation cases.
using pin_memory on device 0
/home3/hghr96/miniconda3/envs/nnUnet/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
using pin_memory on device 0
2025-02-26 21:40:38.737414: Using torch.compile...

This is the configuration used by this training:
Configuration name: 3d_lowres
 {'data_identifier': 'nnUNetPlans_3d_lowres', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 2, 'patch_size': [112, 192, 112], 'median_image_size_in_voxels': [177, 288, 177], 'spacing': [2.275601343470847, 2.028794967802552, 2.275601343470847], 'normalization_schemes': ['CTNormalization'], 'use_mask_for_norm': [False], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.PlainConvUNet', 'arch_kwargs': {'n_stages': 6, 'features_per_stage': [32, 64, 128, 256, 320, 320], 'conv_op': 'torch.nn.modules.conv.Conv3d', 'kernel_sizes': [[3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]], 'strides': [[1, 1, 1], [2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2], [1, 2, 1]], 'n_conv_per_stage': [2, 2, 2, 2, 2, 2], 'n_conv_per_stage_decoder': [2, 2, 2, 2, 2], 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm3d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}}, '_kw_requires_import': ['conv_op', 'norm_op', 'dropout_op', 'nonlin']}, 'batch_dice': False, 'next_stage': '3d_cascade_fullres'} 

These are the global plan.json settings:
 {'dataset_name': 'Dataset501_AD', 'plans_name': 'nnUNetPlans', 'original_median_spacing_after_transp': [0.78515625, 0.7000000476837158, 0.78515625], 'original_median_shape_after_transp': [512, 800, 512], 'image_reader_writer': 'SimpleITKIO', 'transpose_forward': [1, 0, 2], 'transpose_backward': [1, 0, 2], 'experiment_planner_used': 'ExperimentPlanner', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 3071.0, 'mean': 161.64767456054688, 'median': 182.0, 'min': -1103.0, 'percentile_00_5': -840.0, 'percentile_99_5': 778.0, 'std': 241.90689086914062}}} 

2025-02-26 21:40:43.062308: unpacking dataset...
2025-02-26 21:40:56.100931: unpacking done...
2025-02-26 21:40:56.144187: Unable to plot network architecture: nnUNet_compile is enabled!
2025-02-26 21:40:56.188020: 
2025-02-26 21:40:56.190821: Epoch 0
2025-02-26 21:40:56.193508: Current learning rate: 0.01
2025-02-26 21:44:48.949303: train_loss 0.172
2025-02-26 21:44:48.956084: val_loss 0.0387
2025-02-26 21:44:48.958273: Pseudo dice [0.0, 0.0, 0.0, 0.0]
2025-02-26 21:44:48.960521: Epoch time: 232.76 s
2025-02-26 21:44:48.962630: Yayy! New best EMA pseudo Dice: 0.0
2025-02-26 21:44:52.737425: 
2025-02-26 21:44:52.740014: Epoch 1
2025-02-26 21:44:52.742406: Current learning rate: 0.00991
2025-02-26 21:47:03.530971: train_loss 0.0195
2025-02-26 21:47:03.534633: val_loss -0.0436
2025-02-26 21:47:03.536442: Pseudo dice [0.0, 0.2589, 0.0, 0.0342]
2025-02-26 21:47:03.538316: Epoch time: 130.79 s
2025-02-26 21:47:03.539905: Yayy! New best EMA pseudo Dice: 0.0073
2025-02-26 21:47:08.040165: 
2025-02-26 21:47:08.042387: Epoch 2
2025-02-26 21:47:08.044318: Current learning rate: 0.00982
2025-02-26 21:49:14.629427: train_loss -0.0544
2025-02-26 21:49:14.633539: val_loss -0.1136
2025-02-26 21:49:14.635493: Pseudo dice [0.0, 0.2454, 0.0, 0.2435]
2025-02-26 21:49:14.644187: Epoch time: 126.59 s
2025-02-26 21:49:14.648765: Yayy! New best EMA pseudo Dice: 0.0188
2025-02-26 21:49:19.200139: 
2025-02-26 21:49:19.202087: Epoch 3
2025-02-26 21:49:19.203851: Current learning rate: 0.00973
2025-02-26 21:51:26.923580: train_loss -0.1015
2025-02-26 21:51:26.928181: val_loss -0.1421
2025-02-26 21:51:26.930362: Pseudo dice [0.0, 0.2059, 0.0, 0.4696]
2025-02-26 21:51:26.932557: Epoch time: 127.73 s
2025-02-26 21:51:26.934460: Yayy! New best EMA pseudo Dice: 0.0338
2025-02-26 21:51:31.545754: 
2025-02-26 21:51:31.548637: Epoch 4
2025-02-26 21:51:31.550358: Current learning rate: 0.00964
2025-02-26 21:53:44.050382: train_loss -0.1263
2025-02-26 21:53:44.065250: val_loss -0.1623
2025-02-26 21:53:44.067521: Pseudo dice [0.3233, 0.4127, 0.008, 0.3025]
2025-02-26 21:53:44.069761: Epoch time: 132.51 s
2025-02-26 21:53:44.071830: Yayy! New best EMA pseudo Dice: 0.0566
2025-02-26 21:53:48.594963: 
2025-02-26 21:53:48.597392: Epoch 5
2025-02-26 21:53:48.599448: Current learning rate: 0.00955
2025-02-26 21:55:40.124363: train_loss -0.1801
2025-02-26 21:55:40.128740: val_loss -0.2142
2025-02-26 21:55:40.131396: Pseudo dice [0.0, 0.443, 0.5794, 0.0671]
2025-02-26 21:55:40.135049: Epoch time: 111.53 s
2025-02-26 21:55:40.145254: Yayy! New best EMA pseudo Dice: 0.0782
2025-02-26 21:55:44.607896: 
2025-02-26 21:55:44.610446: Epoch 6
2025-02-26 21:55:44.613116: Current learning rate: 0.00946
2025-02-26 21:57:47.262490: train_loss -0.2041
2025-02-26 21:57:47.280697: val_loss -0.2167
2025-02-26 21:57:47.282907: Pseudo dice [0.4205, 0.3698, 0.3542, 0.5041]
2025-02-26 21:57:47.285086: Epoch time: 122.66 s
2025-02-26 21:57:47.286867: Yayy! New best EMA pseudo Dice: 0.1116
2025-02-26 21:57:51.795006: 
2025-02-26 21:57:51.797437: Epoch 7
2025-02-26 21:57:51.799660: Current learning rate: 0.00937
2025-02-26 22:00:06.026007: train_loss -0.2286
2025-02-26 22:00:06.042006: val_loss -0.2558
2025-02-26 22:00:06.044201: Pseudo dice [0.1862, 0.3964, 0.6556, 0.5759]
2025-02-26 22:00:06.046257: Epoch time: 134.23 s
2025-02-26 22:00:06.048170: Yayy! New best EMA pseudo Dice: 0.1458
2025-02-26 22:00:10.635516: 
2025-02-26 22:00:10.637921: Epoch 8
2025-02-26 22:00:10.640301: Current learning rate: 0.00928
2025-02-26 22:02:23.234767: train_loss -0.2498
2025-02-26 22:02:23.258189: val_loss -0.238
2025-02-26 22:02:23.261140: Pseudo dice [0.4119, 0.4691, 0.5572, 0.4672]
2025-02-26 22:02:23.263420: Epoch time: 132.6 s
2025-02-26 22:02:23.265657: Yayy! New best EMA pseudo Dice: 0.1788
2025-02-26 22:02:27.670561: 
2025-02-26 22:02:27.674605: Epoch 9
2025-02-26 22:02:27.676654: Current learning rate: 0.00919
2025-02-26 22:04:36.161972: train_loss -0.2637
2025-02-26 22:04:36.165871: val_loss -0.2305
2025-02-26 22:04:36.167444: Pseudo dice [0.403, 0.3963, 0.5503, 0.5245]
2025-02-26 22:04:36.169584: Epoch time: 128.49 s
2025-02-26 22:04:36.171133: Yayy! New best EMA pseudo Dice: 0.2078
2025-02-26 22:04:39.917419: 
2025-02-26 22:04:39.920321: Epoch 10
2025-02-26 22:04:39.922692: Current learning rate: 0.0091
2025-02-26 22:06:48.424571: train_loss -0.256
2025-02-26 22:06:48.439956: val_loss -0.2447
2025-02-26 22:06:48.442360: Pseudo dice [0.4063, 0.4313, 0.6303, 0.4794]
2025-02-26 22:06:48.444723: Epoch time: 128.51 s
2025-02-26 22:06:48.446788: Yayy! New best EMA pseudo Dice: 0.2357
2025-02-26 22:06:52.777213: 
2025-02-26 22:06:52.779760: Epoch 11
2025-02-26 22:06:52.782054: Current learning rate: 0.009
2025-02-26 22:09:11.149826: train_loss -0.2832
2025-02-26 22:09:11.154988: val_loss -0.26
2025-02-26 22:09:11.165045: Pseudo dice [0.4007, 0.3452, 0.5953, 0.6351]
2025-02-26 22:09:11.167747: Epoch time: 138.37 s
2025-02-26 22:09:11.170240: Yayy! New best EMA pseudo Dice: 0.2615
2025-02-26 22:09:15.594007: 
2025-02-26 22:09:15.597518: Epoch 12
2025-02-26 22:09:15.600220: Current learning rate: 0.00891
2025-02-26 22:11:17.067356: train_loss -0.2845
2025-02-26 22:11:17.072321: val_loss -0.2275
2025-02-26 22:11:17.075356: Pseudo dice [0.4112, 0.4698, 0.4524, 0.5327]
2025-02-26 22:11:17.078027: Epoch time: 121.47 s
2025-02-26 22:11:17.080805: Yayy! New best EMA pseudo Dice: 0.282
2025-02-26 22:11:20.952147: 
2025-02-26 22:11:20.954420: Epoch 13
2025-02-26 22:11:20.956644: Current learning rate: 0.00882
2025-02-26 22:13:33.329281: train_loss -0.2928
2025-02-26 22:13:33.347027: val_loss -0.2263
2025-02-26 22:13:33.349248: Pseudo dice [0.4577, 0.4645, 0.4924, 0.5195]
2025-02-26 22:13:33.351469: Epoch time: 132.38 s
2025-02-26 22:13:33.353445: Yayy! New best EMA pseudo Dice: 0.3022
2025-02-26 22:13:37.813977: 
2025-02-26 22:13:37.816967: Epoch 14
2025-02-26 22:13:37.819274: Current learning rate: 0.00873
2025-02-26 22:15:33.997893: train_loss -0.3102
2025-02-26 22:15:34.002503: val_loss -0.2653
2025-02-26 22:15:34.005288: Pseudo dice [0.6027, 0.4744, 0.6123, 0.5224]
2025-02-26 22:15:34.017075: Epoch time: 116.19 s
2025-02-26 22:15:34.019331: Yayy! New best EMA pseudo Dice: 0.3273
2025-02-26 22:15:38.424880: 
2025-02-26 22:15:38.427646: Epoch 15
2025-02-26 22:15:38.429828: Current learning rate: 0.00864
2025-02-26 22:17:32.982980: train_loss -0.326
2025-02-26 22:17:32.987992: val_loss -0.2727
2025-02-26 22:17:32.990309: Pseudo dice [0.5303, 0.4717, 0.6477, 0.5932]
2025-02-26 22:17:32.992764: Epoch time: 114.56 s
2025-02-26 22:17:32.995148: Yayy! New best EMA pseudo Dice: 0.3506
2025-02-26 22:17:37.600274: 
2025-02-26 22:17:37.602373: Epoch 16
2025-02-26 22:17:37.604679: Current learning rate: 0.00855
2025-02-26 22:19:40.907617: train_loss -0.322
2025-02-26 22:19:40.916468: val_loss -0.2818
2025-02-26 22:19:40.930313: Pseudo dice [0.4182, 0.5476, 0.6681, 0.5607]
2025-02-26 22:19:40.933483: Epoch time: 123.31 s
2025-02-26 22:19:40.936292: Yayy! New best EMA pseudo Dice: 0.3704
2025-02-26 22:19:45.734705: 
2025-02-26 22:19:45.737448: Epoch 17
2025-02-26 22:19:45.739685: Current learning rate: 0.00846
2025-02-26 22:21:42.971312: train_loss -0.3311
2025-02-26 22:21:42.987365: val_loss -0.2918
2025-02-26 22:21:42.990051: Pseudo dice [0.5404, 0.5237, 0.6361, 0.6241]
2025-02-26 22:21:42.992821: Epoch time: 117.24 s
2025-02-26 22:21:42.995174: Yayy! New best EMA pseudo Dice: 0.3915
2025-02-26 22:21:47.610753: 
2025-02-26 22:21:47.613462: Epoch 18
2025-02-26 22:21:47.615683: Current learning rate: 0.00836
2025-02-26 22:23:46.312913: train_loss -0.3368
2025-02-26 22:23:46.317070: val_loss -0.2631
2025-02-26 22:23:46.319671: Pseudo dice [0.543, 0.4887, 0.6315, 0.5569]
2025-02-26 22:23:46.322826: Epoch time: 118.7 s
2025-02-26 22:23:46.335960: Yayy! New best EMA pseudo Dice: 0.4078
2025-02-26 22:23:51.025986: 
2025-02-26 22:23:51.028789: Epoch 19
2025-02-26 22:23:51.030814: Current learning rate: 0.00827
2025-02-26 22:25:57.415062: train_loss -0.3402
2025-02-26 22:25:57.419109: val_loss -0.3062
2025-02-26 22:25:57.421308: Pseudo dice [0.5592, 0.5482, 0.6929, 0.6086]
2025-02-26 22:25:57.423241: Epoch time: 126.39 s
2025-02-26 22:25:57.424921: Yayy! New best EMA pseudo Dice: 0.4273
2025-02-26 22:26:01.904485: 
2025-02-26 22:26:01.907413: Epoch 20
2025-02-26 22:26:01.909541: Current learning rate: 0.00818
2025-02-26 22:27:55.345113: train_loss -0.366
2025-02-26 22:27:55.349914: val_loss -0.3007
2025-02-26 22:27:55.352373: Pseudo dice [0.4552, 0.6205, 0.6365, 0.7072]
2025-02-26 22:27:55.354808: Epoch time: 113.44 s
2025-02-26 22:27:55.357485: Yayy! New best EMA pseudo Dice: 0.445
2025-02-26 22:27:59.277706: 
2025-02-26 22:27:59.280201: Epoch 21
2025-02-26 22:27:59.282030: Current learning rate: 0.00809
2025-02-26 22:29:55.693398: train_loss -0.3643
2025-02-26 22:29:55.698713: val_loss -0.3091
2025-02-26 22:29:55.716816: Pseudo dice [0.4374, 0.4866, 0.6559, 0.6765]
2025-02-26 22:29:55.719191: Epoch time: 116.42 s
2025-02-26 22:29:55.721509: Yayy! New best EMA pseudo Dice: 0.4569
2025-02-26 22:29:59.990490: 
2025-02-26 22:29:59.992666: Epoch 22
2025-02-26 22:29:59.994447: Current learning rate: 0.008
2025-02-26 22:32:05.249210: train_loss -0.3667
2025-02-26 22:32:05.265927: val_loss -0.2834
2025-02-26 22:32:05.268588: Pseudo dice [0.519, 0.5437, 0.5908, 0.5974]
2025-02-26 22:32:05.271050: Epoch time: 125.26 s
2025-02-26 22:32:05.273573: Yayy! New best EMA pseudo Dice: 0.4675
2025-02-26 22:32:09.823696: 
2025-02-26 22:32:09.826263: Epoch 23
2025-02-26 22:32:09.828691: Current learning rate: 0.0079
2025-02-26 22:34:17.644664: train_loss -0.3741
2025-02-26 22:34:17.649167: val_loss -0.3238
2025-02-26 22:34:17.651518: Pseudo dice [0.5625, 0.5835, 0.6873, 0.6713]
2025-02-26 22:34:17.653917: Epoch time: 127.82 s
2025-02-26 22:34:17.656293: Yayy! New best EMA pseudo Dice: 0.4834
2025-02-26 22:34:22.100408: 
2025-02-26 22:34:22.102547: Epoch 24
2025-02-26 22:34:22.104796: Current learning rate: 0.00781
2025-02-26 22:36:27.387260: train_loss -0.3912
2025-02-26 22:36:27.392225: val_loss -0.3096
2025-02-26 22:36:27.394724: Pseudo dice [0.5593, 0.5247, 0.6329, 0.723]
2025-02-26 22:36:27.396903: Epoch time: 125.29 s
2025-02-26 22:36:27.398603: Yayy! New best EMA pseudo Dice: 0.496
2025-02-26 22:36:31.866454: 
2025-02-26 22:36:31.869275: Epoch 25
2025-02-26 22:36:31.871632: Current learning rate: 0.00772
2025-02-26 22:38:30.965260: train_loss -0.384
2025-02-26 22:38:30.970382: val_loss -0.3014
2025-02-26 22:38:30.984806: Pseudo dice [0.5866, 0.5325, 0.7143, 0.6127]
2025-02-26 22:38:30.987236: Epoch time: 119.1 s
2025-02-26 22:38:30.989541: Yayy! New best EMA pseudo Dice: 0.5076
2025-02-26 22:38:35.428638: 
2025-02-26 22:38:35.430970: Epoch 26
2025-02-26 22:38:35.433497: Current learning rate: 0.00763
2025-02-26 22:40:33.516812: train_loss -0.3771
2025-02-26 22:40:33.521242: val_loss -0.3316
2025-02-26 22:40:33.523165: Pseudo dice [0.6712, 0.6669, 0.8108, 0.6379]
2025-02-26 22:40:33.525251: Epoch time: 118.09 s
2025-02-26 22:40:33.526821: Yayy! New best EMA pseudo Dice: 0.5265
2025-02-26 22:40:37.877110: 
2025-02-26 22:40:37.879860: Epoch 27
2025-02-26 22:40:37.882059: Current learning rate: 0.00753
2025-02-26 22:42:48.264215: train_loss -0.3948
2025-02-26 22:42:48.280281: val_loss -0.3409
2025-02-26 22:42:48.282977: Pseudo dice [0.5918, 0.6494, 0.7166, 0.7178]
2025-02-26 22:42:48.285833: Epoch time: 130.39 s
2025-02-26 22:42:48.296807: Yayy! New best EMA pseudo Dice: 0.5407
2025-02-26 22:42:52.858959: 
2025-02-26 22:42:52.861897: Epoch 28
2025-02-26 22:42:52.864213: Current learning rate: 0.00744
2025-02-26 22:44:54.804206: train_loss -0.4026
2025-02-26 22:44:54.822367: val_loss -0.3425
2025-02-26 22:44:54.825075: Pseudo dice [0.5749, 0.6746, 0.6564, 0.7371]
2025-02-26 22:44:54.827655: Epoch time: 121.95 s
2025-02-26 22:44:54.830038: Yayy! New best EMA pseudo Dice: 0.5527
2025-02-26 22:44:59.616028: 
2025-02-26 22:44:59.618574: Epoch 29
2025-02-26 22:44:59.621016: Current learning rate: 0.00735
2025-02-26 22:46:53.537361: train_loss -0.3945
2025-02-26 22:46:53.541968: val_loss -0.3282
2025-02-26 22:46:53.544452: Pseudo dice [0.5935, 0.6239, 0.6861, 0.7233]
2025-02-26 22:46:53.559543: Epoch time: 113.92 s
2025-02-26 22:46:53.562349: Yayy! New best EMA pseudo Dice: 0.5631
2025-02-26 22:46:58.104867: 
2025-02-26 22:46:58.107844: Epoch 30
2025-02-26 22:46:58.110193: Current learning rate: 0.00725
2025-02-26 22:48:59.145994: train_loss -0.4149
2025-02-26 22:48:59.150620: val_loss -0.336
2025-02-26 22:48:59.152859: Pseudo dice [0.5907, 0.6913, 0.7242, 0.7135]
2025-02-26 22:48:59.155162: Epoch time: 121.04 s
2025-02-26 22:48:59.157650: Yayy! New best EMA pseudo Dice: 0.5748
2025-02-26 22:49:03.711855: 
2025-02-26 22:49:03.713832: Epoch 31
2025-02-26 22:49:03.715303: Current learning rate: 0.00716
2025-02-26 22:51:04.940555: train_loss -0.4044
2025-02-26 22:51:04.944574: val_loss -0.3813
2025-02-26 22:51:04.946632: Pseudo dice [0.7364, 0.7014, 0.7893, 0.7292]
2025-02-26 22:51:04.948673: Epoch time: 121.23 s
2025-02-26 22:51:04.950665: Yayy! New best EMA pseudo Dice: 0.5912
2025-02-26 22:51:09.628291: 
2025-02-26 22:51:09.630843: Epoch 32
2025-02-26 22:51:09.633393: Current learning rate: 0.00707
2025-02-26 22:53:17.045375: train_loss -0.4069
2025-02-26 22:53:17.048850: val_loss -0.3418
2025-02-26 22:53:17.050449: Pseudo dice [0.7256, 0.621, 0.7735, 0.702]
2025-02-26 22:53:17.051961: Epoch time: 127.42 s
2025-02-26 22:53:17.053589: Yayy! New best EMA pseudo Dice: 0.6027
2025-02-26 22:53:21.619280: 
2025-02-26 22:53:21.622401: Epoch 33
2025-02-26 22:53:21.625029: Current learning rate: 0.00697
2025-02-26 22:55:34.585726: train_loss -0.4245
2025-02-26 22:55:34.591795: val_loss -0.3238
2025-02-26 22:55:34.602943: Pseudo dice [0.4417, 0.6517, 0.6457, 0.7587]
2025-02-26 22:55:34.605488: Epoch time: 132.97 s
2025-02-26 22:55:34.607993: Yayy! New best EMA pseudo Dice: 0.6048
2025-02-26 22:55:39.293600: 
2025-02-26 22:55:39.296525: Epoch 34
2025-02-26 22:55:39.298806: Current learning rate: 0.00688
2025-02-26 22:57:52.015166: train_loss -0.4314
2025-02-26 22:57:52.035609: val_loss -0.3386
2025-02-26 22:57:52.038184: Pseudo dice [0.584, 0.6932, 0.6743, 0.7486]
2025-02-26 22:57:52.040804: Epoch time: 132.72 s
2025-02-26 22:57:52.043116: Yayy! New best EMA pseudo Dice: 0.6119
2025-02-26 22:57:55.996217: 
2025-02-26 22:57:55.998951: Epoch 35
2025-02-26 22:57:56.001664: Current learning rate: 0.00679
2025-02-26 22:59:51.745559: train_loss -0.426
2025-02-26 22:59:51.763044: val_loss -0.3266
2025-02-26 22:59:51.765585: Pseudo dice [0.406, 0.6893, 0.7017, 0.7319]
2025-02-26 22:59:51.767981: Epoch time: 115.75 s
2025-02-26 22:59:51.769936: Yayy! New best EMA pseudo Dice: 0.6139
2025-02-26 22:59:55.967006: 
2025-02-26 22:59:55.969786: Epoch 36
2025-02-26 22:59:55.972170: Current learning rate: 0.00669
2025-02-26 23:02:02.266737: train_loss -0.4093
2025-02-26 23:02:02.273400: val_loss -0.3268
2025-02-26 23:02:02.275870: Pseudo dice [0.7023, 0.6592, 0.7373, 0.7227]
2025-02-26 23:02:02.278479: Epoch time: 126.3 s
2025-02-26 23:02:02.280748: Yayy! New best EMA pseudo Dice: 0.623
2025-02-26 23:02:06.902131: 
2025-02-26 23:02:06.905043: Epoch 37
2025-02-26 23:02:06.907364: Current learning rate: 0.0066
2025-02-26 23:03:53.424900: train_loss -0.4203
2025-02-26 23:03:53.431241: val_loss -0.3534
2025-02-26 23:03:53.440583: Pseudo dice [0.6311, 0.7284, 0.6819, 0.7917]
2025-02-26 23:03:53.452539: Epoch time: 106.52 s
2025-02-26 23:03:53.455141: Yayy! New best EMA pseudo Dice: 0.6316
2025-02-26 23:03:57.771205: 
2025-02-26 23:03:57.774091: Epoch 38
2025-02-26 23:03:57.775610: Current learning rate: 0.0065
2025-02-26 23:05:58.159234: train_loss -0.4342
2025-02-26 23:05:58.164070: val_loss -0.3345
2025-02-26 23:05:58.166509: Pseudo dice [0.6529, 0.6311, 0.6681, 0.7899]
2025-02-26 23:05:58.168747: Epoch time: 120.39 s
2025-02-26 23:05:58.170576: Yayy! New best EMA pseudo Dice: 0.637
2025-02-26 23:06:02.415728: 
2025-02-26 23:06:02.418064: Epoch 39
2025-02-26 23:06:02.420065: Current learning rate: 0.00641
2025-02-26 23:08:17.526290: train_loss -0.4083
2025-02-26 23:08:17.542575: val_loss -0.3197
2025-02-26 23:08:17.545211: Pseudo dice [0.5724, 0.6399, 0.6478, 0.7453]
2025-02-26 23:08:17.547335: Epoch time: 135.11 s
2025-02-26 23:08:17.549621: Yayy! New best EMA pseudo Dice: 0.6384
2025-02-26 23:08:22.038849: 
2025-02-26 23:08:22.041729: Epoch 40
2025-02-26 23:08:22.043859: Current learning rate: 0.00631
2025-02-26 23:10:23.009693: train_loss -0.4225
2025-02-26 23:10:23.014753: val_loss -0.363
2025-02-26 23:10:23.028335: Pseudo dice [0.6707, 0.7059, 0.6411, 0.7659]
2025-02-26 23:10:23.031128: Epoch time: 120.97 s
2025-02-26 23:10:23.033712: Yayy! New best EMA pseudo Dice: 0.6442
2025-02-26 23:10:27.488674: 
2025-02-26 23:10:27.491157: Epoch 41
2025-02-26 23:10:27.493547: Current learning rate: 0.00622
2025-02-26 23:12:29.558007: train_loss -0.4172
2025-02-26 23:12:29.578356: val_loss -0.3376
2025-02-26 23:12:29.580828: Pseudo dice [0.6255, 0.651, 0.7067, 0.7301]
2025-02-26 23:12:29.583121: Epoch time: 122.07 s
2025-02-26 23:12:29.585894: Yayy! New best EMA pseudo Dice: 0.6476
2025-02-26 23:12:34.294034: 
2025-02-26 23:12:34.297188: Epoch 42
2025-02-26 23:12:34.299227: Current learning rate: 0.00612
2025-02-26 23:14:33.719933: train_loss -0.4355
2025-02-26 23:14:33.724818: val_loss -0.3484
2025-02-26 23:14:33.727708: Pseudo dice [0.6652, 0.7006, 0.7597, 0.7189]
2025-02-26 23:14:33.730108: Epoch time: 119.43 s
2025-02-26 23:14:33.732674: Yayy! New best EMA pseudo Dice: 0.6539
2025-02-26 23:14:38.198609: 
2025-02-26 23:14:38.200573: Epoch 43
2025-02-26 23:14:38.201971: Current learning rate: 0.00603
2025-02-26 23:16:47.466427: train_loss -0.4291
2025-02-26 23:16:47.470898: val_loss -0.3307
2025-02-26 23:16:47.473092: Pseudo dice [0.5908, 0.7068, 0.6189, 0.7656]
2025-02-26 23:16:47.475082: Epoch time: 129.27 s
2025-02-26 23:16:47.477341: Yayy! New best EMA pseudo Dice: 0.6556
2025-02-26 23:16:51.575377: 
2025-02-26 23:16:51.577660: Epoch 44
2025-02-26 23:16:51.579803: Current learning rate: 0.00593
2025-02-26 23:18:54.546667: train_loss -0.4478
2025-02-26 23:18:54.565020: val_loss -0.3449
2025-02-26 23:18:54.567449: Pseudo dice [0.6527, 0.6849, 0.7147, 0.7258]
2025-02-26 23:18:54.570128: Epoch time: 122.97 s
2025-02-26 23:18:54.572290: Yayy! New best EMA pseudo Dice: 0.6595
2025-02-26 23:18:59.762724: 
2025-02-26 23:18:59.765362: Epoch 45
2025-02-26 23:18:59.767000: Current learning rate: 0.00584
2025-02-26 23:21:04.842361: train_loss -0.4363
2025-02-26 23:21:04.859094: val_loss -0.3564
2025-02-26 23:21:04.862093: Pseudo dice [0.6872, 0.7041, 0.746, 0.756]
2025-02-26 23:21:04.864702: Epoch time: 125.08 s
2025-02-26 23:21:04.867119: Yayy! New best EMA pseudo Dice: 0.6659
2025-02-26 23:21:09.210714: 
2025-02-26 23:21:09.212560: Epoch 46
2025-02-26 23:21:09.213985: Current learning rate: 0.00574
2025-02-26 23:23:21.668176: train_loss -0.4339
2025-02-26 23:23:21.674870: val_loss -0.3694
2025-02-26 23:23:21.682311: Pseudo dice [0.7223, 0.7505, 0.7896, 0.6917]
2025-02-26 23:23:21.684916: Epoch time: 132.46 s
2025-02-26 23:23:21.687319: Yayy! New best EMA pseudo Dice: 0.6731
2025-02-26 23:23:25.527534: 
2025-02-26 23:23:25.530047: Epoch 47
2025-02-26 23:23:25.532330: Current learning rate: 0.00565
2025-02-26 23:25:34.362180: train_loss -0.4376
2025-02-26 23:25:34.374845: val_loss -0.3446
2025-02-26 23:25:34.377243: Pseudo dice [0.6384, 0.7105, 0.6534, 0.7869]
2025-02-26 23:25:34.379253: Epoch time: 128.84 s
2025-02-26 23:25:34.381512: Yayy! New best EMA pseudo Dice: 0.6755
2025-02-26 23:25:38.546663: 
2025-02-26 23:25:38.549608: Epoch 48
2025-02-26 23:25:38.551542: Current learning rate: 0.00555
2025-02-26 23:27:37.575288: train_loss -0.4453
2025-02-26 23:27:37.580272: val_loss -0.3651
2025-02-26 23:27:37.582887: Pseudo dice [0.6919, 0.7104, 0.7453, 0.7709]
2025-02-26 23:27:37.585361: Epoch time: 119.03 s
2025-02-26 23:27:37.587702: Yayy! New best EMA pseudo Dice: 0.681
2025-02-26 23:27:41.781614: 
2025-02-26 23:27:41.784305: Epoch 49
2025-02-26 23:27:41.786544: Current learning rate: 0.00546
2025-02-26 23:29:41.947052: train_loss -0.45
2025-02-26 23:29:41.952151: val_loss -0.3093
2025-02-26 23:29:41.954667: Pseudo dice [0.5998, 0.7294, 0.5641, 0.6804]
2025-02-26 23:29:41.957389: Epoch time: 120.17 s
2025-02-26 23:29:46.404516: 
2025-02-26 23:29:46.406781: Epoch 50
2025-02-26 23:29:46.409316: Current learning rate: 0.00536
2025-02-26 23:31:44.269074: train_loss -0.445
2025-02-26 23:31:44.273253: val_loss -0.3397
2025-02-26 23:31:44.275791: Pseudo dice [0.5991, 0.6836, 0.6524, 0.7642]
2025-02-26 23:31:44.278361: Epoch time: 117.87 s
2025-02-26 23:31:45.915395: 
2025-02-26 23:31:45.917764: Epoch 51
2025-02-26 23:31:45.919788: Current learning rate: 0.00526
2025-02-26 23:33:49.378563: train_loss -0.4526
2025-02-26 23:33:49.393329: val_loss -0.3929
2025-02-26 23:33:49.396099: Pseudo dice [0.7198, 0.7387, 0.742, 0.7666]
2025-02-26 23:33:49.398567: Epoch time: 123.46 s
2025-02-26 23:33:49.401190: Yayy! New best EMA pseudo Dice: 0.6834
2025-02-26 23:33:53.368850: 
2025-02-26 23:33:53.371878: Epoch 52
2025-02-26 23:33:53.374311: Current learning rate: 0.00517
2025-02-26 23:36:00.475479: train_loss -0.4652
2025-02-26 23:36:00.492535: val_loss -0.3749
2025-02-26 23:36:00.494275: Pseudo dice [0.6712, 0.7041, 0.7093, 0.7575]
2025-02-26 23:36:00.495828: Epoch time: 127.11 s
2025-02-26 23:36:00.497168: Yayy! New best EMA pseudo Dice: 0.6862
2025-02-26 23:36:05.160851: 
2025-02-26 23:36:05.163320: Epoch 53
2025-02-26 23:36:05.165673: Current learning rate: 0.00507
2025-02-26 23:38:09.186927: train_loss -0.467
2025-02-26 23:38:09.194079: val_loss -0.3598
2025-02-26 23:38:09.197346: Pseudo dice [0.6248, 0.7375, 0.6936, 0.791]
2025-02-26 23:38:09.201799: Epoch time: 124.03 s
2025-02-26 23:38:09.204419: Yayy! New best EMA pseudo Dice: 0.6887
2025-02-26 23:38:13.071219: 
2025-02-26 23:38:13.073760: Epoch 54
2025-02-26 23:38:13.076038: Current learning rate: 0.00497
2025-02-26 23:40:13.309547: train_loss -0.4651
2025-02-26 23:40:13.331066: val_loss -0.352
2025-02-26 23:40:13.334255: Pseudo dice [0.5202, 0.6999, 0.751, 0.7638]
2025-02-26 23:40:13.337023: Epoch time: 120.24 s
2025-02-26 23:40:15.457499: 
2025-02-26 23:40:15.460373: Epoch 55
2025-02-26 23:40:15.462842: Current learning rate: 0.00487
2025-02-26 23:42:21.663626: train_loss -0.4472
2025-02-26 23:42:21.680243: val_loss -0.3648
2025-02-26 23:42:21.685146: Pseudo dice [0.6796, 0.6635, 0.7437, 0.7788]
2025-02-26 23:42:21.687752: Epoch time: 126.21 s
2025-02-26 23:42:21.690229: Yayy! New best EMA pseudo Dice: 0.691
2025-02-26 23:42:26.190995: 
2025-02-26 23:42:26.193020: Epoch 56
2025-02-26 23:42:26.194710: Current learning rate: 0.00478
2025-02-26 23:44:46.667295: train_loss -0.4386
2025-02-26 23:44:46.670549: val_loss -0.3623
2025-02-26 23:44:46.672212: Pseudo dice [0.6025, 0.6895, 0.793, 0.7663]
2025-02-26 23:44:46.683997: Epoch time: 140.48 s
2025-02-26 23:44:46.686087: Yayy! New best EMA pseudo Dice: 0.6932
2025-02-26 23:44:51.104196: 
2025-02-26 23:44:51.106963: Epoch 57
2025-02-26 23:44:51.109416: Current learning rate: 0.00468
2025-02-26 23:46:59.497222: train_loss -0.4555
2025-02-26 23:46:59.501197: val_loss -0.3744
2025-02-26 23:46:59.503153: Pseudo dice [0.5923, 0.7447, 0.7332, 0.7728]
2025-02-26 23:46:59.505135: Epoch time: 128.39 s
2025-02-26 23:46:59.507084: Yayy! New best EMA pseudo Dice: 0.695
2025-02-26 23:47:04.098965: 
2025-02-26 23:47:04.101685: Epoch 58
2025-02-26 23:47:04.103314: Current learning rate: 0.00458
2025-02-26 23:49:10.291074: train_loss -0.4677
2025-02-26 23:49:10.296180: val_loss -0.3274
2025-02-26 23:49:10.298886: Pseudo dice [0.6105, 0.7294, 0.7054, 0.7578]
2025-02-26 23:49:10.301737: Epoch time: 126.19 s
2025-02-26 23:49:10.304126: Yayy! New best EMA pseudo Dice: 0.6955
2025-02-26 23:49:14.946437: 
2025-02-26 23:49:14.949140: Epoch 59
2025-02-26 23:49:14.951348: Current learning rate: 0.00448
2025-02-26 23:51:17.892196: train_loss -0.4728
2025-02-26 23:51:17.909054: val_loss -0.3497
2025-02-26 23:51:17.911711: Pseudo dice [0.6686, 0.7014, 0.7092, 0.769]
2025-02-26 23:51:17.914498: Epoch time: 122.95 s
2025-02-26 23:51:17.917113: Yayy! New best EMA pseudo Dice: 0.6972
2025-02-26 23:51:21.906126: 
2025-02-26 23:51:21.908676: Epoch 60
2025-02-26 23:51:21.910902: Current learning rate: 0.00438
2025-02-26 23:53:27.685323: train_loss -0.4657
2025-02-26 23:53:27.689651: val_loss -0.376
2025-02-26 23:53:27.691983: Pseudo dice [0.7216, 0.7894, 0.7694, 0.7685]
2025-02-26 23:53:27.694473: Epoch time: 125.78 s
2025-02-26 23:53:27.696620: Yayy! New best EMA pseudo Dice: 0.7037
2025-02-26 23:53:32.195707: 
2025-02-26 23:53:32.197797: Epoch 61
2025-02-26 23:53:32.199202: Current learning rate: 0.00429
2025-02-26 23:55:34.696712: train_loss -0.4844
2025-02-26 23:55:34.716819: val_loss -0.3711
2025-02-26 23:55:34.719900: Pseudo dice [0.6522, 0.793, 0.7229, 0.7805]
2025-02-26 23:55:34.722676: Epoch time: 122.5 s
2025-02-26 23:55:34.725121: Yayy! New best EMA pseudo Dice: 0.707
2025-02-26 23:55:39.287872: 
2025-02-26 23:55:39.290539: Epoch 62
2025-02-26 23:55:39.292762: Current learning rate: 0.00419
2025-02-26 23:57:46.638550: train_loss -0.4689
2025-02-26 23:57:46.643372: val_loss -0.3608
2025-02-26 23:57:46.646430: Pseudo dice [0.6024, 0.7519, 0.6738, 0.794]
2025-02-26 23:57:46.649032: Epoch time: 127.35 s
2025-02-26 23:57:49.003233: 
2025-02-26 23:57:49.005906: Epoch 63
2025-02-26 23:57:49.007745: Current learning rate: 0.00409
2025-02-27 00:00:05.818877: train_loss -0.4619
2025-02-27 00:00:05.823521: val_loss -0.3992
2025-02-27 00:00:05.826284: Pseudo dice [0.6859, 0.7853, 0.7371, 0.7921]
2025-02-27 00:00:05.828676: Epoch time: 136.82 s
2025-02-27 00:00:05.830786: Yayy! New best EMA pseudo Dice: 0.7112
2025-02-27 00:00:10.472462: 
2025-02-27 00:00:10.475056: Epoch 64
2025-02-27 00:00:10.477479: Current learning rate: 0.00399
2025-02-27 00:02:25.333486: train_loss -0.4735
2025-02-27 00:02:25.338669: val_loss -0.3476
2025-02-27 00:02:25.351050: Pseudo dice [0.6506, 0.7656, 0.7376, 0.7735]
2025-02-27 00:02:25.354209: Epoch time: 134.86 s
2025-02-27 00:02:25.356713: Yayy! New best EMA pseudo Dice: 0.7133
2025-02-27 00:02:29.396324: 
2025-02-27 00:02:29.398709: Epoch 65
2025-02-27 00:02:29.400640: Current learning rate: 0.00389
2025-02-27 00:04:37.308352: train_loss -0.4841
2025-02-27 00:04:37.312861: val_loss -0.3736
2025-02-27 00:04:37.314959: Pseudo dice [0.5798, 0.7907, 0.7039, 0.8154]
2025-02-27 00:04:37.317302: Epoch time: 127.91 s
2025-02-27 00:04:37.319553: Yayy! New best EMA pseudo Dice: 0.7142
2025-02-27 00:04:41.235474: 
2025-02-27 00:04:41.238468: Epoch 66
2025-02-27 00:04:41.240893: Current learning rate: 0.00379
2025-02-27 00:06:43.992253: train_loss -0.4875
2025-02-27 00:06:43.997417: val_loss -0.3659
2025-02-27 00:06:44.008404: Pseudo dice [0.6408, 0.732, 0.7274, 0.7795]
2025-02-27 00:06:44.010822: Epoch time: 122.76 s
2025-02-27 00:06:44.013255: Yayy! New best EMA pseudo Dice: 0.7148
2025-02-27 00:06:48.346102: 
2025-02-27 00:06:48.349030: Epoch 67
2025-02-27 00:06:48.351538: Current learning rate: 0.00369
2025-02-27 00:08:51.228561: train_loss -0.4828
2025-02-27 00:08:51.243536: val_loss -0.3697
2025-02-27 00:08:51.246069: Pseudo dice [0.6587, 0.7102, 0.715, 0.7836]
2025-02-27 00:08:51.248491: Epoch time: 122.89 s
2025-02-27 00:08:51.250318: Yayy! New best EMA pseudo Dice: 0.715
2025-02-27 00:08:55.811234: 
2025-02-27 00:08:55.813977: Epoch 68
2025-02-27 00:08:55.816079: Current learning rate: 0.00359
2025-02-27 00:10:56.624035: train_loss -0.4698
2025-02-27 00:10:56.639635: val_loss -0.3689
2025-02-27 00:10:56.642149: Pseudo dice [0.7294, 0.6898, 0.7539, 0.7878]
2025-02-27 00:10:56.644638: Epoch time: 120.81 s
2025-02-27 00:10:56.646854: Yayy! New best EMA pseudo Dice: 0.7175
2025-02-27 00:11:00.688137: 
2025-02-27 00:11:00.690778: Epoch 69
2025-02-27 00:11:00.693162: Current learning rate: 0.00349
2025-02-27 00:13:07.234344: train_loss -0.483
2025-02-27 00:13:07.248159: val_loss -0.3876
2025-02-27 00:13:07.250876: Pseudo dice [0.6554, 0.7699, 0.7745, 0.7882]
2025-02-27 00:13:07.253435: Epoch time: 126.55 s
2025-02-27 00:13:07.255499: Yayy! New best EMA pseudo Dice: 0.7205
2025-02-27 00:13:11.839510: 
2025-02-27 00:13:11.842392: Epoch 70
2025-02-27 00:13:11.844841: Current learning rate: 0.00338
2025-02-27 00:15:14.202459: train_loss -0.4921
2025-02-27 00:15:14.208852: val_loss -0.3511
2025-02-27 00:15:14.210848: Pseudo dice [0.5601, 0.7256, 0.7221, 0.7687]
2025-02-27 00:15:14.213095: Epoch time: 122.36 s
2025-02-27 00:15:16.723542: 
2025-02-27 00:15:16.726553: Epoch 71
2025-02-27 00:15:16.728970: Current learning rate: 0.00328
2025-02-27 00:17:21.900567: train_loss -0.4871
2025-02-27 00:17:21.912826: val_loss -0.3625
2025-02-27 00:17:21.915688: Pseudo dice [0.6969, 0.7521, 0.7458, 0.776]
2025-02-27 00:17:21.918098: Epoch time: 125.18 s
2025-02-27 00:17:24.095895: 
2025-02-27 00:17:24.098779: Epoch 72
2025-02-27 00:17:24.101155: Current learning rate: 0.00318
2025-02-27 00:19:25.841999: train_loss -0.4787
2025-02-27 00:19:25.844692: val_loss -0.3438
2025-02-27 00:19:25.846105: Pseudo dice [0.5729, 0.7906, 0.711, 0.8063]
2025-02-27 00:19:25.847153: Epoch time: 121.75 s
2025-02-27 00:19:28.040505: 
2025-02-27 00:19:28.044118: Epoch 73
2025-02-27 00:19:28.046167: Current learning rate: 0.00308
2025-02-27 00:21:33.620132: train_loss -0.4738
2025-02-27 00:21:33.745565: val_loss -0.3915
2025-02-27 00:21:33.762780: Pseudo dice [0.7167, 0.7604, 0.7413, 0.8008]
2025-02-27 00:21:33.765690: Epoch time: 125.58 s
2025-02-27 00:21:33.767722: Yayy! New best EMA pseudo Dice: 0.7237
2025-02-27 00:21:38.392912: 
2025-02-27 00:21:38.395467: Epoch 74
2025-02-27 00:21:38.398013: Current learning rate: 0.00297
2025-02-27 00:23:34.678784: train_loss -0.4904
2025-02-27 00:23:34.691451: val_loss -0.3714
2025-02-27 00:23:34.692912: Pseudo dice [0.6443, 0.7779, 0.6975, 0.7962]
2025-02-27 00:23:34.694283: Epoch time: 116.29 s
2025-02-27 00:23:34.695932: Yayy! New best EMA pseudo Dice: 0.7243
2025-02-27 00:23:38.985121: 
2025-02-27 00:23:38.988259: Epoch 75
2025-02-27 00:23:38.991418: Current learning rate: 0.00287
2025-02-27 00:25:41.744172: train_loss -0.4777
2025-02-27 00:25:41.748811: val_loss -0.3847
2025-02-27 00:25:41.751365: Pseudo dice [0.7419, 0.7357, 0.7965, 0.7753]
2025-02-27 00:25:41.753973: Epoch time: 122.76 s
2025-02-27 00:25:41.756119: Yayy! New best EMA pseudo Dice: 0.7281
2025-02-27 00:25:46.349682: 
2025-02-27 00:25:46.352568: Epoch 76
2025-02-27 00:25:46.354557: Current learning rate: 0.00277
2025-02-27 00:27:48.570491: train_loss -0.4866
2025-02-27 00:27:48.575280: val_loss -0.3773
2025-02-27 00:27:48.578101: Pseudo dice [0.5637, 0.8101, 0.7209, 0.8001]
2025-02-27 00:27:48.580746: Epoch time: 122.22 s
2025-02-27 00:27:50.846155: 
2025-02-27 00:27:50.849459: Epoch 77
2025-02-27 00:27:50.851516: Current learning rate: 0.00266
2025-02-27 00:29:55.763638: train_loss -0.4891
2025-02-27 00:29:55.780684: val_loss -0.3566
2025-02-27 00:29:55.783420: Pseudo dice [0.6022, 0.7321, 0.764, 0.7588]
2025-02-27 00:29:55.786193: Epoch time: 124.92 s
2025-02-27 00:29:57.413734: 
2025-02-27 00:29:57.416221: Epoch 78
2025-02-27 00:29:57.418471: Current learning rate: 0.00256
2025-02-27 00:32:04.186896: train_loss -0.4879
2025-02-27 00:32:04.191860: val_loss -0.4031
2025-02-27 00:32:04.195856: Pseudo dice [0.7425, 0.7963, 0.7666, 0.7916]
2025-02-27 00:32:04.198094: Epoch time: 126.77 s
2025-02-27 00:32:04.200412: Yayy! New best EMA pseudo Dice: 0.7311
2025-02-27 00:32:08.832816: 
2025-02-27 00:32:08.835358: Epoch 79
2025-02-27 00:32:08.837810: Current learning rate: 0.00245
2025-02-27 00:34:14.183864: train_loss -0.4827
2025-02-27 00:34:14.201029: val_loss -0.3719
2025-02-27 00:34:14.203454: Pseudo dice [0.6602, 0.7919, 0.7642, 0.7941]
2025-02-27 00:34:14.206135: Epoch time: 125.35 s
2025-02-27 00:34:14.208580: Yayy! New best EMA pseudo Dice: 0.7332
2025-02-27 00:34:19.752443: 
2025-02-27 00:34:19.755056: Epoch 80
2025-02-27 00:34:19.757416: Current learning rate: 0.00235
2025-02-27 00:36:21.548084: train_loss -0.4806
2025-02-27 00:36:21.552782: val_loss -0.37
2025-02-27 00:36:21.555168: Pseudo dice [0.5613, 0.7919, 0.6971, 0.7976]
2025-02-27 00:36:21.557294: Epoch time: 121.8 s
2025-02-27 00:36:23.764400: 
2025-02-27 00:36:23.766996: Epoch 81
2025-02-27 00:36:23.769419: Current learning rate: 0.00224
2025-02-27 00:38:29.566660: train_loss -0.4868
2025-02-27 00:38:29.571290: val_loss -0.3746
2025-02-27 00:38:29.573868: Pseudo dice [0.5962, 0.789, 0.6897, 0.8136]
2025-02-27 00:38:29.576497: Epoch time: 125.8 s
2025-02-27 00:38:31.310736: 
2025-02-27 00:38:31.313665: Epoch 82
2025-02-27 00:38:31.315737: Current learning rate: 0.00214
2025-02-27 00:40:31.483701: train_loss -0.4989
2025-02-27 00:40:31.488485: val_loss -0.3589
2025-02-27 00:40:31.491214: Pseudo dice [0.6117, 0.7503, 0.6862, 0.8115]
2025-02-27 00:40:31.493857: Epoch time: 120.17 s
2025-02-27 00:40:33.122833: 
2025-02-27 00:40:33.126305: Epoch 83
2025-02-27 00:40:33.128981: Current learning rate: 0.00203
2025-02-27 00:42:50.378349: train_loss -0.4887
2025-02-27 00:42:50.384483: val_loss -0.3561
2025-02-27 00:42:50.385809: Pseudo dice [0.5777, 0.7683, 0.6382, 0.8191]
2025-02-27 00:42:50.387223: Epoch time: 137.26 s
2025-02-27 00:42:52.593357: 
2025-02-27 00:42:52.595341: Epoch 84
2025-02-27 00:42:52.597081: Current learning rate: 0.00192
2025-02-27 00:44:49.552630: train_loss -0.4955
2025-02-27 00:44:49.557387: val_loss -0.3554
2025-02-27 00:44:49.559358: Pseudo dice [0.6457, 0.7497, 0.7155, 0.7726]
2025-02-27 00:44:49.561990: Epoch time: 116.96 s
2025-02-27 00:44:51.306283: 
2025-02-27 00:44:51.308822: Epoch 85
2025-02-27 00:44:51.310977: Current learning rate: 0.00181
2025-02-27 00:47:01.223191: train_loss -0.4861
2025-02-27 00:47:01.229442: val_loss -0.3497
2025-02-27 00:47:01.243842: Pseudo dice [0.6299, 0.7684, 0.7042, 0.7891]
2025-02-27 00:47:01.246759: Epoch time: 129.92 s
2025-02-27 00:47:02.792455: 
2025-02-27 00:47:02.795101: Epoch 86
2025-02-27 00:47:02.797750: Current learning rate: 0.0017
2025-02-27 00:49:18.001353: train_loss -0.4949
2025-02-27 00:49:18.005855: val_loss -0.37
2025-02-27 00:49:18.008309: Pseudo dice [0.6243, 0.8249, 0.7381, 0.8197]
2025-02-27 00:49:18.010693: Epoch time: 135.21 s
2025-02-27 00:49:20.283912: 
2025-02-27 00:49:20.286220: Epoch 87
2025-02-27 00:49:20.288389: Current learning rate: 0.00159
2025-02-27 00:51:21.806547: train_loss -0.4989
2025-02-27 00:51:21.811600: val_loss -0.3704
2025-02-27 00:51:21.814027: Pseudo dice [0.6621, 0.731, 0.7166, 0.8027]
2025-02-27 00:51:21.815651: Epoch time: 121.52 s
2025-02-27 00:51:23.401578: 
2025-02-27 00:51:23.403640: Epoch 88
2025-02-27 00:51:23.405906: Current learning rate: 0.00148
2025-02-27 00:53:19.385585: train_loss -0.5065
2025-02-27 00:53:19.389391: val_loss -0.3934
2025-02-27 00:53:19.399265: Pseudo dice [0.7034, 0.7873, 0.7373, 0.8092]
2025-02-27 00:53:19.401731: Epoch time: 115.99 s
2025-02-27 00:53:21.595008: 
2025-02-27 00:53:21.597869: Epoch 89
2025-02-27 00:53:21.600030: Current learning rate: 0.00137
2025-02-27 00:55:22.483992: train_loss -0.4911
2025-02-27 00:55:22.488701: val_loss -0.3618
2025-02-27 00:55:22.490399: Pseudo dice [0.6483, 0.7149, 0.7318, 0.7815]
2025-02-27 00:55:22.492001: Epoch time: 120.89 s
2025-02-27 00:55:24.724698: 
2025-02-27 00:55:24.727077: Epoch 90
2025-02-27 00:55:24.729099: Current learning rate: 0.00126
2025-02-27 00:57:32.311109: train_loss -0.4969
2025-02-27 00:57:32.316543: val_loss -0.3808
2025-02-27 00:57:32.321349: Pseudo dice [0.6596, 0.7351, 0.7375, 0.8024]
2025-02-27 00:57:32.323835: Epoch time: 127.59 s
2025-02-27 00:57:34.465367: 
2025-02-27 00:57:34.468201: Epoch 91
2025-02-27 00:57:34.470447: Current learning rate: 0.00115
2025-02-27 00:59:42.870156: train_loss -0.4991
2025-02-27 00:59:42.875704: val_loss -0.3611
2025-02-27 00:59:42.879954: Pseudo dice [0.678, 0.7297, 0.7416, 0.7895]
2025-02-27 00:59:42.882634: Epoch time: 128.41 s
2025-02-27 00:59:44.920592: 
2025-02-27 00:59:44.922979: Epoch 92
2025-02-27 00:59:44.925192: Current learning rate: 0.00103
2025-02-27 01:01:47.713347: train_loss -0.5097
2025-02-27 01:01:47.718072: val_loss -0.4023
2025-02-27 01:01:47.720176: Pseudo dice [0.6543, 0.811, 0.754, 0.8166]
2025-02-27 01:01:47.722747: Epoch time: 122.79 s
2025-02-27 01:01:47.725236: Yayy! New best EMA pseudo Dice: 0.7335
2025-02-27 01:01:52.296036: 
2025-02-27 01:01:52.299384: Epoch 93
2025-02-27 01:01:52.301537: Current learning rate: 0.00091
2025-02-27 01:03:56.925593: train_loss -0.5037
2025-02-27 01:03:56.932041: val_loss -0.3962
2025-02-27 01:03:56.935415: Pseudo dice [0.7398, 0.8057, 0.8252, 0.7722]
2025-02-27 01:03:56.938073: Epoch time: 124.63 s
2025-02-27 01:03:56.947899: Yayy! New best EMA pseudo Dice: 0.7387
2025-02-27 01:04:01.396182: 
2025-02-27 01:04:01.398616: Epoch 94
2025-02-27 01:04:01.400843: Current learning rate: 0.00079
2025-02-27 01:06:18.465737: train_loss -0.5043
2025-02-27 01:06:18.483095: val_loss -0.3672
2025-02-27 01:06:18.486151: Pseudo dice [0.7466, 0.7251, 0.8008, 0.769]
2025-02-27 01:06:18.487909: Epoch time: 137.07 s
2025-02-27 01:06:18.490070: Yayy! New best EMA pseudo Dice: 0.7409
2025-02-27 01:06:22.403899: 
2025-02-27 01:06:22.406572: Epoch 95
2025-02-27 01:06:22.408541: Current learning rate: 0.00067
2025-02-27 01:08:22.942872: train_loss -0.506
2025-02-27 01:08:22.960890: val_loss -0.3669
2025-02-27 01:08:22.963778: Pseudo dice [0.6323, 0.7354, 0.7063, 0.8017]
2025-02-27 01:08:22.966357: Epoch time: 120.54 s
2025-02-27 01:08:24.557038: 
2025-02-27 01:08:24.559369: Epoch 96
2025-02-27 01:08:24.561597: Current learning rate: 0.00055
2025-02-27 01:10:34.198946: train_loss -0.5032
2025-02-27 01:10:34.211224: val_loss -0.3959
2025-02-27 01:10:34.213832: Pseudo dice [0.7052, 0.7849, 0.8002, 0.7722]
2025-02-27 01:10:34.215738: Epoch time: 129.64 s
2025-02-27 01:10:34.217939: Yayy! New best EMA pseudo Dice: 0.7414
2025-02-27 01:10:38.955563: 
2025-02-27 01:10:38.958485: Epoch 97
2025-02-27 01:10:38.960569: Current learning rate: 0.00043
2025-02-27 01:12:42.454929: train_loss -0.5013
2025-02-27 01:12:42.471802: val_loss -0.3648
2025-02-27 01:12:42.474718: Pseudo dice [0.6533, 0.7667, 0.7045, 0.8244]
2025-02-27 01:12:42.476947: Epoch time: 123.5 s
2025-02-27 01:12:44.135800: 
2025-02-27 01:12:44.138855: Epoch 98
2025-02-27 01:12:44.141463: Current learning rate: 0.0003
2025-02-27 01:14:46.897257: train_loss -0.5029
2025-02-27 01:14:46.902796: val_loss -0.4009
2025-02-27 01:14:46.906320: Pseudo dice [0.7465, 0.7715, 0.7812, 0.7915]
2025-02-27 01:14:46.908886: Epoch time: 122.76 s
2025-02-27 01:14:46.911105: Yayy! New best EMA pseudo Dice: 0.7441
2025-02-27 01:14:52.396274: 
2025-02-27 01:14:52.398824: Epoch 99
2025-02-27 01:14:52.401361: Current learning rate: 0.00016
2025-02-27 01:16:58.565299: train_loss -0.506
2025-02-27 01:16:58.570243: val_loss -0.3893
2025-02-27 01:16:58.572849: Pseudo dice [0.6561, 0.7595, 0.7687, 0.7965]
2025-02-27 01:16:58.575428: Epoch time: 126.17 s
2025-02-27 01:16:58.578262: Yayy! New best EMA pseudo Dice: 0.7442
2025-02-27 01:17:05.439100: Training done.
2025-02-27 01:17:05.472684: Using splits from existing split file: /home3/hghr96/parm/work/AD_project/segmentation/nnUNet/data/nnUNet_preprocessed/Dataset501_AD/splits_final.json
2025-02-27 01:17:05.475920: The split file contains 5 splits.
2025-02-27 01:17:05.477445: Desired fold for training: 3
2025-02-27 01:17:05.478950: This split has 71 training and 17 validation cases.
2025-02-27 01:17:05.481613: predicting ad_004
2025-02-27 01:17:05.487369: ad_004, shape torch.Size([1, 140, 225, 140]), rank 0
2025-02-27 01:17:26.609039: predicting ad_006
2025-02-27 01:17:26.617755: ad_006, shape torch.Size([1, 177, 489, 177]), rank 0
2025-02-27 01:20:21.933498: predicting ad_016
2025-02-27 01:20:21.946048: ad_016, shape torch.Size([1, 100, 242, 100]), rank 0
2025-02-27 01:29:18.564829: predicting ad_018
2025-02-27 01:29:18.577219: ad_018, shape torch.Size([1, 177, 253, 177]), rank 0
2025-02-27 01:33:28.108595: predicting ad_032
2025-02-27 01:33:28.121998: ad_032, shape torch.Size([1, 187, 319, 187]), rank 0
2025-02-27 01:38:33.861080: predicting ad_054
2025-02-27 01:38:33.875737: ad_054, shape torch.Size([1, 200, 288, 200]), rank 0
2025-02-27 01:44:48.709447: predicting ad_058
2025-02-27 01:44:48.722193: ad_058, shape torch.Size([1, 176, 326, 176]), rank 0
2025-02-27 01:50:44.489968: predicting ad_062
2025-02-27 01:50:44.504135: ad_062, shape torch.Size([1, 187, 333, 187]), rank 0
2025-02-27 01:56:18.720844: predicting ad_071
2025-02-27 01:56:18.732653: ad_071, shape torch.Size([1, 124, 275, 124]), rank 0
2025-02-27 02:06:47.020419: predicting ad_072
2025-02-27 02:06:47.030469: ad_072, shape torch.Size([1, 166, 296, 166]), rank 0
2025-02-27 02:11:40.231512: predicting ad_075
2025-02-27 02:11:40.245356: ad_075, shape torch.Size([1, 166, 288, 166]), rank 0
2025-02-27 02:20:58.026928: predicting ad_077
2025-02-27 02:20:58.041586: ad_077, shape torch.Size([1, 199, 237, 199]), rank 0
2025-02-27 02:25:10.775408: predicting ad_082
2025-02-27 02:25:10.788896: ad_082, shape torch.Size([1, 117, 261, 117]), rank 0
2025-02-27 02:30:12.518062: predicting ad_090
2025-02-27 02:30:12.533924: ad_090, shape torch.Size([1, 217, 300, 217]), rank 0
2025-02-27 02:34:50.560169: predicting ad_091
2025-02-27 02:34:50.574888: ad_091, shape torch.Size([1, 185, 220, 185]), rank 0
2025-02-27 02:41:20.760826: predicting ad_092
2025-02-27 02:41:20.775094: ad_092, shape torch.Size([1, 215, 261, 215]), rank 0
2025-02-27 02:44:44.454834: predicting ad_103
2025-02-27 02:44:44.467818: ad_103, shape torch.Size([1, 103, 229, 103]), rank 0
2025-02-27 02:56:19.371066: Validation complete
2025-02-27 02:56:19.374007: Mean Validation Dice:  0.5625749879086963
Finished at Thu 27 Feb 2025 02:56:22 AM GMT
Total Execution Time: 18968 seconds
